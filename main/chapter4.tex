%!TEX root = ../my_thesis.tex

\renewcommand{\curChapter}{main/chapter4}

\chapter{Performance Evaluations and Comparisons}
\label{chap:eval}

This chapter proposes to evaluate the various contributions exposed in the
previous chapters. The three first sections focus on the efficient
implementations of the LDPC decoders, polar decoders and turbo decoders. The
throughput, the latency and the energy efficiency are studied and compared with
other works. The forth section summarizes the most efficient software decoder
implementations we found in the literature. Three hall of fames are proposed:
one for the LDPC decoders, one for the polar decoders and one for the turbo
decoders. Some metrics are defined to facilitate the comparison with the
different works. The fifth section is an evaluation of the proposed SCMA
demodulator implementations. The throughput, the latency and the energy
efficiency are studied over various platforms. The sixth section is a
performance analysis of the proposed \AFFECT simulator. A representative digital
communication chain is defined and evaluated at two different levels. The first
level is the mono-threaded per task performance and the second level is the
multi-threaded global performance of the simulator. The last section concludes
this chapter.

\vspace*{\fill}
\minitoccustom
\vspace*{\fill}

\newpage
\section{LDPC Decoders}
\label{sec:eval_ldpc}

In this section we propose to evaluate the fast LDPC BP implementation presented
in Section~\ref{sec:opt_ldpc}. The decoder throughputs and latencies are benched
on two high-end x86 CPUs and on two $\mathcal{H}$ parity matrices with different
characteristics. Then, the proposed BP decoder is compared with the
state-of-the-art LDPC decoders.

\subsection{Experimentation Platforms}

\begin{table}[htp]
  \centering
  \caption
    [Specifications of the target processors for the LPDC decoder experiments.]
    {Specifications of the target processors.}
  \begin{tabular}{c | c  c  c}
                         & \textbf{Platinum 8168}        & \textbf{EPYC 7452}       \\
    \hline
    \hline
    \textbf{CPU}         & Intel\R Xeon\TM Platinum 8168 & AMD\R EPYC 7452          \\
    \textbf{Arch.}       & \textit{Skylake} Q3'17        & \textit{Zen 2} Q3'19     \\
    \textbf{Process}     & 14 nm                         & 7 nm                     \\
    \textbf{Cores/Freq.} & 24 cores, 2.7 GHz             & 32 cores, 2.35 GHz       \\
    \textbf{LLC}         & 33 MB L3                      & 128 MB L3                \\
    \textbf{TDP}         & 205 W                         & 155 W                    \\
  \end{tabular}
  \label{tab:eval_ldpc_specs}
\end{table}

For the experimentations, we selected two high end CPUs: the Intel\R Xeon\TM
Platinum 8168 and the AMD\R EPYC 7452 as shown in
Table~\ref{tab:eval_ldpc_specs}. The two targets come with a large number of
cores, 24 and 32 respectively. The SMT and the frequency boost have been
disabled for a matter of reproducibility. The Intel\R CPU is able to execute
SSE, AVX and AVX-512 instructions while the AMD\R CPU can only execute SSE and
AVX instructions. The GNU compiler version 7.5 has been used with the following
optimization flags: \verb|-O3 -funroll-loops|.

In this section, we choose to evaluate the BP decoder with an horizontal layered
scheduling (BP-HL) and with the Normalized Min-Sum (NMS) update rules. We focus
on the BP-HL+NMS implementation presented in
Section~\ref{sec:opt_ldpc_spe_bphlnms}. This decoder is not as flexible as the
one presented in Section~\ref{sec:opt_ldpc_gen}. But it comes with higher
decoding speed. Gains ranging between 20\% to 50\% are observed depending on the
$\mathcal{H}$ parity matrix and on the CPU. In all the presented results, the
decoder works on 16-bit fixed-point data. This representation is able to match
the BER/FER decoding performance of the floating-point representation. We
encounter some difficulties to keep an acceptable level of decoding performance
when we ran the 8-bit fixed-point decoder. This is why we have chosen a 16-bit
fixed-point representation.

\subsection{Throughput and Latency Performance on Multi-core CPUs}

\begin{figure}[htp]
  \centering
  \subfloat[][Throughput.]{\includegraphics[width=0.485\textwidth]{\curChapter/fig/ldpc/WiMAX_thr_lat/WiMAX_thr}\label{plot:eval_ldpc_WiMAX_thr}}
  \quad
  \subfloat[][Latency.]{\includegraphics[width=0.485\textwidth]{\curChapter/fig/ldpc/WiMAX_thr_lat/WiMAX_lat}\label{plot:eval_ldpc_WiMAX_lat}}
  \caption
    [LDPC decoder throughput and latency depending on the number of cores (WiMAX).]
    {LDPC decoder throughput and latency depending on the number of cores.
    (2304, 1152) IEEE 802.16e WiMAX code. BP-HL scheduling with 50 iterations
    and NMS updates rules ($\alpha = 0.875$). 16-bit fixed-point data
    representation.}
  \label{plot:eval_ldpc_WiMAX_thr_lat}
\end{figure}

In this section, we propose to study the throughput and the latency performance
evolution depending on the number of cores. Two $\mathcal{H}$ parity matrices
are benched. The first one comes from the WiMAX standard and is a middle size
matrix where $N = 2304$ and $R = 1/2$. The second one is a bigger matrix from
the DVB-S2 standard where $N = 16200$ and $K = 14400$.

The throughput and latency values for the WiMAX $\mathcal{H}$ parity matrix are
given in Figure~\ref{plot:eval_ldpc_WiMAX_thr_lat}. On the Platinum 8168 target,
the throughput evolution is almost linear in function of the number of cores and
the wider instruction sets. In other words, the best throughput performance is
obtained with AVX-512 instructions and on 24 cores. If we look at the latencies,
we remark that with AVX-512 instructions there is a marginal increase of the
value starting from 17 cores. On the EPYC 7452 CPU the performance increase is
mostly linear from 1 to 15 cores. After that, the latency is increasing and the
throughput gains are reduced. Like for the Platinum 8168 target, it is
preferable to use the wider possible SIMD instructions on the EPYC 7452 CPU.

\begin{figure}[htp]
  \centering
  \subfloat[][Throughput.]{\includegraphics[width=0.485\textwidth]{\curChapter/fig/ldpc/DVB-S2_thr_lat/DVB-S2_thr}\label{plot:eval_ldpc_DVB-S2_thr}}
  \quad
  \subfloat[][Latency.]{\includegraphics[width=0.485\textwidth]{\curChapter/fig/ldpc/DVB-S2_thr_lat/DVB-S2_lat}\label{plot:eval_ldpc_DVB-S2_lat}}
  \caption
    [LDPC decoder throughput and latency depending on the number of cores (DVB-S2).]
    {LDPC decoder throughput and latency depending on the number of cores.
    (16200, 14400) DVB-S2 code. BP-HL scheduling with 50 iterations and NMS
    updates rules ($\alpha = 0.875$). 16-bit fixed-point data representation.}
  \label{plot:eval_ldpc_DVB-S2_thr_lat}
\end{figure}

The obtained throughput and latency values for the DVB-S2 $\mathcal{H}$ parity
matrix are presented in Figure~\ref{plot:eval_ldpc_DVB-S2_thr_lat}. This matrix
is significantly larger than the previous one. As a consequence the memory
footprint of the decoder is also higher. This highlights some limitations of the
proposed inter-frame SIMD implementation. With this type of implementation, the
memory footprint of the decoder is increasing with the size of the SIMD
instructions. On the proposed 16-bit implementation, 8 frames are buffered in
SSE, 16 frames are buffered in AVX and 32 frames are buffered in AVX-512.
On the resulting throughput performance, one can note that the AVX-512
performance is acceptable until a point (14/15 cores) where the performance
begin to decrease significantly. At this point the caches of the CPUs are not
big enough to contain all the data anymore. The number of slow transactions
between the CPU and the RAM are increasing (as well as the number of LLC
misses). The same phenomena appears for the AVX implementation on the Platinum
8168 target but later namely 20 cores. On the EPYC 7452 the throughout
performance results always take advantage of the increasing number of cores. But
in AVX, after 16 cores the performance gains is smaller. This is due to the fact
that the data cannot be fully contained in the L2 caches anymore.

The Platinum 8168 comes with higher computational power per core than the EPYC
7452 CPU thanks to its AVX-512 SIMD engine. However the dedicated amount of L3
memory per core is lower than on the EPYC CPU. The Platinum 8168 target
dedicates $33 / 24 = 1.375$ MB per core while the EPYC 7452 target dedicates
$128 / 32 = 4$ MB per core. This is approximately three times more L3 memory
per core for the EPYC CPU. As a consequence, the AMD\R Zen 2 architecture is
more adapted to the inter-frame SIMD strategy.

\subsection{Comparison with State-of-the-art BP Decoders.}

\begin{table}[htp]
  \centering
  \caption
    [Comparison of the proposed BP decoder with the state-of-art.]
    {Comparison of the proposed BP decoder with the state-of-art.
     Horizontal layered scheduling. Early termination is disabled.
     $\mathcal{NT}_c = (\mathcal{T}_c \times i) / (\text{Cores} \times 50)$.}
  \label{tab:eval_ldpc_comparison}
  {\resizebox{\linewidth}{!}{
  \begin{tabular}{r r r r r r r r r r}
       \textbf{Ref.} & \textbf{Standard} $\bm{(N,K)}$ & \textbf{Platform} & \textbf{Cores} & \textbf{Pre.} & $\bm{i}$ & \textbf{Up.}   & $\bm{\mathcal{L}}$ & $\bm{\mathcal{T}_c}$ & $\bm{\mathcal{NT}_c}$ \\
                     &                                &                   &                &        (bits) &          & \textbf{Rules} &           ($\mu$s) &               (Mb/s) &                (Mb/s) \\
    \hline
    \hline
    \cite{LeGal2016} &          802.16e $(2304,1152)$ & i7-4960HQ         &              4 &             8 &       50 &            OMS &               1359 &                  217 &                 54.25 \\
    \cite{LeGal2017} &          802.16e $(2304,1152)$ & i7-5650U          &              2 &             8 &       10 &            OMS &                 12 &                  385 &                 38.50 \\
    \cite{Xu2019}    &               5G $(9126,8448)$ & Gold 6154         &             18 &             8 &       10 &            OMS &                 31 &                 4892 &                 54.36 \\
    This work        &          802.16e $(2304,1152)$ & Platinum 8168     &             24 &            16 &       50 &            NMS &               2637 &                  671 &                 27.96 \\
    This work        &          802.16e $(2304,1152)$ & EPYC 7452         &             32 &            16 &       50 &            NMS &               1368 &                  862 &                 26.94 \\
  \end{tabular}
  }}
\end{table}

Table~\ref{tab:eval_ldpc_comparison} summarizes the fastest software LDPC BP
implementations on CPU we found in the literature. \emph{Pre.} is the precision
in bits. $i$ is the number of decoding iterations. \emph{Up. Rules} are the
update rules type. $\mathcal{L}$ is the decoder latency. $\mathcal{T}_c$ is the
coded throughput. $\mathcal{NT}_c$ is the normalized coded throughput: this
metric considers 50 iterations on a single core. It enables to directly compare
the throughput of the listed decoders. In \cite{LeGal2016}, the decoder uses
the same inter-frame SIMD strategy as our proposed decoder. The latency is
comparable with our implementation while the throughput is about two times
higher. This is a direct consequence of the 8-bit quantization. All the
presented decoders from the literature are using a 8-bit fixed-point
representation while our implementation is executed on 16-bit. The 8-bit
implementations require specific modifications to ensure the same level of
decoding performance. In the proposed implementation, these specific
modifications have not been implemented to the benefit of genericity. Indeed,
the same decoder description is able to adapt to 32-bit floating-point and
16-bit fixed-point representations. It is also able to run on various targets
like x86 and ARM\R CPUs.

In \cite{LeGal2017,Xu2019}, an intra-frame SIMD strategy is used. The
parallelism comes from the structure of the $\mathcal{H}$ parity matrix
(quasi-cyclic). It is then possible to apply the SIMD instructions during the
decoding of a single frame. It leads to much lower latencies. We can see that
our proposed decoder is not competitive. The limitation of this type of
intra-frame implementation is that the performance strongly depends on the
parity matrix. In the worst case, if the $\mathcal{H}$ parity matrix is not
quasi-cyclic, then the throughput and the latency cannot be improved.

To summarize, the proposed implementation comes with a throughput approaching to
the best implementations ($\approx$ two times slower) while the latency is still
very high compared to the intra-frame decoders. One of the main advantage of the
proposed implementation is its flexibility. Indeed, it can be run on 32-bit
floating-point or 16-bit fixed-point. There is also a unique source code
description for the SSE, AVX, AVX-512 and NEON instructions. As it has been
shown before, this is valuable because depending on the $\mathcal{H}$ parity
matrix, the CPU and the number of cores used. The throughput and latency
performances can be more interesting on one or the other of the SIMD engine.
However, even if the proposed implementation is always able to take advantage of
the SIMD instructions, we saw some limitations when the memory footprint exceeds
the CPU caches.

\section{Polar Decoders}

\subsection{Successive Cancellation Decoders}

In this section we propose to evaluate both the polar SC dynamic and generated
decoders presented in Section~\ref{sec:opt_polar_sc}. First, a study on the
software decoders energy efficiency is conducted on low power ARM\R CPUs. Then,
the impact of the compression technique for the generated SC decoders
(see Section~\ref{sec:opt_polar_sc_compression}) is studied. Finally, the
dynamic and generated SC decoders are compared with the state-of-the-art
decoders.

\subsubsection{Experimentation Platforms}

\begin{table}[htp]
  \centering
  \caption
    [Specification of the x86 platforms for the polar decoders experiments.]
    {Specification of the x86 platforms.}
  \label{tab:eval_polar_sc_specs_x86}
  \begin{tabular}{c | c c c}
                                & \textbf{E3-1225}        & \textbf{i7-2600}        & \textbf{i7-4850HQ}         \\
  \hline
  \hline
  \multirow{1}{*}{\textbf{CPU}} & Intel\R Xeon\TM E3-1225 & Intel\R Core\TM i7-2600 & Intel\R Core\TM  i7-4850HQ \\
  \textbf{Cores/Freq.}          & 4 cores, 3.1-3.4 Ghz    & 4 cores, 3.4-3.8 GHz    & 4 cores, 2.3-3.5 GHz       \\
  \textbf{Arch.}                & \emph{Sandy Bridge}     & \emph{Sandy Bridge}     & \emph{Crystal Well}        \\
  \textbf{Process}              & 32 nm                   & 32 nm                   & 22 nm                      \\
  \multirow{1}{*}{\textbf{LLC}} & L3 6 MB                 & L3 8 MB                 & L3 6 MB                    \\
  \end{tabular}
\end{table}

\begin{table}[htp]
  \centering
  \caption
    [Specification of the ARM\R platforms for the polar decoders experiments.]
    {Specification of the ARM\R platforms.}
  \label{tab:eval_polar_sc_specs_arm}
  \begin{tabular}{c | c c c}
                                      &       \textbf{A15-J} &    \textbf{A15-O/A7-O} &       \textbf{A57/A53} \\
    \hline
    \hline
    \multirow{1}{*}{\textbf{SoC}}     &  Nvidia\R Jetson TK1 & Hardkernel\R ODROID-XU &            ARM\R \juno \\
    \multirow{1}{*}{\textbf{Arch.}}   & 32-bit, \emph{ARMv7} &   32-bit, \emph{ARMv7} &   64-bit, \emph{ARMv8} \\
    \multirow{1}{*}{\textbf{Process}} &                28 nm &                  28 nm & unspecified (32/28 nm) \\
    \hline
    \multirow{3}{*}{\textbf{\bigARM}} &  4xCortex-A15 MPCore &    4xCortex-A15 MPCore &    2xCortex-A57 MPCore \\
                                      &       freq. 2.32 Ghz &     freq. 0.8--1.6 GHz &    freq. 0.45--1.1 GHz \\
                                      &              L2 1 MB &                L2 2 MB &                L2 2 MB \\
    \hline
    \multirow{3}{*}{\textbf{\little}} &   \multirow{4}{*}{-} &     4xCortex-A7 MPCore &    4xCortex-A53 MPCore \\
                                      &                      &     freq. 250--600 MHz &     freq. 450--850 MHz \\
                                      &                      &              L2 512 KB &                L2 1 MB \\
  \end{tabular}
\end{table}

Table~\ref{tab:eval_polar_sc_specs_x86} shows the x86/Intel\R targets used for
the polar SC decoders evaluation while Table~\ref{tab:eval_polar_sc_specs_arm}
summarizes the ARM\R platforms. There are two platforms with Cortex-A15 cores.
We decided to identify the ones from the Nvidia\R Jetson TK1 board as the
\emph{A15-J} and the ones from the Hardkernel\R ODROID-XU as the \emph{A15-O}.

In this section, all the binaries have been compiled with the GNU compiler
version 5.4 and with the following optimization flags:
\verb|-Ofast -funroll-loops|. All the proposed results are single threaded and
the frequency boost is enabled on the Intel\R CPUs. As a convention, performance
of the intra-frame SIMD version of the SC decoder is represented in blue in the
figures while performance of the inter-frame SIMD version is represented in red.

\subsubsection{Performance and Energy Efficiency on Embedded CPUs}

The objective and originality of this section is to explore different software
and hardware parameters for the execution of a software SC decoder on ARM\R
architectures. For a software decoder implementation, many parameters can
be explored, influencing performance and energy efficiency. The target rate and
frame size are applicative parameters. The SIMDization strategies (intra-frame
or inter-frame) and the features of decoders (generated or dynamic) are software
parameters. Furthermore, the target architecture, its frequency and its voltage
are hardware parameters. This study investigates the correlations between these
parameters in order to better choose an efficient implementation for a given
applicative purpose. The low-power general purpose ARM32 and ARM64 processor
testbeds based on big.LITTLE architecture are selected as representative of
modern multi-core and heterogeneous architectures.

The flexibility of the AFF3CT software enables to alter many parameters and turn
many optimizations on or off, leading to a large amount of potential
combinations. For the purpose of this study, computations are performed with
8-bit fixed-point data types, with all tree pruning optimizations activated. The
main metric considered is the average amount of energy in Joules to decode one
bit of information, expressed  as  $E_b = (P \times \mathcal{L}) / (K \times F)$
where $P$ is the average power (Watts), $\mathcal{L}$ is the latency, $K$ is the
number of information bits and $F$ is the number of frames decoded in parallel.

\begin{table}[htp]
  \centering
  \caption
    [Throughput, latency and \emph{energy-per-bit} of the dynamic SC decoders.]
    {Characteristics for each cluster ($\mathcal{T}_i$ is the information
    throughput), for dynamic SC decoders. $N = 4096$, rate $R = 1/2$. The RAM
    consumption is not included in $P$ and in $E_b$.}
  \label{tab:eval_polar_energy_results}
  \begin{tabular}{r r r r r r r}
    \textbf{Cluster} & \textbf{Freq.} & \textbf{Impl.} & $\bm{\mathcal{L}}$ & $\bm{\mathcal{T}_i}$ & $\bm{P}$ & $\boldsymbol{E_b}$ \\
                     &          (MHz) &                &          ($\mu$s)  &               (Mb/s) &      (W) &               (nJ) \\
    \hline
    \hline
    \multirow{3}{*}{A7-O}      & \multirow{3}{*}{ 450} & seq.  &  655.0 &   3.1 & 0.117 &  37.8 \\
                               &                       & intra &  158.0 &  13.0 & 0.123 &   9.5 \\
                               &                       & inter & 1506.0 &  21.8 & 0.131 &   6.0 \\
    \hline
    \multirow{3}{*}{A53}       & \multirow{3}{*}{ 450} & seq.  &  966.0 &   2.1 & 0.062 &  29.0 \\
                               &                       & intra &  203.0 &  10.1 & 0.070 &   7.0 \\
                               &                       & inter & 1902.0 &  17.2 & 0.088 &   5.1 \\
    \hline
    \multirow{3}{*}{A15-O}     & \multirow{3}{*}{1100} & seq.  &  274.0 &   7.5 & 0.913 & 122.0 \\
                               &                       & intra &   58.0 &  35.2 & 0.991 &  28.2 \\
                               &                       & inter &  522.0 &  62.8 & 1.093 &  17.4 \\
    \hline
    \multirow{3}{*}{A57}       & \multirow{3}{*}{1100} & seq.  &  222.0 &   9.2 & 0.730 &  78.9 \\
                               &                       & intra &   52.0 &  39.2 & 0.826 &  21.1 \\
                               &                       & inter &  503.0 &  65.1 & 0.923 &  14.2 \\
    \hline
    \multirow{3}{*}{i7-4850HQ} & \multirow{3}{*}{3300} & seq.  &   56.5 &  36.3 & 8.532 & 235.4 \\
                               &                       & intra &    9.2 & 221.8 & 9.017 &  40.5 \\
                               &                       & inter &   51.8 & 632.2 & 9.997 &  15.8 \\
  \end{tabular}
\end{table}

Table~\ref{tab:eval_polar_energy_results} gives an overview of the decoder
behavior on different clusters and for various implementations. The code is
always single threaded and only the 8-bit fixed-point decoders are considered.
Indeed 32-bit floating-point versions are 4 times more energy consuming, on
average. The sequential version is mentioned for reference only, as the
throughput $\mathcal{T}_i$ is much higher on vectorized versions. Generally the
inter-frame SIMD strategy delivers better performance at the cost of a higher
latency $\mathcal{L}$. Table~\ref{tab:eval_polar_energy_results} also compares
the energy consumption of \little and \bigARM clusters. The A53 consumes less
energy than the A7-O. The A57 consumes less energy than the A15-O, respectively.
This can be explained by architectural improvements brought by the more recent
ARM64 platform. Despite the fact that the ARM64 is a development board, the
ARM64 outperforms the ARM32 architecture. Finally we observe that the power
consumption is higher for the inter-frame version than for the intra-frame one
because it fills the SIMD units more intensively. One can note that the SIMD
units consume more than the scalar pipeline. However, this is largely
compensated by a much higher efficiency.

For comparison, the results for the Intel\R Core\TM i7-4850HQ, using SSE4.1
instructions (same vector length as ARM\R NEON vectors) are also included. Even
if the i7 is competitive with the ARM\R big cores in terms of
\textit{energy-per-bit} ($E_b$), these results show it is not well suited for
the low power SDR systems because of its high power requirements.

\begin{figure}[htp]
  \centering
  \subfloat[][Total (cluster + memory).]{\includegraphics[height=7cm]{\curChapter/fig/polar/sc_energy_implems_vs/sc_energy_implems_vs_total}\label{plot:eval_polar_sc_energy_implems_vs_total}}
  \quad
  \subfloat[][Memory only.]{\includegraphics[height=7cm]{\curChapter/fig/polar/sc_energy_implems_vs/sc_energy_implems_vs_mem}\label{plot:eval_polar_sc_energy_implems_vs_mem}}
  \caption
    [SC variation of the \emph{energy-per-bit} for different frame sizes and
    implementations.]
    {Variation of the \emph{energy-per-bit} for different frame sizes and
    implementations: intra-/inter-frame, dynamic and generated code, on A15-O @
    1.1 GHz and with a fixed code rate $R = 1/2$.}
  \label{plot:eval_polar_sc_energy_implems_vs}
\end{figure}

Figure~\ref{plot:eval_polar_sc_energy_implems_vs} shows the
\emph{energy-per-bit} consumption depending on the frame size $N$ for the fixed
rate $R = 1/2$. In general, the energy consumption increases with the frame
size. For small frame sizes ($N$ from $2^{8}$ to $2^{14}$), the inter-frame SIMD
outperforms the intra-frame SIMD. This is especially true for $N = 2^8$ which
has a low ratio of SIMD computations over scalar computations in the intra-frame
version. As the frame size increases, the ratio of SIMD versus scalar
computations increases as well. At some point around $N = 2^{16}$ the
intra-frame implementation begins to outperform the inter-frame one. Indeed, the
data for the intra-frame decoder still fits in the CPU cache, whereas the data
of the inter-frame decoder does not fit the cache anymore. In our case (8-bit
fixed point numbers and 128-bit vector registers) the inter-frame decoders
require 16~times more memory than the intra-frame decoders. Then, for the frame
size $N = 2^{20}$, both intra and inter-frame decoders now exceed the cache
capacity. The RAM power consumption becomes more significant due to the
increased number of cache misses causing RAM transactions. Considering those
previous observations, it is more energy efficient to use inter-frame strategy
for small frame sizes, whereas it is better to apply intra-frame strategy for
larger frame sizes.

\begin{figure}[htp]
  \centering
  \subfloat[][ARM\R Cortex-A7 (ODROID-XU+E)]{\includegraphics[width=0.485\textwidth]{\curChapter/fig/polar/sc_energy_freq/sc_energy_freq_a7}\label{plot:eval_polar_sc_energy_freq_a7}}
  \quad
  \subfloat[][ARM\R Cortex-A15 (ODROID-XU+E)]{\includegraphics[width=0.485\textwidth]{\curChapter/fig/polar/sc_energy_freq/sc_energy_freq_a15}\label{plot:eval_polar_sc_energy_freq_a15}}
  \caption
    [SC variation of the \emph{energy-per-bit} depending on the cluster
    frequency.]
    {Variation of the \emph{energy-per-bit} ($E_b$) depending on the cluster
    frequency (dynamic code, intra-, inter-frame). $N = 4096$ and $R = 1/2$.
    Dark colors and light colors stand for CPU cluster and RAM energy
    consumption, respectively.}
  \label{plot:eval_polar_sc_energy_freq}
\end{figure}

Figure~\ref{plot:eval_polar_sc_energy_freq} shows the impact of the frequency on
the energy, for a given value of frame size $N=4096$ and a code rate $R=1/2$. On
both A7-O and A15-O clusters, the supply voltage increases with the frequency
from 0.946 V to 1.170 V. Results for the A7-O \little cluster shows that the
energy consumed by the system RAM is significant: At 250 MHz it accounts for
half of the energy cost. Indeed, at low frequency, the long execution time due
to the low throughput causes a high dynamic RAM refreshing bill. Therefore it is
more interesting to use frequencies higher than 250 MHz. For this problem size
and configuration, and from an energy-only point of view, the best choice is to
run the decoder at 350 MHz. On the A15-O \bigARM cluster, the energy cost is
driven by the CPU frequency, while the RAM energy bill is limited compared to
the CPU.

Thus, the bottom line about energy versus frequency relationship is: On the \little
cluster it is more interesting to clock the CPU at high frequency (higher
throughput and smaller latency for a small additional energy cost); On the
\bigARM cluster, where the RAM consumption is less significant, it is better to
clock the CPU at a low frequency.

\begin{figure}[htp]
  \centering
  \includegraphics[width=0.70\textwidth]{\curChapter/fig/polar/sc_energy_rate/sc_energy_rate_N32768}
  \caption
    [SC evolution of the \emph{energy-per-bit} depending on the code rate.]
    {Evolution of the \emph{energy-per-bit} ($E_b$) for $N = 32768$ depending on
    the code rate $R = K / N$ (various impl.: intra-, inter-frame, code gen.
    on). Running on A7-O, A53 and A57 clusters @ 450MHz.}
  \label{plot:eval_polar_sc_energy_rate}
\end{figure}

In Figure~\ref{plot:eval_polar_sc_energy_rate} the \emph{energy-per-bit} cost
decreases when the code rate increases. This is expected because there are many
information bits in the frame when $R$ is high. It makes the decoder more
energy efficient. With high rates, the SC decoding tree can be pruned more
effectively. It makes the decoding process even more energy efficient.
Figure~\ref{plot:eval_polar_sc_energy_rate} also compares the ARM\R A7-O, A53
and A57 clusters for the same 450 MHz frequency (note: this frequency is not
available on the A15-O). The \little A7-O is more energy efficient than the
\bigARM A57, and the \little A53 is itself more energy efficient than the
\little A7-O ($E_{b_{\text{A53}}} < E_{b_{\text{A7-O}}} < E_{b_{\text{A57}}}$).

\begin{figure}[htp]
  \centering
  \includegraphics[scale=1]{\curChapter/fig/polar/sc_colgate/sc_colgate}
  \caption
    [SC ranking of intra-/inter-frame SIMD approaches along 5 metrics.]
    {Ranking of the different approaches along
     5 metrics. In red, inter-frame vectorization performance and in blue,
     intra-frame performance. Solid color is for the dynamic versions and dotted
     is for the generated versions. Each version is positioned along each of the
     5 axes and the best version for one axis is placed further from the
     center.}
  \label{fig:eval_polar_sc_colgate}
\end{figure}

Figure~\ref{fig:eval_polar_sc_colgate} presents a qualitative summary of the
characteristics of the different code versions, for intra-/inter-frame
vectorization, generated or dynamic code. For instance, if the size of
the memory footprint is an essential criterion, the dynamic intra-frame
code exhibits the best performance.

To sum up, the dynamic implementations provides efficient trade-off between
throughput, latency and energy depending on code length. It was demonstrated by
previous benchmarks. Both implementations provide low-energy and low-power
characteristics compared to previous works in the field on x86 processors
\cite{Sarkis2014,Giard2014,Sarkis2014a,LeGal2014,LeGal2015a,Cassagne2015c}.
Whereas the throughput on a single processor core is reduced compared to x86
implementations, ARM\R implementations must fulfil a large set of SDR
applications with limited throughputs and where the power consumption matters.
Finally, it is important to notice that multi-core implementations of the
proposed ARM\R decoders is still possible on these ARM\R targets to improve the
decoding throughputs.

\subsubsection{Source Code Compression for the Generated Decoders}

For generated decoders, the corresponding binary size is linearly increasing
with the codeword size $N$. Beyond a codeword size point which depends on the
architecture and on the selected SIMD version, performance decreases due to L1I
cache misses. Indeed, decoders are generated as straight-line code (no recursive
calls), with all node computations put in sequence. This improves performance
for small to medium codeword size, up to the point where  the compiled binary
exceeds the L1I cache size.
% ---- to remove, already explained in chap 3
We mitigated this issue by reducing decoder binary sizes by applying two
compression techniques: 1) in the generated code, we moved the buffer offsets
from template arguments to function arguments. It enabled the compiler to
factorize more function calls than before, 2) we implemented a sub-tree folding
algorithm in the generator.
% ---- to remove, already explained in chap 3

\begin{table}[htp]
  \centering
  \caption
    [Binary code size (in KB) of the generated SC decoders.]
    {Binary code size (in KB) of the generated decoders depending on the number
     of bits $N$ per frame.}
  \label{tab:eval_polar_sc_gen_l1i_size}
  \begin{tabular}{r r r r r r r}
    \textbf{Decoder}         & $\bm{N = 2^6}$ & $\bm{N = 2^8}$ & $\bm{N = 2^{10}}$ & $\bm{N = 2^{12}}$ & $\bm{N = 2^{14}}$ & $\bm{N = 2^{16}}$           \\
    \hline
    \hline
    inter 32-bit, $R = 1/2$  & 1 (7)          & 2 (24)         & 7 (\textbf{77})   & 9 (\textbf{254})  & 19 (\textbf{736}) & \textbf{40} (\textbf{2528}) \\
    inter 32-bit, $R = 5/6$  & 1 (4)          & 2 (19)         & 4 (\textbf{53})   & 7 (\textbf{167})  & 16 (\textbf{591}) & 32          (\textbf{1758}) \\
    intra 32-bit, $R = 1/2$  & 1 (4)          & 3 (16)         & 9 (\textbf{56})   & 8 (\textbf{182})  & 19 (\textbf{563}) & \textbf{38} (\textbf{1947}) \\
    intra 32-bit, $R = 5/6$  & 1 (3)          & 3 (13)         & 6 (\textbf{38})   & 7 (\textbf{126})  & 20 (\textbf{392}) & 27          (\textbf{1365}) \\
    inter ~8-bit, $R = 1/2$  & 1 (5)          & 2 (22)         & 7 (\textbf{72})   & 8 (\textbf{252})  & 17 (\textbf{665}) & \textbf{36} (\textbf{2220}) \\
    inter ~8-bit, $R = 5/6$  & 1 (4)          & 2 (18)         & 4 (\textbf{51})   & 6 (\textbf{191})  & 14 (\textbf{461}) & 26          (\textbf{1555}) \\
  \end{tabular}
\end{table}

\begin{figure}[htp]
  \centering
  \subfloat[][Without compression]{\includegraphics[width=0.485\textwidth]{\curChapter/fig/polar/sc_gen_l1i_size/sc_gen_l1i_size_wo_comp}\label{plot:eval_polar_sc_gen_l1i_size_wo_comp}}
  \quad
  \subfloat[][With compression]{\includegraphics[width=0.485\textwidth]{\curChapter/fig/polar/sc_gen_l1i_size/sc_gen_l1i_size_w_comp}\label{plot:eval_polar_sc_gen_l1i_size_w_comp}}
  \caption
    {Generated SC decoder binary sizes depending on the frame size
     ($R=1/2$).}
  \label{plot:eval_polar_sc_gen_l1i_size}
\end{figure}

Table~\ref{tab:eval_polar_sc_gen_l1i_size} and
Figure~\ref{plot:eval_polar_sc_gen_l1i_size} illustrate the binary code size of
the decoders depending on $N$. The results which exceed the 32KB of the L1I
cache are highlighted in bold font. A CPU with L1I = 32 KB is supposed, this is
consistent with most of the current CPUs. Sub-tree folding is enabled starting
from $N=2^{12}$ because there is an overhead (at run-time) when using this
technique. The source code is compiled with AVX instructions for the 32-bit
decoders and with SSE4.1 instructions for the 8-bit decoders. \AFFECT decoder
code sizes without compression are shown in parentheses: we can observe a huge
improvement, until $N=2^{14}$ the code size never exceeds the L1I cache anymore.
In~\cite{Giard2016b}, authors report that they can't compile codes longer than
$N = 2^{15}$. The proposed compression technique enables to exceed that limit.
For instance, we were able to generate $N = 2^{20}$ decoders as shown in
Figure~\ref{plot:eval_polar_sc_energy_implems_vs}.

\subsubsection{Comparison with State-of-the-art SC Decoders}

\paragraph{Dynamic Implementation}

\begin{table}[htp]
  \centering
  \caption
    [Comparison of 8-bit fixed-point dynamic SC decoders (intra-frame SIMD).]
    {Comparison of 8-bit fixed-point dynamic SC decoders (intra-frame SIMD).
     $N = 32768$ and $R = 5/6$.}
  \label{tab:eval_polar_energy_comparison}
  \begin{tabular}{r r r r r r}
    \textbf{Ref.}        & \textbf{Platform} & \textbf{Freq.} & \textbf{SIMD} & $\bm{\mathcal{L}}$ & $\bm{\mathcal{T}_i}$ \\
                         &                   &          (GHz) &               &           ($\mu$s) &               (Mb/s) \\
    \hline
    \hline
    \cite{Giard2014}     &           i7-2600 &            3.4 &        SSE4.1 &                135 &                 204  \\
    \cite{Cassagne2016b} &         i7-4850HQ &            3.3 &        SSE4.1 &                 47 &         \textbf{580} \\
    \cite{Cassagne2016b} &             A15-O &            1.1 &          NEON &                391 &                  70  \\
    \cite{Cassagne2016b} &               A57 &            1.1 &          NEON &                374 &                  73  \\
  \end{tabular}
\end{table}

Table~\ref{tab:eval_polar_energy_comparison} shows a performance comparison
(throughput, latency) with the dynamic intra-frame decoder of~\cite{Giard2014}.
On a x86 CPU, our dynamic decoder is 2.8 times faster than the state-of-the-art
decoder. Even if we used a more recent CPU, the same set of instructions
(SSE4.1) is applied and the frequencies are comparable.

\paragraph{Generated Implementation}

\begin{figure}[htp]
  \centering
  \subfloat[][Intel\R Xeon\TM E3-1225 (AVX SIMD)]{\includegraphics[width=0.485\textwidth]{\curChapter/fig/polar/sc_gen_thr_intra/sc_gen_thr_intra_x86}\label{plot:eval_polar_sc_gen_thr_intra_x86}}
  \quad
  \subfloat[][Nvidia\R Jetson TK1 A15 (NEON SIMD)]{\includegraphics[width=0.485\textwidth]{\curChapter/fig/polar/sc_gen_thr_intra/sc_gen_thr_intra_arm}\label{plot:eval_polar_sc_gen_thr_intra_arm}}
  \caption
    [SC performance comparison between two code rates (intra-frame
     vectorization).]
    {Performance comparison between two code rates of 32-bit floating-point
    decoding stages (intra-frame vectorization, generated SC decoders).}
  \label{plot:eval_polar_sc_gen_thr_intra}
\end{figure}

\begin{table}[htp]
  \centering
  \caption
    [Comparing SC generated software decoder with the state-of-art (intra-frame
    SIMD).]
    {Comparing SC with a state-of-art generated software polar decoder, for
     different code sizes, using intra-frame SIMD. The two cross marks show
     state-of-the art performance results reported in~\cite{Sarkis2014}, for
     comparison. The AVX SIMD instructions are applied.}
  \label{tab:eval_polar_sc_gen_thr_comparison}
  \begin{tabular}{r  r r  r  r}
    \textbf{Ref.}        & $\bm{(N, K)}$                   & \textbf{Platform} & $\bm{\mathcal{L}}$ & $\bm{\mathcal{T}_i}$ \\
                         &                                 &                   &           ($\mu$s) &               (Mb/s) \\
    \hline
    \hline
  %%this performance is included in the graphs
  % \cite{Sarkis2014}    & \multirow{2}{*}{(2048, 1024)}   &           i7-2600 &                  7 &                  147 \\
  % \cite{Cassagne2015c} &                                 &           E3-1225 &                  5 &                  195 \\
  % \hline
  %%this performance is included in the graphs
  % \cite{Sarkis2014}    & \multirow{2}{*}{(2048, 1707)}   &           i7-2600 &                  5 &                  335 \\
  % \cite{Cassagne2015c} &                                 &           E3-1225 &                  4 &                  402 \\
  % \hline
    \cite{Sarkis2014}    & \multirow{2}{*}{(16384, 14746)} &           i7-2600 &                 50 &                  292 \\
    \cite{Cassagne2015c} &                                 &           E3-1225 &                 43 &                  341 \\
    \hline
    \cite{Sarkis2014}    & \multirow{2}{*}{(32768, 27568)} &           i7-2600 &                125 &                  220 \\
    \cite{Cassagne2015c} &                                 &           E3-1225 &                114 &                  241 \\
    \hline
    \cite{Sarkis2014}    & \multirow{2}{*}{(32768, 29492)} &           i7-2600 &                113 &                  261 \\
    \cite{Cassagne2015c} &                                 &           E3-1225 &                101 &                  293 \\
  \end{tabular}
\end{table}

\begin{figure}[htp]
  \centering
  \subfloat[][Intel\R Xeon\TM E3-1225 (SSE4.1 SIMD)]{\includegraphics[width=0.485\textwidth]{\curChapter/fig/polar/sc_gen_thr_inter/sc_gen_thr_inter_x86}\label{plot:eval_polar_sc_gen_thr_inter_x86}}
  \quad
  \subfloat[][Nvidia\R Jetson TK1 A15 (NEON SIMD)]{\includegraphics[width=0.485\textwidth]{\curChapter/fig/polar/sc_gen_thr_inter/sc_gen_thr_inter_arm}\label{plot:eval_polar_sc_gen_thr_inter_arm}}
  \caption
    [SC performance comparison between several code rates (inter-frame
     vectorization).]
    {Performance comparison between two code rates of 8-bit fixed-point decoding
     stages (inter-frame vectorization). Squares show AFF3CT generated SC
     decoders results. Circles show the ``handwritten'' implementation results
     from~\cite{LeGal2015a}.}
  \label{plot:eval_polar_sc_gen_thr_inter}
\end{figure}

Figure~\ref{plot:eval_polar_sc_gen_thr_intra} shows \AFFECT intra-frame
throughput on different architectures. Our generic framework performance
outperforms previous works (between 10\% and 25\% higher). This is confirmed in
Table~\ref{tab:eval_polar_sc_gen_thr_comparison} which compares \AFFECT with the
state-of-the-art result samples for some specific code sizes reported
in~\cite{Sarkis2014}. The throughput of the inter-frame implementation is shown
in Figure~\ref{plot:eval_polar_sc_gen_thr_inter} for different architectures.
Again, the results confirm that our generic approach overtakes handwritten code
(also between 10\% and 25\% higher on x86). It worth mentioning that the decoder
from \cite{LeGal2015a} is not generated and can dynamically adapt to various
frame sizes and code rates where our generated decoders cannot. To the best of
our knowledge, there is no other generated implementation with the inter-frame
SIMD strategy in the literature. By design, generated decoders are faster than
the dynamic decoder (up to 20\% on x86-based CPUs). But, it is less clear on
ARM\R-based CPUs.

\subsection{Successive Cancellation List Decoders}

Throughput and latency measurements of the dynamic SCL implementations (see
Section~\ref{sec:opt_polar_scl}) are detailed in this section. The proposed
dynamic decoder implementations are compared with the previous software
decoder implementations. Despite the additional levels of genericity and
flexibility, the proposed software implementation is very competitive with its
counterparts.

\subsubsection{Experimentation Platforms}

During our investigations, all the throughput and latency measurements have been
obtained on a single core of an Intel\R Core\TM i5-6600K CPU (Skylake
architecture with AVX2 SIMD) with a base clock frequency of 3.6 GHz and a
maximum turbo frequency of 3.9 GHz. The description has been compiled on Linux
with the C++ GNU compiler (version 5.4.0) and with the following options:
\verb|-Ofast -march=native -funroll-loops|.

\newpage
\subsubsection{Throughput and Latency of Adaptive SCL Decoders}

\begin{table}[htp]
  \centering
  \caption
    [Throughput comparisons between floating-point and fixed-point A-SSCL
     decoders.]
    {Throughput and latency comparisons between floating-point (32-bit) and
    fixed-point (16-bit and 8-bit) Adaptive SSCL decoders. Code (2048,1723),
    $L = 32$ and 32-bit CRC (Gzip). $\mathcal{L}_\text{avg}$ is in $\mu$s and
    $\mathcal{T}_i$ is in Mb/s.}
  \label{tab:eval_polar_scl_perfs_fixed}
  \begin{tabular}{r  r  r  r  r |  r  r | r  r}
    \multirow{2}{*}{\textbf{Decoder}} & \multirow{2}{*}{\textbf{Prec.}} & \multirow{2}{*}{\shortstack[r]{\textbf{$\bm{\mathcal{L}_\text{worst}}$}\\($\mu$s)}} & \multicolumn{2}{c|}{\textbf{3.5 dB}} & \multicolumn{2}{c|}{\textbf{4.0 dB}} & \multicolumn{2}{c}{\textbf{4.5 dB}} \\
    \cline{4-9}
    & & & \textbf{$\bm{\mathcal{L}_\text{avg}}$} & $\bm{\mathcal{T}_i}$ & \textbf{$\bm{\mathcal{L}_\text{avg}}$} & $\bm{\mathcal{T}_i}$ & \textbf{$\bm{\mathcal{L}_\text{avg}}$} & $\bm{\mathcal{T}_i}$ \\
    \hline
    \hline
    \multirow{3}{*}{PA-SSCL} & 32-bit &  635 & 232.3 &   7.6 & 41.7 &  42.1 & 7.4 & 237.6 \\
                             & 16-bit &  622 & 219.6 &   8.0 & 40.1 &  43.8 & 6.6 & 267.5 \\
                             &  8-bit &  651 & 232.4 &   7.6 & 41.2 &  42.6 & 6.5 & 268.3 \\
    \hline
    \multirow{3}{*}{FA-SSCL} & 32-bit & 1201 &  67.2 &  26.1 &  8.5 & 207.8 & 5.1 & 345.5 \\
                             & 16-bit & 1198 &  68.7 &  25.6 &  7.7 & 225.7 & 4.3 & 408.7 \\
                             &  8-bit & 1259 &  71.8 &  24.4 &  7.7 & 227.3 & 4.1 & 425.9 \\
  \end{tabular}
\end{table}

The property to easily change the list size of the SCL decoders enables the use
of the FA-SSCL algorithm. With an unrolled decoder as proposed
in~\cite{Sarkis2016}, the fully adaptive decoder would imply to generate a fully
unrolled decoder for each value of the list depth. In our approach, only one
source code gives to the designer the possibility to run each variation of the
SCL decoders. FA-SSCL algorithm is the key to achieve the highest possible
throughput. In Table~\ref{tab:eval_polar_scl_perfs_fixed}, maximum latency
($\mathcal{L}_\text{worst}$ in $\mu s$), average latency
($\mathcal{L}_\text{avg}$ in $\mu s$) and information throughput
($\mathcal{T}_i$ in Mb/s) are given. The FER performance of the 32-bit version
of the PA/FA-SSCL decoders as well as the corresponding throughputs can be seen
in Figure~\ref{plot:aff3ct_polar_scl_adaptive}. The 16-bit and 8-bit
implementations have similar decoding performance. Note that in 8-bit
configuration only the \texttt{REP}$_{\texttt{8-}}$ nodes are used. The
fixed-point implementation reduces, on average, the latency. In the high SNR
region, the frame errors are less frequent. Therefore, the SCL algorithm is less
necessary than in low SNR regions for Adaptive SCL algorithms. As the gain of
fixed-point implementation benefits more to the SC algorithm than to the SCL
algorithm, the throughput is higher in high SNR regions. With an 8-bit
fixed-point representation of the decoder inner values, the achieved throughput
in the case of the ($2048$,$1723$) polar code is about $425$ Mb/s on the
i5-6600K for an $E_b/N_0$ value of $4.5$~dB. It corresponds to a FER of
$5\times10^{-8}$. This throughput is almost 2 times higher than the throughput
of the PA-SSCL algorithm. The highest throughput increase from PA-SSCL to
FA-SSCL, of about $380\%$, is in the domain where the FER value is between
$10^{-3}$ and $10^{-5}$. It is the targeted domain for wireless communications
like LTE or 5G standards. In these conditions, the throughput of FA-SSCL
algorithm is about $227$ Mb/s compared to $42$ Mb/s for the PA-SSCL algorithm.

With Adaptive SCL algorithms, the worst case latency is the sum of the latency
of each triggered algorithm. In the case of PA-SSCL with $L_{max}=32$, it is
just the sum of the latency of the SC algorithm, plus the latency of the SCL
algorithm with $L=32$. In the case of the FA-SSCL algorithm, it is the sum of
the decoding latency of the SC algorithm and all the decoding latencies of the
SCL algorithm for $L={2,4,8,16,32}$. This is the reason why the worst latency of
the PA-SSCL algorithm is lower while the average latency. Consequently the
average throughput is better with the FA-SSCL algorithm.

\subsubsection{Comparison with State-of-the-art SCL Decoders}

\begin{table}[htp]
  \centering
  \caption
    [Throughput and latency comparisons with state-of-the-art SCL decoders.]
    {Throughput and latency comparisons with state-of-the-art SCL decoders.
    32-bit floating-point representation. Polar code (2048,1723), $L = 32$,
    32-bit CRC.}
  \label{tab:eval_polar_scl_perfs_comparison}
  \begin{tabular}{r r r r r r r}
    \multirow{2}{*}{\textbf{Ref.}}        & \multirow{2}{*}{\textbf{Target}} & \multirow{2}{*}{\textbf{Decoder}} & \multirow{1}{*}{\textbf{$\bm{\mathcal{L}_\text{worst}}$}} & \multicolumn{3}{c}{$\bm{\mathcal{T}_i}$ (Mb/s)} \\
    \cline{5-7}
                                          &                                  &                                   & ($\mu s$)                         & \textbf{3.5 dB} & \textbf{4.0 dB} & \textbf{4.5 dB} \\
    \hline
    \hline
    \multirow{3}{*}{\cite{Sarkis2014b}}   & \multirow{3}{*}{i7-2600}         & CA-SCL                            & 23000                             &  0.07           &  0.07           &   0.07          \\
                                          &                                  & CA-SSCL                           &  3300                             &  0.52           &  0.52           &   0.52          \\
                                          &                                  & PA-SSCL                           & $\approx$ 3300                    &  0.90           &  4.90           &  54.00          \\
    \hline
    \cite{Shen2016}                       & \multirow{1}{*}{i7-4790K}        & CA-SCL                            &  1572                             &  1.10           &  1.10           &   1.10          \\
    \hline
    \multirow{3}{*}{\cite{Sarkis2016}}    & \multirow{3}{*}{i7-2600}         & CA-SCL                            &  2294                             &  0.76           &  0.76           &   0.76          \\
                                          &                                  & CA-SSCL                           &   433                             &  4.00           &  4.00           &   4.00          \\
                                          &                                  & PA-SSCL                           & $\approx$ 433                     &  8.60           & 33.00           & 196.00          \\
    \hline
%   original data
%   \multirow{4}{*}{\cite{Leonardon2019}} & \multirow{4}{*}{E5-2650}         & CA-SCL                            &  6554                             &  0.27           &   0.27          &   0.27          \\
%                                         &                                  & CA-SSCL                           &  1048                             &  1.67           &   1.67          &   1.67          \\
%                                         &                                  & PA-SSCL                           & $\approx$ 1048                    &  4.07           &  22.90          & 124.10          \\
%                                         &                                  & FA-SSCL                           & $\approx$ 2096                    & 14.30           & 109.80          & 180.00          \\
%   \hline
%   rescaled data from E5-2650
    \multirow{4}{*}{\cite{Leonardon2019}} & \multirow{4}{*}{i7-2600}         & CA-SCL                            &  4819                             &  0.37           &   0.37          &   0.37          \\
                                          &                                  & CA-SSCL                           &   770                             &  2.30           &   2.30          &   2.30          \\
                                          &                                  & PA-SSCL                           &   847                             &  5.50           &  31.10          & 168.40          \\
                                          &                                  & FA-SSCL                           &  1602                             & 19.40           & 149.00          & 244.30          \\
    \hline
    \multirow{4}{*}{\cite{Leonardon2019}} & \multirow{4}{*}{i5-6600K}        & CA-SCL                            &  3635                             &  0.48           &   0.48          &   0.48          \\
                                          &                                  & CA-SSCL                           &   577                             &  3.00           &   3.00          &   3.00          \\
                                          &                                  & PA-SSCL                           &   635                             &  7.60           &  42.10          & 237.60          \\
                                          &                                  & FA-SSCL                           &  1201                             & 26.10           & 207.80          & 345.50          \\
  \end{tabular}
\end{table}

The throughput and latency of the proposed decoder compared to other reported
implementations are detailed in Table~\ref{tab:eval_polar_scl_perfs_comparison}.
For all the decoders, all the available tree pruning optimizations are applied
excluding the $\texttt{SPC}_\texttt{4+}$ nodes because of the performance
degradation. Each decoder is based on a 32-bit floating-point representation.
The polar code parameters are $N=2048$, $K=1723$ and the 32-bit GZip CRC is
applied. The list size is $L=32$.

The latency given in Table~\ref{tab:eval_polar_scl_perfs_comparison} is the
worst case latency. The throughput is the average information throughput. The
first version, CA-SCL, is the implementation of the CA-SCL algorithm without any
tree pruning. As mentioned before the throughput of the proposed CA-SSCL decoder
($2.3$ Mb/s) is only halved compared to the specific unrolled CA-SSCL decoder
(4.0 Mb/s) described in~\cite{Sarkis2016}. The proposed CA-SSCL decoder is
approximately 4 times faster than the generic implementation ($0.52$ Mb/s)
in~\cite{Sarkis2014b} and 2 times faster than the CA-SCL implementation
($1.1$ Mb/s) in~\cite{Shen2016}  thanks to the implementation improvements
detailed in Section~\ref{sec:opt_polar_scl}. Furthermore, the proposed decoder
exhibits a much deeper level of genericity and flexibility than the ones
proposed in~\cite{Sarkis2014,Shen2016}. Indeed, the following features are not
enabled: the customization of the tree pruning, the 8-bit and 16-bit fixed-point
representations of the LLRs, the puncturing patterns and the FA-SSCL algorithm.

When implemented on the same target (i7-2600), the proposed PA-SSCL is
competitive with the unrolled PA-SSCL in~\cite{Sarkis2016}, being only two times
slower. This can be explained by the improvements concerning the CRC that are
described in Section \ref{sec:opt_polar_scl_crc}, especially the information
bits extraction in the SC decoder. Finally, as mentioned before, the throughput
of the proposed FA-SSCL significantly outperforms all the other SCL decoders (up
to 345.5 Mb/s at 4.5 dB in 32-bit floating-point).

% \newpage
\section{Turbo Decoders}
\label{sec:eval_turbo}

In this section we propose to evaluate the turbo EML-MAP decoder presented in
Section~\ref{sec:opt_turbo_implem}. The decoder throughput is benched on middle
and high-end x86 CPUs. Then, the energy efficiency of the proposed decoder is
studied. Finally, it is compared with the state-of-the-art decoders.

\subsection{Experimentation Platforms}

\begin{table}[htp]
  \centering
  \caption
    [Specifications of the target processors for the turbo decoder experiments.]
    {Specifications of the target processors.}
  {\resizebox{\linewidth}{!}{
  \begin{tabular}{c | c  c  c}
                         & \textbf{E5-2650}          & \textbf{i7-4960HQ}        & \textbf{E5-2680 v3}        \\
    \hline
    \hline
    \textbf{CPU}         & Intel\R Xeon\TM E5-2650   & Intel\R Core\TM i7-4960HQ & Intel\R Xeon\TM E5-2680 v3 \\
    \textbf{Cores/Freq.} & 8 cores, 2--2.8 GHz       & 4 cores, 2.6--3.8 GHz     & 12 cores,  2.5--3.3 GHz    \\
    \textbf{Arch.}       & \textit{Ivy Bridge} Q1'12 & \textit{Haswell} Q4'13    & \textit{Haswell} Q3'14     \\
    \textbf{LLC}         & 20 MB L3                  & 6 MB L3                   & 30 MB L3                   \\
    \textbf{TDP}         & 95 W                      & 47 W                      & 120 W                      \\
  \end{tabular}
  }}
  \label{tab:eval_turbo_specs}
\end{table}

The experiments have been conducted on three different x86-based processors
detailed in Table~\ref{tab:eval_turbo_specs}. A mid-range processor (i7-4960HQ)
is used for comparison with similar CPU targets in the
literature~\cite{Huang2011,Zhang2012,Wu2013}. The two high-end processors
(E5-2650 and E5-2680 v3) are used for multi-threading benchmarking. Indeed,
E5-2650 and E5-2680 v3 are potentially good candidates for C-RAN servers.
Moreover, the code has been compiled with the GNU compiler (version 4.8) and
with the \verb|-Ofast -funroll-loops -msse4.1/-mavx2| options.

\subsection{Throughput Performance on Multi-core CPUs}

\begin{figure}[htp]
  \centering
  \includegraphics[width=0.90\textwidth]{\curChapter/fig/turbo/thr/thr}
  \caption
    [Information throughput of the turbo decoder depending on $K$.]
    {Information throughput depending on $K$ for various number of cores and
    SIMD instruction types. 6 iterations, 8-bit fixed-point.}
  \label{plot:eval_turbo_thr}
\end{figure}

Figure~\ref{plot:eval_turbo_thr} shows the evolution of the information
throughput depending on the code dimension $K$. This experiment was conducted on
i7-4960HQ and E5-2680 v3 (both have \emph{Haswell} architectures). The
throughput tends to increase linearly with the number of cores (up to 24 cores)
except in AVX mode where a performance drop can be observed when $K > 4096$. The
reason is that the AVX instructions use vectors $2\times$ wider than those used
by SSE instructions. The inter-frame strategy loads twice the number of frames
to fill these vectors. Thus, for $K > 4096$, in AVX, the memory footprint
exceeds the L3 cache occupancy. Consequently, the performance is driven by the
RAM bandwidth. Then, as $K$ increases the number of RAM accesses increases.
There is not enough memory bandwidth to feed all the cores. This explains the
decreasing throughput for $K > 4096$, in AVX mode. Nonetheless, on E5-2680~v3
target, the throughput exceeds 1 Gbps for all codes with $K<4096$.

\subsection{Energy Efficiency on a Multi-core CPU}

\begin{figure}[htp]
  \centering
  \includegraphics[width=0.7\textwidth]{\curChapter/fig/turbo/energy/energy}
  \caption
    [Turbo decoder \emph{energy-per-bit} depending on the number of cores.]
    {\emph{Energy-per-bit} ($E_d$) depending on the number of cores and the
    instruction types. 6 iterations, 8-bit fixed-point.}
  \label{plot:eval_turbo_energy}
\end{figure}

Figure~\ref{plot:eval_turbo_energy} shows the energy consumed by the processor
to decode one information bit ($E_d$) of the codes using SSE and AVX
instructions on the i7-4960HQ CPU target. The throughput and power measurements
were conducted on i7-4960HQ with the \emph{Intel\R Power Gadget} tool. For small
codewords ($K=1024$) it is more energy efficient to resort to AVX. But this is
not so clear on larger codewords ($K=6144$) since with 3/4 cores, the code using
SSE outperforms the AVX one.

\subsection{Comparison with State-of-the-art Turbo Decoders}

\begin{table}[htp]
  \renewcommand{\arraystretch}{1.2}
  \centering
  \caption
    [Comparison of the proposed turbo decoder with the state-of-art.]
    {Comparison of the proposed turbo decoder with the state-of-art.
     EML-MAP decoder ($\alpha = 0.75)$. Code from the LTE standard, $K = 6144$
     and $R = 1/3$.
     $\mathcal{NT}_i = (\mathcal{T}_i \times i) / (\text{Cores} \times 6)$.}
  \label{tab:eval_turbo_comparison}
  \checkoddpage
  {\resizebox{1.00\textwidth}{!}{
  \begin{tabular}{r r r r r r r r r r r r}
  \multicolumn{1}{r}{\textbf{Ref.}} & \textbf{Platform}   & \textbf{Cores} & \textbf{SIMD} & \textbf{Pre.} & \textbf{Inter} & $\bm{i}$ & \textbf{BER} & \textbf{FER}     & $\bm{\mathcal{L}}$    & $\bm{\mathcal{T}_i}$   & $\bm{\mathcal{NT}_i}$ \\
  \multicolumn{1}{r}{}              &                     &                & (length)      & (bit)         & (level)        &          & \multicolumn{2}{c}{(at 0.7 dB)} & ($\mu$s)              & (Mb/s)                 & (Mb/s)                \\
  \hline
  \hline
  \cite{Zhang2012}                  & X5670               & 6              & 16            &  8           & 6               & 3        & 6e-02        &     -            &                  157  &                 222.6  &   18.6                \\
  \cite{Wu2013}                     & i7-3770K            & 4              &  8            & 16           & 4               & 6        &     -        & 1e-01            &                  323  &                  76.2  &   19.1                \\
  \cite{Cassagne2016a}              & E5-2650             & 8              &  8            & 16           & 64              & 6        & 6e-06        & 5e-03            &                 3665  &                 107.3  &   13.4                \\
  \cite{Cassagne2016a}              & i7-4960HQ           & 4              &  8            & 16           & 32              & 6        & 6e-06        & 5e-03            &                 2212  &                  88.9  &   22.2                \\
  \cite{Cassagne2016a}              & $2\times$E5-2680 v3 & 24             &  8            & 16           & 192             & 6        & 6e-06        & 5e-03            &                 2657  &                 443.7  &   18.5                \\
  \cite{Cassagne2016a}              & E5-2650             & 8              & 16            &  8           & 128             & 6        & 5e-05        & 4e-02            &                 3492  &                 225.2  &   28.2                \\
  \cite{Cassagne2016a}              & i7-4960HQ           & 4              & 16            &  8           & 64              & 6        & 5e-05        & 4e-02            &                 2837  &                 138.6  &   34.7                \\
  \cite{Cassagne2016a}              & $2\times$E5-2680 v3 & 24             & 16            &  8           & 384             & 6        & 5e-05        & 4e-02            &                 3293  &                 716.4  &   29.9                \\
  \cite{LeGal2019a}                 & $2\times$E5-2680 v3 & 24             & 32            &  8           & 24              & 6        & 1e-03        & 3e-01            &                   84  &                1735.0  &   72.3                \\
  \end{tabular}
  }}
\end{table}

Table~\ref{tab:eval_turbo_comparison} shows a performance comparison with
related works. \emph{SIMD} is the number of elements that can be computed in
parallel in one SIMD instruction. \emph{Pre.} is the precision of LLRs in bits.
\emph{Inter} is the number of frames computed in parallel. \emph{i} is the
number of turbo decoding iterations. \emph{BER} and \emph{FER} are the decoding
performance of the decoder at 0.7 dB. $\mathcal{L}$ is the decoder latency.
$\mathcal{T}_i$ is the information throughput of the decoder and
$\mathcal{NT}_i$ is the normalized information throughput: this metric considers
6 iterations on a single core. It enables to directly compare the throughput of
the listed decoders. The FER performance of the proposed decoders are shown in
Figure~\ref{plot:aff3ct_turbo_quantization}. One can note that using the 8-bit
decoder leads to BER/FER degradations.

The variety of CPU targets and algorithmic parameters enables to
show some global emerging trends. When comparing to similar CPU
targets~\cite{Zhang2012,Wu2013}, the proposed implementation reaches similar or
higher throughput (from 88.9 Mbps to 138.6 Mbps on i7-4960HQ target) at the
price of an latency increase (from 2212 $\mu$s to 2837 $\mu$s) and additional
memory footprint. The implementation from~\cite{LeGal2019a} outperforms the
throughput (up to 2,5 times higher) and the latency performance of our proposed
decoder on the E5-2680 v3 target. The other works~\cite{Zhang2012,Wu2013,
LeGal2019a} are based on the intra-frame SIMD strategy. It results in
significantly reduced latencies compared to the proposed implementation. The
intra-frame implementations use less memory than the inter-frame strategy. It is
possible to take advantage of wider SIMD instructions for the selected code. It
mainly explains the throughput performance difference between the proposed
implementation and the implementation from~\cite{LeGal2019a}. Moreover, the
decoder has been specialized for the LTE interleaver. However in the LTE
standard, the EML-MAP turbo decoder comes with a limited inherent parallelism of
8 (corresponding to the 8 trellis states). To fill the SIMD registers, the
intra-frame implementations require to modify the algorithm to introduce more
parallelism. This modification leads to non-negligible decoding performance
losses. At 0.7 dB, none of the state-of-the-art implementations are able to
match the reference decoding performance of the EML-MAP algorithm except our
proposed implementation in 16-bit. Even considering our 8-bit implementation,
none of the other works are reaching the same level of decoding performance.

To summarize, the proposed implementation comes with a throughput approaching to
the best implementations ($\approx$ two times slower) while the latency is still
very high compared to the intra-frame decoders. One of the main advantage of the
proposed implementation is its flexibility. Indeed, it can be run on 32-bit
floating-point and 16/8-bit fixed-point. There is also a unique source code
description for the SSE, AVX, AVX-512 and NEON instructions. As it has been
shown before, this is valuable because depending on the codeword size, the CPU
and the number of cores assigned, the throughput and latency performance can be
more interesting on one or the other of the SIMD engine. Moreover, the proposed
implementation is able to reach the reference decoding performance in 16-bit.
In 8-bit, there is contained decoding performance degradations compared to the
other works in the literature.

% \newpage
\section{FEC Software Decoders Hall of Fame}
\label{sec:eval_hof}

\begin{table}[htp]
  \renewcommand{\arraystretch}{1.2}
  \centering
  \caption{LDPC Software Decoders Hall of Fame.}
  \label{tab:eval_ldpc_hof}
  \checkoddpage
  \ifthenelse{\boolean{twosidedoc}}
  {\begin{adjustbox}{angle=\ifoddpage 90\else -90\fi}}
  {\begin{adjustbox}{angle=90}}
  {\resizebox{0.95\textheight}{!}{
  \begin{tabular}{|r|r r|r r r r r r|r r r|r r r r r r|r r|r r r|}
  \hline
  \multicolumn{3}{|c|}{\multirow{2}{*}{}} & \multicolumn{6}{c|}{\multirow{2}{*}{\textbf{Hardware specifications}}} & \multicolumn{3}{c|}{\multirow{2}{*}{\textbf{Code}}} & \multicolumn{6}{c|}{\multirow{2}{*}{\textbf{Decoder parameters}}} & \multicolumn{2}{c|}{\multirow{2}{*}{\textbf{Decoding perf.}}} & \multicolumn{3}{c|}{\multirow{2}{*}{\textbf{Metrics}}} \\
  \multicolumn{3}{|c|}{}                  & \multicolumn{6}{c|}{}                                                  & \multicolumn{3}{c|}{}                               & \multicolumn{6}{c|}{}                                             & \multicolumn{2}{c|}{}                                         & \multicolumn{3}{c|}{}                                  \\
  \hline
  \multicolumn{2}{|r}{\textbf{Work}}                                                   & \textbf{Year} & \textbf{Platform} & \textbf{Arch.}     & \textbf{TDP} & \textbf{Cores}      & \textbf{SIMD} & \textbf{Freq.} & $\bm{(N,K)}$       & \textbf{Std.}     & \textbf{\# of} & \textbf{Sche-}  & \textbf{Early} & \textbf{Up.}   & \textbf{Pre.} & $\bm{F}$       & $\bm{i}$ & $\bm{\mathcal{L}}$       & $\bm{\mathcal{T}_c}$     & $\bm{\mathcal{NT}_c}$ & \textbf{TNDC} & $\boldsymbol{E_d}$ \\
  \multicolumn{2}{|r}{}                                                                &               &                   &                    & (W)          & (or SM)             & (length)      & (GHz)          &                    &                   & \textbf{Edges} & \textbf{duling} & \textbf{T.}    & \textbf{Rules} & (bit)         & (inter)        &          & ($\mu$s)                 & (Mb/s)                   & (Mb/s)                &               & (nJ)               \\
  \hline
  \hline
  \multirow{21}{*}{\rotatebox[origin=c]{90}{\textbf{GPU-based}}} & \cite{Wang2008}     & 2008          & 8800 GT           & \textit{Tesla}     &          105 &                  7  &  16           & 1.50           & $(  4096,   2048)$ &                 - &   6144         & BP-F            & yes            &  SPA           & 32            &     1          &   6      &                  467000  &                    0.01  &    0.001              & 0.000006      &  105000000         \\
                                                                 & \cite{Falcao2009}   & 2009          & 8800 GTX          & \textit{Tesla}     &          176 &                  8  &  16           & 1.35           & $(  1908,   1696)$ &                 - &   7632         & BP-F            &  no            &  SPA           & 32            &     -          &  50      &                       -  &                    0.08  &    0.080              & 0.000500      &    2200000         \\
                                                                 & \cite{Falcao2011a}  & 2011          & 8800 GTX          & \textit{Tesla}     &          176 &                  8  &  16           & 1.35           & $(  8000,   4000)$ &                 - &  24000         & BP-F            &  no            &  SPA           &  8            &     -          &  50      &                       -  &                   10.10  &   10.100              & 0.058000      &      17426         \\
                                                                 & \cite{Falcao2011}   & 2011          & Tesla C2050       & \textit{Fermi}     &          247 &                 14  &  32           & 1.15           & $( 64800,  21600)$ &            DVB-S2 & 216000         & BP-F            &  no            &   MS           &  8            &    16          &  30      &                   13275  &                   78.10  &   46.860              & 0.091000      &       5271         \\
                                                                 & \cite{Wang2011}     & 2011          & GTX 470           & \textit{Fermi}     &          215 &                 14  &  32           & 1.22           & $(  1944,    972)$ &           802.11n &   6804         & BP-F            & yes            & LSPA           & 32            &   300          &  50      &                   57743  &                   10.10  &   10.100              & 0.018000      &      21287         \\
                                                                 & \cite{Ji2011}       & 2011          & GTX 285           & \textit{Tesla}     &          204 &                 15  &  16           & 1.48           & $(  2304,   1152)$ &           802.16e &   7296         & BP-F            & yes            &  SPA           & 32            &     1          &  15      &                    1097  &                    2.10  &    0.630              & 0.001800      &     323810         \\
                                                                 & \cite{Chang2011}    & 2011          & Tesla C1060       & \textit{Tesla}     &          200 &                 15  &  16           & 1.30           & $(  8000,   4000)$ &                 - &  32000         & BP-F            &  no            & LSPA           & 32            &     1          &  50      &                    8638  &                    0.92  &    0.920              & 0.002900      &     217391         \\
                                                                 & \cite{Wang2011a}    & 2011          & GTX 470           & \textit{Fermi}     &          215 &                 14  &  32           & 1.22           & $(  2304,   1152)$ &           802.16e &   7296         & BP-F            &  no            & LSPA           & 32            &   224          &  10      &                   10533  &                   49.00  &    9.800              & 0.018000      &      21939         \\
                                                                 & \cite{Kang2012}     & 2012          & GTX 480           & \textit{Fermi}     &          250 &                 15  &  32           & 1.40           & $(  2048,   1723)$ &           802.3an &  12288         & BP-F            & yes            &  SPA           & 32            &     1          &  50      &                     426  &                    4.80  &    4.800              & 0.007100      &      52083         \\
                                                                 & \cite{Falcao2012}   & 2012          & HD 5870           & \textit{Cypress}   &          188 &                 20  &  20           & 1.20           & $(  8000,   4000)$ &                 - &      -         & BP-F            &  no            &   MS           &  8            &   500          &  10      &                   22222  &                  180.00  &   36.000              & 0.075000      &       5222         \\
                                                                 & \cite{Falcao2012}   & 2012          & Tesla C2050       & \textit{Fermi}     &          247 &                 14  &  32           & 1.15           & $(  8000,   4000)$ &                 - &      -         & BP-F            &  no            &   MS           &  8            &   500          &  10      &                   20000  &                  200.00  &   40.000              & 0.078000      &       6175         \\
                                                                 & \cite{Gronroos2012} & 2012          & Tesla C2050       & \textit{Fermi}     &          247 &                 14  &  32           & 1.15           & $( 16200,   8100)$ &            DVB-T2 &  48599         & BP-F            &  no            &   MS           &  8            &   128          &  50      &                   26083  &                   79.50  &   79.500              & 0.154000      &       3107         \\
                                                                 & \cite{Li2013}       & 2013          & GTX 580           & \textit{Fermi}     &          244 &                 16  &  32           & 1.54           & $(  2304,   1152)$ &           802.16e &   7296         & BP-CL           &  no            &   MS           &  8            &  1024          &   5      &                    3322  &                  710.20  &  142.000              & 0.180000      &       1718         \\
                                                                 & \cite{Wang2013}     & 2013          & GTX TITAN         & \textit{Kepler}    &          250 &                 14  & 192           & 0.84           & $(  2304,   1152)$ &           802.16e &   7296         & BP-F            & yes            &  NMS           & 32            &    50          &  10      &                    1266  & {\color{Paired-7}304.20} &   60.800              & 0.027000      &       4112         \\
                                                                 & \cite{Wang2013}     & 2013          & GTX TITAN         & \textit{Kepler}    &          250 &                 14  & 192           & 0.84           & $(  2304,   1152)$ &           802.16e &   7296         & BP-F            & yes            &  NMS           & 32            &     6          &  10      &                     207  &                   66.80  &   13.400              & 0.006000      &      18657         \\
                                                                 & \cite{Lin2014a}     & 2014          & GTX 660 Ti        & \textit{Kepler}    &          150 &                  7  & 192           & 0.92           & $(  8000,   4000)$ &                 - &  24000         & BP-F            &  no            &  SPA           &  8            & 12544          &  50      & {\color{Paired-3}954100} &                  105.20  &  105.200              & 0.085000      &       1426         \\
                                                                 & \cite{LeGal2014a}   & 2014          & GTX 660           & \textit{Kepler}    &          140 &                  5  & 192           & 0.98           & $(  1944,    972)$ &           802.11n &   6804         & BP-HL           &  no            &  OMS           &  8            & 16384          &  10      & {\color{Paired-3} 34362} &                  926.90  &  185.400              & 0.049000      &        755         \\
                                                                 & \cite{Lai2016}      & 2016          & GTX 470           & \textit{Fermi}     &          215 &                 14  &  32           & 1.22           & $(  1944,    972)$ &           802.11n &   6804         & BP-PL           &  no            &   MS           & 32            &   256          &  10      & {\color{Paired-3}  9739} &                   51.10  &   10.200              & 0.019000      &      21078         \\
                                                                 & \cite{Keskin2017b}  & 2017          & GTX TITAN X       & \textit{Pascal}    &          250 &                 28  & 128           & 1.42           & $(  1944,    972)$ &           802.11n &   6804         & BP-F            &  no            &   MS           & 32            &     1          &  10      & {\color{Paired-3}     2} &                  913.00  &  182.600              & 0.036000      &       1369         \\
                                                                 & \cite{Keskin2017a}  & 2017          & GTX TITAN X       & \textit{Pascal}    &          250 &                 28  & 128           & 1.42           & $(  1944,    972)$ &           802.11n &   6804         & BP-F            &  no            &   MS           & 32            &    28          &  10      & {\color{Paired-3}    33} &                 1660.00  &  332.000              & 0.065000      &        753         \\
                                                                 & \cite{Kun2018}      & 2018          & GTX TITAN Xp      & \textit{Pascal}    &          250 &                 30  & 128           & 1.58           & $( 64800,  21600)$ &            DVB-S2 & 216000         & BP-F            & yes            &  OMS           & 32            &     1          &  50      & {\color{Paired-3}   405} &                  160.00  &  160.000              & 0.026000      &       1563         \\
  \hline
  \hline
  \multirow{14}{*}{\rotatebox[origin=c]{90}{\textbf{CPU-based}}} & \cite{Falcao2008}   & 2008          & CELL/BE           & \textit{CELL}      &          200 &                  6  &  16           & 3.30           & $(  1248,    624)$ &           802.16e &      -         & BP-F            &  no            &   MS           &  8            &    96          &  25      &                    3653  &                   32.80  &   16.400              & 0.052000      &       6098         \\
                                                                 & \cite{Falcao2011a}  & 2011          & CELL/BE           & \textit{CELL}      &          200 &                  6  &   4           & 3.30           & $(  1024,    512)$ &                 - &   3072         & BP-F            &  no            &  SPA           & 32            &    24          &  50      &                    1719  &                   14.30  &   14.300              & 0.181000      &      13986         \\
                                                                 & \cite{Falcao2011a}  & 2011          & 2xE5530           & \textit{Nehalem}   &          160 &                  8  &   4           & 2.40           & $(  8000,   4000)$ &                 - &  24000         & BP-F            &  no            &  SPA           & 32            &     1          &  50      &                   13115  &                    0.61  &    0.610              & 0.007900      &     262295         \\
                                                                 & \cite{Zhao2011}     & 2011          & CELL/BE           & \textit{CELL}      &          200 &                  8  &  16           & 3.20           & $(   960,    480)$ &           802.16e &      -         & BP-F            &  no            &  OMS           &  8            &     1          &  15      &                      74  &                   13.00  &    3.900              & 0.009500      &      51282         \\
                                                                 & \cite{Gronroos2012} & 2012          & i7-950            & \textit{Nehalem}   &          130 &                  4  &  16           & 3.06           & $( 16200,   8100)$ &            DVB-T2 &  48599         & BP-F            &  no            &   MS           &  8            &   128          &  50      &                  113934  &                   18.20  &   18.200              & 0.093000      &       7143         \\
                                                                 & \cite{Pan2013}      & 2013          & i7-3960X          & \textit{S. Bridge} &          130 &                  6  &  16           & 3.30           & $(  9216,   4608)$ &              CMMB &  27648         & BP-F            & yes            &  NMS           &  8            &    12          &  10      &                    1202  &                   92.00  &   18.400              & 0.058000      &       7065         \\
                                                                 & \cite{Han2013}      & 2013          & i7-2600K          & \textit{S. Bridge} &          130 & {\color{Paired-1}4} &  16           & 3.40           & $(524280, 262140)$ &           802.11n &      -         & BP-L            &  no            &  OMS           &  8            &     1          &   5      &                   17420  &                   30.10  &    3.000              & 0.055000      &      31667         \\
                                                                 & \cite{Gronroos2013} & 2013          & Cortex-A9         & \textit{ARMv7}     &  $\approx~$4 &                  4  &  16           & 1.60           & $( 16200,   8100)$ &            DVB-T2 &  48599         & BP-F            &  no            &   MS           &  8            &   128          &  20      &                  592457  &                    3.50  &    1.400              & 0.014000      &       2857         \\
                                                                 & \cite{Debbabi2016}  & 2016          & i7-4960HQ         & \textit{Haswell}   &           47 &                  4  &   8           & 3.40           & $(  2304,   1152)$ &           802.16e &   7296         & LP-F            &  no            & ADMM           & 32            &     4          &   8      &                    1511  &                    6.10  &    0.980              & 0.009000      &      47959         \\
                                                                 & \cite{Debbabi2016a} & 2016          & i7-4960HQ         & \textit{Haswell}   &           47 &                  4  &   8           & 3.40           & $(  2304,   1152)$ &           802.16e &   7296         & LP-HL           &  no            & ADMM           & 32            &    32          & 100      &                   13755  &                    5.40  &   10.800              & 0.099000      &       4352         \\
                                                                 & \cite{LeGal2016}    & 2016          & i7-4960HQ         & \textit{Haswell}   &           47 &                  4  &  32           & 3.40           & $(  2304,   1152)$ &           802.16e &   7296         & BP-HL           & yes            &  NMS           &  8            &   128          &  50      &                    1359  &                  217.00  &  217.000              & 0.500000      &        217         \\
                                                                 & \cite{LeGal2017}    & 2017          & i7-5650U          & \textit{Broadwell} & $\approx~$10 &                  2  &  32           & 3.00           & $(  2304,   1152)$ &           802.16e &   7296         & BP-HL           & yes            &  OMS           &  8            &     2          &  10      &                      12  &                  385.00  &   77.000              & 0.401000      &        123         \\
                                                                 & \cite{Grayver2019}  & 2019          & 2xEPYC 7351       & \textit{Zen}       &          340 &                 32  &  16           & 2.40           & $( 64800,  32400)$ &            DVB-S2 & 226799         & BP-HL           & yes            &  OMS           &  8            &   512          &  20      &                   18432  &                 1800.00  &  720.000              & 0.586000      &        472         \\
                                                                 & \cite{Xu2019}       & 2019          & Gold 6154         & \textit{Skylake}   &          200 &                 18  &  64           & 3.00           & $(  9126,   8448)$ &                5G &      -         & BP-HL           & yes            &  OMS           &  8            &    18          &  10      &                      31  &                 4892.40  &  978.500              & 0.283000      &        204         \\
                                                                 & This work           & 2020          & Platinum 8168     & \textit{Skylake}   &          205 &                 24  &  32           & 2.70           & $(  2304,   1152)$ &           802.16e &   7296         & BP-HL           & yes            &  NMS           & 16            &   768          &  50      &                    2637  &                  671.04  &  671.040              & 0.323600      &        305         \\
                                                                 & This work           & 2020          & EPYC 7452         & \textit{Zen 2}     &          155 &                 32  &  16           & 2.35           & $(  2304,   1152)$ &           802.16e &   7296         & BP-HL           & yes            &  NMS           & 16            &   512          &  50      &                    1368  &                  862.08  &  862.080              & 0.716500      &        180         \\
  \hline
  \end{tabular}
  }}
  \end{adjustbox}
\end{table}

\begin{table}[htp]
  \renewcommand{\arraystretch}{1.2}
  \centering
  \caption{Polar Software Decoders Hall of Fame.}
  \label{tab:eval_polar_hof}
  \checkoddpage
  \ifthenelse{\boolean{twosidedoc}}
  {\begin{adjustbox}{angle=\ifoddpage 90\else -90\fi}}
  {\begin{adjustbox}{angle=90}}
  {\resizebox{0.95\textheight}{!}{
  \begin{tabular}{|r|r r|r r r r r r|r r|r r r r|r r|r r r|}
  \hline
  \multicolumn{3}{|c|}{\multirow{2}{*}{}} & \multicolumn{6}{c|}{\multirow{2}{*}{\textbf{Hardware specifications}}} & \multicolumn{2}{c|}{\multirow{2}{*}{\textbf{Code}}} & \multicolumn{4}{c|}{\multirow{2}{*}{\textbf{Decoder parameters}}} & \multicolumn{2}{c|}{\multirow{2}{*}{\textbf{Decoding perf.}}} & \multicolumn{3}{c|}{\multirow{2}{*}{\textbf{Metrics}}} \\
  \multicolumn{3}{|c|}{}                  & \multicolumn{6}{c|}{}                                                  & \multicolumn{2}{c|}{}                               & \multicolumn{4}{c|}{}                                             & \multicolumn{2}{c|}{}                                         & \multicolumn{3}{c|}{}                                  \\
  \hline
  \multicolumn{2}{|r}{\textbf{Work}}                                                    & \textbf{Year} & \textbf{Platform}  & \textbf{Arch.}     & \textbf{TDP} & \textbf{Cores}      & \textbf{SIMD} & \textbf{Freq.} & $\bm{N}$ & $\bm{R}$ & \textbf{Algorithm} & \textbf{Pre.} & $\bm{F}$                 & $\bm{i}$/$\bm{L}$ & $\bm{\mathcal{L}}$     & $\bm{\mathcal{T}_i}$      & $\bm{\mathcal{NT}_i}$ & \textbf{TNDC} & $\boldsymbol{E_d}$ \\
  \multicolumn{2}{|r}{}                                                                 &               &                    &                    & (W)          & (or SM)             & (length)      & (GHz)          &          &          &                    & (bit)         & (inter)                  &                   & ($\mu$s)               & (Mb/s)                    & (Mb/s)                &               & (nJ)               \\
  \hline
  \hline
  \multirow{ 5}{*}{\rotatebox[origin=c]{90}{\textbf{GPU-based}}} & \cite{Giard2016b}    & 2016          & Tesla K20c         & \textit{Kepler}    &         225  & 13                  & 192           & 0.71           &  4096    & 0.90     &      SSC           & 32            &                   832  &  1                &                    9400  & {\color{Paired-7}1043.00} & 1043.00               &  0.5890        &    216             \\
                                                                 & \cite{Li2016b}       & 2016          & Tesla K20c         & \textit{Kepler}    &         225  & 13                  & 192           & 0.71           &   256    & 0.50     &      SSC           & 32            &                     -  &  1                &                       -  &                   395.00  &  395.00               &  0.2230        &    570             \\
                                                                 & \cite{Cammerer2017}  & 2017          & GTX 980 Ti         & \textit{Maxwell}   &         250  & 22                  & 128           & 1.00           &  4096    & 0.50     & BP+CA-SCL          & 32            &    {\color{Paired-9}5} & 32                &                 1000000  &                     0.01  &    0.32               &  0.0001        & 781250             \\
                                                                 & \cite{Han2017}       & 2017          & GTX 980            & \textit{Maxwell}   &         165  & 16                  & 128           & 1.17           &  4096    & 0.50     &       SCL          & 32/16         & {\color{Paired-9}1310} & 32                & {\color{Paired-3}111900} &                    24.00  &  768.00               &  0.3205        &    215             \\
                                                                 & \cite{Han2017}       & 2017          & GTX TITAN X        & \textit{Maxwell}   &         250  & 24                  & 128           & 1.00           &  4096    & 0.50     &       SCL          & 32/16         & {\color{Paired-9}1918} & 32                & {\color{Paired-3}126700} &                    31.00  &  992.00               &  0.3229        &    252             \\
  \hline
  \hline
  \multirow{17}{*}{\rotatebox[origin=c]{90}{\textbf{CPU-based}}} & \cite{Giard2014}     & 2014          & i7-2600            & \textit{S. Bridge} &          95  & {\color{Paired-1}4} &   8           & 3.40           & 32768    & 0.84     &      SSC           & 32            &                     1  &  1                &                     223  &                   123.70  &  123.70               &  4.5480        &    768             \\
                                                                 & \cite{Giard2014}     & 2014          & i7-2600            & \textit{S. Bridge} &          95  & {\color{Paired-1}4} &  16           & 3.40           & 32768    & 0.84     &      SSC           &  8            &                     1  &  1                &                     135  &                   203.60  &  203.60               &  3.7430        &    467             \\
                                                                 & \cite{LeGal2014}     & 2014          & Cortex-A9          & \textit{ARMv7}     & $\approx~$3  & {\color{Paired-1}4} &  16           & 1.30           & 32768    & 0.90     &      SSC           &  8            &                    16  &  1                &                   16852  &                    28.00  &   28.00               &  1.3460        &    107             \\
                                                                 & \cite{Sarkis2014b}   & 2014          & i7-2600            & \textit{S. Bridge} &          95  & {\color{Paired-1}4} &   8           & 3.40           &  2048    & 0.84     &   CA-SSCL          & 32            &                     1  & 32                &                    3300  &                     0.52  &   16.64               &  0.5882        &   5709             \\
                                                                 & \cite{Sarkis2014}    & 2014          & i7-2600            & \textit{S. Bridge} &          95  & {\color{Paired-1}4} &   8           & 3.40           & 32768    & 0.84     &      SSC           & 32            &                     1  &  1                &                     125  &                   219.80  &  219.80               &  8.0810        &    432             \\
                                                                 & \cite{LeGal2015a}    & 2015          & i7-4960HQ          & \textit{Haswell}   &          47  & {\color{Paired-1}4} &  16           & 3.60           & 32768    & 0.90     &      SSC           &  8            &                    16  &  1                &                     337  &                  1400.00  & 1400.00               & 24.3060        &     34             \\
                                                                 & \cite{Cassagne2015c} & 2015          & E3-1225            & \textit{S. Bridge} &          95  & {\color{Paired-1}4} &   8           & 3.10           & 32768    & 0.84     &      SSC           & 32            &                     1  &  1                &                     114  &                   241.00  &  241.00               &  9.7180        &    394             \\
                                                                 & \cite{Cassagne2015c} & 2015          & E3-1225            & \textit{S. Bridge} &          95  & {\color{Paired-1}4} &  16           & 3.10           & 32768    & 0.83     &      SSC           &  8            &                    16  &  1                &                     370  &                  1180.00  & 1180.00               & 23.7900        &     81             \\
                                                                 & \cite{Sarkis2016}    & 2016          & i7-2600            & \textit{S. Bridge} &          95  & {\color{Paired-1}4} &   8           & 3.40           &  2048    & 0.84     &   CA-SSCL          & 32            &                     1  & 32                &                     433  &                     4.00  &  128.00               &  4.7059        &    742             \\
                                                                 & \cite{Giard2016b}    & 2016          & i7-4770S           & \textit{Haswell}   &          64  & {\color{Paired-1}4} &  32           & 3.10           & 32768    & 0.84     &      SSC           &  8            &                     1  &  1                &                      31  &                   886.00  &  886.00               &  8.9310        &     73             \\
                                                                 & \cite{Giard2016b}    & 2016          & Cortex-A9          & \textit{ARMv7}     & $\approx~$3  & {\color{Paired-1}4} &  16           & 1.70           & 32768    & 0.90     &      SSC           &  8            &                     1  &  1                &                     361  &                    81.70  &   81.70               &  3.0030        &     37             \\
                                                                 & \cite{Cassagne2016b} & 2016          & i7-4850HQ          & \textit{Haswell}   &          47  & {\color{Paired-1}4} &  16           & 3.30           & 32768    & 0.83     &      SSC           &  8            &                     1  &  1                &                      47  &                   580.00  &  580.00               & 10.9840        &     81             \\
                                                                 & \cite{Cassagne2016b} & 2016          & Cortex-A57         & \textit{ARMv8}     & $\approx~$2  & {\color{Paired-1}2} &  16           & 1.10           & 32768    & 0.83     &      SSC           &  8            &                     1  &  1                &                     374  &                    73.00  &   73.00               &  4.1480        &     27             \\
                                                                 & \cite{Shen2016}      & 2016          & i7-4790K           & \textit{Haswell}   &          88  & {\color{Paired-1}4} &   8           & 4.00           &  2048    & 0.84     &       SCL          & 32            &                     1  &  1                &                    1573  &                     1.10  &   35.10               &  1.0938        &   2514             \\
                                                                 & \cite{LeGal2017a}    & 2018          & i7-4960HQ          & \textit{Haswell}   &          47  & {\color{Paired-1}4} &  32           & 3.60           & 32768    & 0.84     &      SSCAN         & 32            &                     1  &  1                &                      56  &                   490.00  &  490.00               &  4.2535        &     96             \\
                                                                 & \cite{LeGal2017a}    & 2018          & i7-4960HQ          & \textit{Haswell}   &          47  & {\color{Paired-1}4} &  32           & 3.60           & 32768    & 0.84     &      SSCAN         & 32            &                    32  &  1                &                    1601  &                   550.00  &  550.00               &  4.7743        &     85             \\
                                                                 & \cite{Leonardon2019} & 2019          & i5-6600K           & \textit{Skylake}   &          91  & {\color{Paired-1}4} &  32           & 3.90           &  2048    & 0.84     &   CA-SSCL          &  8            &                     1  & 32                &                     577  &                     3.00  &   96.00               &  0.7692        &    948             \\

  \hline
  \end{tabular}
  }}
  \end{adjustbox}
\end{table}

\begin{table}[htp]
  \renewcommand{\arraystretch}{1.2}
  \centering
  \caption{Turbo Software Decoders Hall of Fame.}
  \label{tab:eval_turbo_hof}
  \checkoddpage
  \ifthenelse{\boolean{twosidedoc}}
  {\begin{adjustbox}{angle=\ifoddpage 90\else -90\fi}}
  {\begin{adjustbox}{angle=90}}
  {\resizebox{0.95\textheight}{!}{
  \begin{tabular}{|r|r r|r r r r r r|r r r|r r r r|r r r r|r r r|}
  \hline
  \multicolumn{3}{|c|}{\multirow{2}{*}{}} & \multicolumn{6}{c|}{\multirow{2}{*}{\textbf{Hardware specifications}}} & \multicolumn{3}{c|}{\multirow{2}{*}{\textbf{Code}}} & \multicolumn{4}{c|}{\multirow{2}{*}{\textbf{Decoder parameters}}} & \multicolumn{4}{c|}{\multirow{2}{*}{\textbf{Decoding performances}}} & \multicolumn{3}{c|}{\multirow{2}{*}{\textbf{Metrics}}} \\
  \multicolumn{3}{|c|}{}                  & \multicolumn{6}{c|}{}                                                  & \multicolumn{3}{c|}{}                               & \multicolumn{4}{c|}{}                                             & \multicolumn{4}{c|}{}                                                & \multicolumn{3}{c|}{}                                  \\
  \hline
  \multicolumn{2}{|r}{\textbf{Work}}                                                    & \textbf{Year} & \textbf{Platform}   & \textbf{Arch.}     & \textbf{TDP} & \textbf{Cores} & \textbf{SIMD} & \textbf{Freq.} & $\bm{K}$ & $\bm{R}$ & $\textbf{Std.}$ & \textbf{Algorithm} & \textbf{Pre.} & $\bm{F}$       & $\bm{i}$ & \textbf{BER} & \textbf{FER}     & $\bm{\mathcal{L}}$    & $\bm{\mathcal{T}_i}$   & $\bm{\mathcal{NT}_i}$ & \textbf{TNDC} & $\boldsymbol{E_d}$ \\
  \multicolumn{2}{|r}{}                                                                 &               &                     &                    & (W)          & (or SM)        & (length)      & (GHz)          &          &          &                 &                    & (bit)         & (inter)        &          & \multicolumn{2}{c}{(at 0.7 dB)} & ($\mu$s)              & (Mb/s)                 & (Mb/s)                &               & (nJ)               \\
  \hline
  \hline
  \multirow{12}{*}{\rotatebox[origin=c]{90}{\textbf{GPU-based}}} & \cite{Wu2010}        & 2010          & Tesla C1060         & \textit{Tesla}     & 200          & 15             & 16            & 1.30           & 6144     & 1/3      & LTE             &  ML-MAP            & 32            & 100            & 5        & 1e-04        &     -            &                76800  &                   8.0  &   6.7                 & 0.021         &  29851             \\
                                                                 & \cite{Wu2011}        & 2011          & GTX 470             & \textit{Fermi}     & 215          & 14             & 32            & 1.22           & 6144     & 1/3      & LTE             &  ML-MAP            & 32            & 100            & 5        & 4e-05        &     -            &                20827  &                  29.5  &  24.6                 & 0.045         &   8740             \\
                                                                 & \cite{Chinnici2012}  & 2012          & Tesla C2050         & \textit{Fermi}     & 247          & 14             & 32            & 1.15           & 11918    & 1/3      &   -             &   L-MAP            & 32            & 32             & 5        &     -        &     -            &               108965  &                   3.5  &   2.9                 & 0.0057        &  85172             \\
                                                                 & \cite{Yoge2012}      & 2012          & 9800 GX2            & \textit{Tesla}     & 197          & 16             & 16            & 1.50           & 6144     & 1/3      & LTE             &  ML-MAP            & 32            & 1              & 5        & 1e-02        &     -            &                 3072  &                   2.0  &   1.7                 & 0.0043        & 115882             \\
                                                                 & \cite{Liu2013}       & 2013          & GTX 550 Ti          & \textit{Fermi}     & 116          & 6              & 32            & 1.80           & 6144     & 1/3      & LTE             & EML-MAP            & 32            & 1              & 6        & 1e-02        &     -            & {\color{Paired-3} 72} &                  85.3  &  85.3                 & 0.247         &   1360             \\
                                                                 & \cite{Chen2013}      & 2013          & GTX 580             & \textit{Fermi}     & 244          & 16             & 32            & 1.54           & 6144     & 1/3      & LTE             &  ML-MAP            & 32            & 1              & 6        & 3e-04        &     -            &                 1660  &                   3.7  &   3.7                 & 0.0047        &  63946             \\
                                                                 & \cite{Xianjun2013}   & 2013          & GTX 480             & \textit{Fermi}     & 250          & 15             & 32            & 1.40           & 6144     & 1/3      & LTE             & EML-MAP            & 32            & 1              & 6        &     -        &     -            & {\color{Paired-3} 50} &                 122.8  & 122.8                 & 0.183         &   2036             \\
                                                                 & \cite{Wu2013}        & 2013          & GTX 680             & \textit{Kepler}    & 195          & 8              & 192           & 1.01           & 6144     & 1/3      & LTE             & EML-MAP            & 32            & 16             & 6        &     -        & 1e-02            &                 2657  &                  37.0  &  37.0                 & 0.024         &   5270             \\
                                                                 & \cite{Zhang2014}     & 2014          & Tesla K20c          & \textit{Kepler}    & 225          & 13             & 192           & 0.71           & 6144     & 1/3      & LTE             &  ML-MAP            & 32            & 1              & 5        & 1e-04        &     -            &                 1097  &                   5.6  &   4.7                 & 0.0026        &  47872             \\
                                                                 & \cite{Li2014}        & 2014          & GTX 580             & \textit{Fermi}     & 244          & 16             & 32            & 1.54           & 6144     & 1/3      & LTE             & BR-SOVA            & 8             & 4              & 5        & 2e-02        &     -            & {\color{Paired-3}192} &                 127.8  & 106.5                 & 0.135         &   2291             \\
                                                                 & \cite{Li2016a}       & 2016          & GTX 680             & \textit{Kepler}    & 195          & 8              & 192           & 1.01           & 6144     & 1/3      & LTE             & EML-MAP            & 32            & 1              & 7        & 9e-03        &     -            &                  817  & {\color{Paired-7} 8.2} &   9.6                 & 0.0062        &  20313             \\
                                                                 & \cite{Li2016a}       & 2016          & GTX 680             & \textit{Kepler}    & 195          & 8              & 192           & 1.01           & 6144     & 1/3      & LTE             &    FPTD            & 32            & 1              & 36       & 9e-03        &     -            &                  403  & {\color{Paired-7}18.7} &   -                   & -             &      -             \\
  \hline
  \hline
  \multirow{10}{*}{\rotatebox[origin=c]{90}{\textbf{CPU-based}}} & \cite{Huang2011}     & 2011          & i7-960              & \textit{Nehalem}   & 130          & 1              &  8            & 3.20           & 1008     & 1/3      & LTE             &  ML-MAP            & 16           & 1               & 8        & 3e-03        & 7e-02            &                  138  &                   7.3  &    9.7                & 0.380         &  13402             \\
                                                                 & \cite{Zhang2012}     & 2012          & X5670               & \textit{Westmere}  & 95           & 6              & 16            & 2.93           & 5824     & 1/3      & LTE             & EML-MAP            &  8           & 6               & 3        & 6e-02        &     -            &                  157  &                 222.6  &  111.3                & 0.396         &    854             \\
                                                                 & \cite{Wu2013}        & 2013          & i7-3770K            & \textit{I. Bridge} & 77           & 4              &  8            & 3.50           & 6144     & 1/3      & LTE             & EML-MAP            & 16           & 4               & 6        &     -        & 1e-01            &                  323  &                  76.2  &   76.2                & 0.680         &   1011             \\
                                                                 & \cite{Cassagne2016a} & 2016          & E5-2650             & \textit{I. Bridge} & 95           & 8              &  8            & 2.50           & 6144     & 1/3      & LTE             & EML-MAP            & 16           & 64              & 6        & 6e-06        & 6e-03            &                 3665  &                 107.3  &  107.3                & 0.669         &    885             \\
                                                                 & \cite{Cassagne2016a} & 2016          & i7-4960HQ           & \textit{Haswell}   & 47           & 4              &  8            & 3.20           & 6144     & 1/3      & LTE             & EML-MAP            & 16           & 32              & 6        & 6e-06        & 6e-03            &                 2212  &                  88.9  &   88.9                & 0.868         &    527             \\
                                                                 & \cite{Cassagne2016a} & 2016          & $2\times$E5-2680 v3 & \textit{Haswell}   & 240          & 24             &  8            & 2.50           & 6144     & 1/3      & LTE             & EML-MAP            & 16           & 192             & 6        & 6e-06        & 6e-03            &                 2657  &                 443.7  &  443.7                & 0.924         &    541             \\
                                                                 & \cite{Cassagne2016a} & 2016          & E5-2650             & \textit{I. Bridge} & 95           & 8              & 16            & 2.50           & 6144     & 1/3      & LTE             & EML-MAP            &  8           & 128             & 6        & 8e-05        & 5e-02            &                 3492  &                 225.2  &  225.2                & 0.704         &    422             \\
                                                                 & \cite{Cassagne2016a} & 2016          & i7-4960HQ           & \textit{Haswell}   & 47           & 4              & 16            & 3.20           & 6144     & 1/3      & LTE             & EML-MAP            &  8           & 64              & 6        & 8e-05        & 5e-02            &                 2837  &                 138.6  &  138.6                & 0.677         &    339             \\
                                                                 & \cite{Cassagne2016a} & 2016          & $2\times$E5-2680 v3 & \textit{Haswell}   & 240          & 24             & 16            & 2.50           & 6144     & 1/3      & LTE             & EML-MAP            &  8           & 384             & 6        & 8e-05        & 5e-02            &                 3293  &                 716.4  &  716.4                & 0.746         &    335             \\
                                                                 & \cite{LeGal2019a}    & 2019          & $2\times$E5-2680 v3 & \textit{Haswell}   & 240          & 24             & 32            & 2.50           & 6144     & 1/3      & LTE             & EML-MAP            &  8           & 24              & 6        & 1e-03        & 3e-01            &                   84  &                1735.0  & 1735.0                & 0.904         &    138             \\
  \hline
  \end{tabular}
  }}
  \end{adjustbox}
\end{table}

In this section three software decoders Hall of Fames (HoFs) are provided:
1) for the LDPC decoders in Table~\ref{tab:eval_ldpc_hof}, 2) for the polar
decoders in Table~\ref{tab:eval_polar_hof} and 3) for the turbo decoders in
Table~\ref{tab:eval_turbo_hof}. The purpose of these HoFs is to see at a glance
what has been achieved, what can be expected from current software decoders.
Moreover, they enable to easily compare their respective characteristics. All
the presented results, collected from the state-of-the-art research papers
published in the field, consider a BPSK (Bit Phase-Shift Keying)
modulation/demodulation and an AWGN (Additive White Gaussian Noise) channel.
This Hall of Fame strives to present results as fairly as possible. For
instance,  early termination (\emph{Early T.}) criteria are not taken into
consideration while computing throughput, in order to compare raw performances
using a consistent method. It remains possible, however, for
typos/glitches/mistakes to have inadvertently made it to the scoreboard.

\newpage
All the entries are sorted by platform type (GPU and CPU) and chronologically.
For each HoF table, a column is dedicated to the \emph{Hardware specifications}.
Indeed, it can have a huge impact on the decoding performance depending on if
you are using a low power ARM\R CPU or a high end HPC GPU for instance. Then the
next column aims to give some insights on the \emph{Code} used in the decoding
process. Again, decoding a short code generally results in low latencies
performance when decoding a big code generally leads to higher latencies. The
\emph{Decoder parameters} are given in a dedicated column. Those parameters
characterize the decoding process used in the experiments. The \emph{Decoding
performances} (or \emph{Decoding perf.}) column shows the reported performances
in terms of latency and throughput (and exceptionally the BER and FER in the
turbo HoF). For the LDPC HoF, the throughput considers the codeword size (coded
throughput $\mathcal{T}_c$, $N$ bits) whereas in the polar and turbo HoFs the
information throughputs are presented ($\mathcal{T}_i$ considering $K$ bits).
Generally speaking, the throughput ($\mathcal{T}$) can be deduced from the
number of bits $B$ in the codeword ($B$ can be $K$ or $R$ depending on if we are
considering information or coded throughput), the number of frames decoded in
parallel ($F$) and the latency ($\mathcal{L}$):
\begin{equation}
  \mathcal{T} = (B \times F) / \mathcal{L}.
\end{equation}
In many cases, the raw performances are hard to directly compare. Indeed, the
number of iterations ($i$) or the number of lists ($L$) can vary from a work to
another one. This is why we proposed some \emph{Metrics} in the last column. Those
metrics aim to facilitate the comparison between the results. The
\emph{normalized throughput} ($\mathcal{NT}$) is different for each HoF. But,
the idea is to normalize the throughput with a representative number of
iterations/lists ($I$). The normalized throughput can be expressed as follows:
\begin{equation}
  \mathcal{NT} = (\mathcal{T} \times i) / I,
\end{equation}
for the LDPC HoF $I = 50$, for the turbo HoF $I = 6$ and for the polar HoF
$I = 1$.
The \emph{Throughput under Normalized Decoding Cost} (\emph{TNDC}) is a metric
proposed in~\cite{Ying2012}. The general idea is to see how much the hardware
components are stressed (higher TNDC is better). In the initial paper, the TNDC
was only taking care of the frequency and the number of cores. In this thesis we
refined the model by adding the SIMD length as this is a key for performance in
channel decoding algorithms:
\begin{equation}
  \text{TNDC} = \mathcal{NT} / (\text{Freq.} \times \text{Cores} \times \text{SIMD}).
\end{equation}
The last metric is the \emph{decoding energy} ($E_d$), this is the energy cost
of the proposed implementation (lower is better):
\begin{equation}
  E_d = (\text{TDP} / \mathcal{NT}) \times 10^3.
\end{equation}
For the TNDC and the decoding energy, the normalized throughput is considered
instead of the raw throughput. So one can compare metrics with each other. One
can note that there is additional information given by the colors in the
different tables. The definition of the colors is:
\begin{itemize}
  \item {\color{Paired-1}blue}: only one core of the CPU is used, in the TNDC
    computation one core is considered, in $E_d$ the entire TDP is used,
  \item {\color{Paired-3}green}: not including the memory data transfer time
    between the CPU and the GPU, in real life those transfers occur and the
    impact on the real latency can be significant,
  \item {\color{Paired-7}orange}: following the formula, the throughput should
    be lower but the authors performed a specific data transfers overlapping
    with CUDA streams to reach higher throughput,
  \item {\color{Paired-9}purple}: the inter-frame level has been deduced from
    the throughput and the latency.
\end{itemize}

\section{SCMA Demodulators}
\label{sec:eval_scma}

In this section, the effects of the various SCMA demodulator optimizations
considered in Section~\ref{sec:opt_scma} are investigated. Energy efficiency,
power consumption, throughput and latency are discussed.

\subsection{Experimentation Platforms}

\begin{table}[htp]
  \centering
  \caption
    [Specifications of the target processors for the SCMA demodulators
     experiments.]
    {Specifications of the target processors.}
  {\resizebox{\linewidth}{!}{
  \begin{tabular}{c | c  c  c}
                                  & \textbf{i7-6700HQ}        & \textbf{7120P}                & \textbf{A57}          \\
    \hline
    \hline
    \multirow{2}{*}{\textbf{CPU}} & Intel\R Core\TM i7-6700HQ & Intel\R Xeon Phi\TM 7120P     & ARM\R Cortex-A57      \\
                                  &                           &                               & (Nvidia\R Jetson TX1) \\
    \textbf{Cores/Freq.}          & 4 cores, 2.6--3.5 GHz     & 64 cores,  1.24--1.33 GHz     & 4 cores, 1.91 GHz     \\
    \textbf{Arch.}                & \textit{Ivy Bridge} Q1'12 & \textit{Knights Corner} Q2'13 & \textit{ARMv8} Q1'15  \\
    \textbf{LLC}                  & 6 MB L3                   & 30.5 MB L2                    & 2 MB L2               \\
    \textbf{TDP}                  & 45 W                      & 300 W                         & 15 W                  \\
  \end{tabular}
  }}
  \label{tab:eval_scma_specs}
\end{table}

Energy efficiency is of interest in the design of C-RAN servers. It is
determined by the rate of computation that can be achieved by a processor.
Joint optimization of the throughput and energy consumption is a main goal of
system designers. Energy optimization can significantly reduce the cost of cloud
services while it can contribute to decrease the emission of greenhouse
gases. Power utilization is also important because improved performance per Watt
is useful to limit power demands. This section explores the power, energy
efficiency and throughput of the various message passing algorithms suggested in
this work. Tests have been conducted on three platforms running the Ubuntu Linux
operating system. The three systems are : 1) an Intel\R Core\TM i7-6700HQ
processor with AVX instructions (256-bit SIMD) and four physical cores using
2-way Simultaneous Multi-Threading (SMT or Intel\R Hyper-Threading technology)
running at nominal frequency of 2.6 GHz, 2) an ARM\R Cortex-A57 with NEON
instructions (128-bit SIMD) and four cores (no SMT) running at 2.0 GHz and 3) an
Intel\R Xeon Phi\TM 7120P with KNCI instructions (512-bit SIMD)
and 61 cores using 4-way SMT and running at 1.2 GHz. On the i7-6700HQ and the
Cortex-A57 targets the GNU compiler (version 5.4) has been used while on the
Xeon Phi\TM co-processor the Intel compiler (version 17) has been used.

\subsection{Throughput, Latency and Energy Efficiency on Multi-core CPUs}
\label{sec:eval_scma_throughput}

\begin{table}[htp]
  \centering
  \caption
    [MPA throughput, latency, power and energy characteristics.]
    {MPA throughput, latency, power and energy characteristics over 768 Million bits~\cite{Ghaffari2019}.}
  \label{tab:eval_scma_thr}
  \begin{tabular}{r | r r | r r r r}
  & \textbf{Algorithm} & \textbf{Optim.} & $\bm{\mathcal{L}}$ & $\bm{\mathcal{T}}$ & $\bm{P}$ & $\bm{E_b}$ \\
  & \textbf{\& SIMD}   & \textbf{Level}  & (s)                & (Mb/s)             & (W)      & ($\mu$J)   \\
  \hline
  \hline
  \multirow{6}{*}{\rotatebox[origin=c]{90}{\textbf{i7-6700HQ}}}
  %  Algorithm &           Optim & Latency & T. per Socket &  Power & Energy per Bit \\ % T per Thread
  &  E-MPA+AVX & \texttt{-Ofast} &    81.4 &         75.46 &  40.02 &           0.53 \\ %         9.43
  &  MPA+AVX   & \texttt{-Ofast} &    90.6 &         67.83 &  40.53 &           0.59 \\ %         8.48
  &  Log-MPA   & \texttt{-Ofast} &   595.3 &         10.31 &  35.11 &           3.40 \\ %         1.29
  &  Log-MPA   & \texttt{-O3}    &   960.0 &          6.37 &  33.11 &           5.17 \\ %         0.80
  &  MPA       & \texttt{-Ofast} &   412.9 &         14.85 &  33.01 &           2.22 \\ %         1.86
  &  MPA       & \texttt{-O3}    &  1745.5 &          3.51 &  35.00 &           9.94 \\ %         0.44
  \hline
  \multirow{4}{*}{\rotatebox[origin=c]{90}{\textbf{7120P}}}
  %  Algorithm &           Optim & Latency & T. per Socket &  Power & Energy per Bit \\
  & E-MPA+KNCI &    \texttt{-O2} &  1634.0 &        114.60 & 198.00 &           1.73 \\ %         0.47
  & MPA+KNCI   &    \texttt{-O2} &  2258.8 &         82.32 & 198.00 &           2.39 \\ %         0.34
  & Log-MPA    &    \texttt{-O2} &  3490.9 &         53.38 & 184.00 &           3.43 \\ %         0.22
  & MPA        &    \texttt{-O2} &  5120.0 &         36.09 & 196.00 &           5.36 \\ %         0.15
  \hline
  \multirow{6}{*}{\rotatebox[origin=c]{90}{\textbf{A57}}}
  %  Algorithm &           Optim & Latency & T. per Socket &  Power & Energy per Bit \\
  & E-MPA+NEON & \texttt{-Ofast} &   200.5 &         15.30 &   7.93 &           0.51 \\ %         3.83
  & MPA+NEON   & \texttt{-Ofast} &   365.7 &          8.40 &   7.56 &           0.90 \\ %         2.10
  & Log-MPA    & \texttt{-Ofast} &   650.1 &          4.70 &   6.99 &           1.48 \\ %         1.18
  & Log-MPA    & \texttt{-O3}    &  1024.0 &          3.01 &   6.99 &           2.33 \\ %         0.75
  & MPA        & \texttt{-Ofast} &   752.9 &          4.07 &   7.18 &           1.76 \\ %         1.02
  & MPA        & \texttt{-O3}    &  1920.0 &          1.60 &   6.99 &           4.37 \\ %         0.40
  \end{tabular}
\end{table}

Table~\ref{tab:eval_scma_thr} shows the comparison of throughput, latency, power
consumption and energy of different decoding algorithms that are executed on the
three platforms to decode 768 Million bits. The average power and energy
consumption measured on the Core\TM i7 processor were obtained with the
\emph{turbostat} software\footnote{turbostat: \url{https://github.com/torvalds/linux/tree/master/tools/power/x86/turbostat}}
which exploits the Intel\R performance counters in Machine Specific Registers
(MSRs) to monitor CPU and RAM utilizations. However, in the case of ARM\R and
Xeon Phi\TM platforms, external current sensors were used to measure the energy
and power consumptions.

\paragraph{i7-6700HQ Platform}

During the evaluation process, 8 threads are run on the i7-6700HQ platform. The
baseline implementation of MPA with level 3 (\verb|-O3|) optimization of the GNU
compiler reaches 3.51 Mbps by assigning all four physical cores of the processor
(SMT on). Log-MPA algorithms improves the performance to 6.37 Mbps thanks to the
deletion  of the exponential calculations, still in \verb|-O3|. However, using
the fast math libraries (\verb|-Ofast|) and the loop optimizations from
Section~\ref{sec:opt_scma_float} increases the throughput to 14.85 Mbps for MPA
and to 10.31 Mbps for log-MPA. It is important to observe that MPA outperforms
the log-MPA with the fast math libraries and more aggressive optimizations,
without compromising on the bit error rate performance. This is because log-MPA
induces inefficient data accesses due to the messages passed from resources to
users. Using the AVX and SSE SIMD ISAs reduces the branch mispredictions and the
cache misses (see Section~\ref{sec:opt_scma_flattening}). Consequently, the
throughput is increased to 67.83 Mbps in MPA and to 75.46 Mbps for the E-MPA
where the $\Psi'$ estimated exponentials from \eqref{eq:ctx_scma_19} are
performed. These results confirm significant throughput gains for the proposed
implementations, while the energy consumption is reduced. AVX instructions
increase the average power consumption of MPA and log-MPA from 35 to 40 Watts
but throughput and latency are improved by much larger factors. It means that
the overall energy consumption have been decreased with AVX instructions.

\paragraph{7120P Platform}

The Xeon Phi\TM Knights Corner (KNC)~\cite{Chrysos2012} benefits from the
ability to execute four hardware threads per core, while having 61~cores and
512-bit SIMD registers. In this case, 244 threads are run to handle the MPA
decoding task. Despite these benefits, the Xeon Phi\TM Knights Corner suffers
from two main disadvantages: 1) the KNC instruction set diversity is reduced
compared to AVX or AVX-512 ISAs and 2) the cores frequency is relatively low in
order to keep reasonable power consumption and limits the heat dissipation. As
an example of missing instruction, the KNCI ISA does not offer coalesced
division for floating-point numbers. Beside those limitations, the E-MPA+KNCI
exhibits the highest throughput among the three mentioned platforms (up to
114.60 Mbps). However, it consumes almost three times more energy per bit
compared to the ARM\R-based implementations. On the Intel\R ICPC compiler, the
best performances are obtained using the \verb|-O2| optimization level. Enabling
the \verb|-O3| optimization level and the fast math library does not lead to
higher throughputs.

\paragraph{A57 Platform}

On the \emph{Nvidia\R Jetson TX1} platform, the throughput difference caused by
the fast math libraries of the GNU compiler is still visible for MPA and log-MPA
algorithms. With level three optimization (\verb|-O3|), MPA and log-MPA run at
1.60 Mbps and 3.01 Mbps, respectively. When using fast math libraries
(\verb|-Ofast|) the throughputs increase to 4.07 and 4.70 Mbps. It should be
noted that the four physical cores of the ARM\R platform were  utilized for
those tests. Power consumption and energy used per decoded bit are lower on the
ARM\R platform than on the Intel\R processors. The low power consumption of the
ARM\R platform notably comes at the cost of less powerful floating-point
arithmetic units (see MPA+NEON and E-MPA+NEON in Table~\ref{tab:eval_scma_thr}).
Eliminating the exponential computations almost doubled the performance in E-MPA
(15.30 Mbps) as compared to MPA+NEON (8.40 Mbps). It shows the limits of low
power processors when many exponentials have to be calculated. Nevertheless, by
using E-MPA, the ARM\R low power processors can be a good candidate for
implementation of SCMA decoders on C-RAN servers as it enables significant
energy savings.

Considering the energy consumed per decoded bit ($E_b$), the SIMD algorithms
have a higher energy efficiency. The processor resources are well stressed and
the power does not increase too much. Among the obtained results, the Xeon
Phi\TM achieves the best throughput while the Cortex-A57 has the lowest energy
consumption. If the number of users in the cloud increases, then the presented
results are scalable up to the number of processing units dedicated to them.

\section{Analysis of the Simulator Performance}
\label{sec:eval_simu}

\begin{figure}[htp]
  \centering
  \includegraphics[width=1.0\textwidth]{\curChapter/fig/simu/chain/chain}
  \caption
    [\AFFECT simulator chain.]
    {\AFFECT simulator chain.}
  \label{fig:eval_simu_chain}
\end{figure}

In this section we propose to evaluate the simulator performance over a
representative simulation chain. This chain is illustrated in
Figure~\ref{fig:eval_simu_chain}. The transmitter is simplified and only
all-zero codewords are generated. This technique enables to bench only the AWGN
channel and the receiver tasks. The AWGN channel is presented in
Section~\ref{sec:ctx_awgn} and the vectorized implementation from the
Section~\ref{sec:opt_simu_awgn} is applied. The SNR is set to
$E_b/N_0 = 4.5$~dB. The BPSK demodulator implementation is also vectorized and
its implementation has not been detailed in the manuscript. Indeed, it is
trivial and can be resumed to the multiplication of the AWGN channel output by a
constant factor ($\bm{l} = \bm{y} \times \frac{2}{\sigma^2}$). Then, the
demodulator 32-bit floating-point output data is converted in a 8-bit
fixed-point representation thanks to the quantizer task (see
Section~\ref{sec:opt_simu_quantizer}). The decoder is the 8-bit polar FA-SSCL
presented in Section~\ref{sec:ctx_polar_ascl} an in
Section~\ref{sec:opt_polar_scl}. A $N = 2048$ and $K_1 = 1755$ polar code with
$L = 32$ and a 32-bit CRC (GZip \verb|0x04C11DB7|) is simulated (see
Figure~\ref{plot:aff3ct_polar_scl_adaptive} for the error rate). This decoder
has been chosen because it represents one of the best optimized decoder of this
thesis work. After the decoding process, the 32 CRC bits are extracted from the
polar codeword and $K_2 = 1723$ bits are returned. This operation consists in
copying the $K_2$ first bits of the $K_1$ decoder output bits. Finally, the
monitor checks if all the bits are equal to zero, if not, errors are counted.
All the tasks of the proposed communication chain are fully vectorized with the
\MIPP wrapper. The intra-frame SIMD strategy is applied.

This section is decomposed in three sub-sections. The first one details the
selected experimentation platforms. Then, the mono-threaded performances
are given for each task. Finally, the full potential of the simulator is
demonstrated over multi-threaded and multi-node executions.

\subsection{Experimentation Platforms}

\begin{table}[htp]
  \centering
  \caption
    [Specifications of the target processors for the \AFFECT simulator
     experiments.]
    {Specifications of the target processors.}
  \label{tab:eval_simu_cpus_specs}
  {\resizebox{\linewidth}{!}{
  \begin{tabular}{l  l | l | l | c | c | c | c | c}
  \multicolumn{2}{c |}{\multirow{2}{*}{\textbf{CPU}}} & \multicolumn{2}{c |}{\textbf{SIMD instr.}} & \multirow{2}{*}{\textbf{\# Proc.}} & \textbf{\# Cores}  & \textbf{Freq.} & \multirow{2}{*}{\textbf{SMT}} & \textbf{Turbo} \\ \cline{3-4}
          &                                           & \textbf{Name} & \textbf{Size}              &                                    & \textbf{per Proc.} & (GHz)          &                               & \textbf{Boost} \\
  \hline
  \hline
  ARM\R   & ThunderX2\R CN9975                        & NEON          & 128-bit                    & 2                                  &  28                & 2.00           & 4                             & \xmark         \\
  Intel\R & Xeon Phi\TM 7230                          & AVX-512F      & 512-bit                    & 1                                  &  64                & 1.30           & 4                             & \cmark         \\
  Intel\R & Xeon\TM E5-2680 v3                        & AVX2          & 256-bit                    & 2                                  &  12                & 2.50           & 1                             & \xmark         \\
  Intel\R & Xeon\TM Gold 6140                         & AVX-512BW     & 512-bit                    & 2                                  &  18                & 2.30           & 2                             & \cmark         \\
% Intel\R & Xeon\TM Gold 6142                         & AVX-512BW     & 512-bit                    & 2                                  &  16                & 2.60           & 1                             & \xmark         \\
  Intel\R & Xeon\TM Gold 6240                         & AVX-512BW     & 512-bit                    & 2                                  &  18                & 2.60           & 1                             & \xmark         \\
% AMD\R   & EPYC\TM 7452                              & AVX2          & 256-bit                    & 2                                  &  32                & 2.35           & 1                             & \xmark         \\
  AMD\R   & EPYC\TM 7702                              & AVX2          & 256-bit                    & 2                                  &  64                & 2.00           & 1                             & \xmark         \\

  \end{tabular}
  }}
\end{table}

Table~\ref{tab:eval_simu_cpus_specs} summarizes the 6 server-class selected
CPUs. These CPUs have been chosen because they have a lot of cores and are good
candidates for a multi-threading scaling evaluation. All these CPUs are 8-bit
SIMD fixed-point capable except for the Xeon Phi\TM 7230. In this specific case
the computations are made on 32-bit everywhere and the quantizer task is
skipped. Also, Intel\R, AMD\R and ARM\R CPUs are representative of the today
market. It demonstrates the flexibility and the portability capacities of the
proposed simulator. One can note that \AFFECT can adapt to various CPU
architectures.

For all the CPU targets, the code has been compiled with the \Cxx GNU compiler
version 8.2.0 on Linux, with the following optimization flags:
\verb|-O3 -funroll-loops -march=native|. Note that \AFFECT also works on Windows
and macOS at the same level of performance.

\subsection{Mono-threaded Performances}

\newcommand{\CB}{\cellcolor{Paired-1!15}}
\newcommand{\CR}{\cellcolor{Paired-5!15}}
\newcommand{\BF}[1]{\textbf{#1}}

\begin{table}[htp]
  \centering
  \caption
    [Average throughput and latency performance per simulated task
     (single-threaded).]
    {Average throughput and latency performance per simulated task
     (single-threaded). In \textbf{bold} the best performance by task. In
     \colorbox{Paired-1!15}{blue} the best
     total simulation performance and in \colorbox{Paired-5!15}{red} the worst
     total simulation performance.}
  \label{tab:eval_simu_taks_thr_lat}
  % {\small
  {\resizebox{\linewidth}{!}{
  \begin{tabular}{c | l | r r r r r r | r}
  & \textbf{CPU}           & \textbf{Chan.} & \textbf{Demod.} & \textbf{Quant.} & \textbf{Dec.} & \textbf{CRC ext.} & \textbf{Mon.} & \textbf{Total} \\
  \hline \hline
  \multirow{6}{*}{\rotatebox[origin=c]{90}{$\bm{\mathcal{T}}$ (Mb/s)}}
  & \CR ThunderX2\R CN9975 & \CR      53.7  & \CR      672.9  & \CR      748.3  & \CR    112.1  & \CR       6338.4  & \CR   2386.3  & \CR      28.4  \\
  &     Xeon Phi\TM 7230   &         100.2  &         1862.1  &            -    &         49.8  &           2073.2  &        921.4  &          29.0  \\
  &     Xeon\TM E5-2680 v3 &         159.7  &         7427.1  &         4586.2  &        247.5  &          20832.6  &       8234.5  &          82.3  \\
  & \CB Xeon\TM Gold 6140  & \CB \BF{421.7} & \CB    14131.7  & \CB\BF{12931.5} & \CB\BF{376.5} & \CB  \BF{31749.5} & \CB  11093.0  & \CB     171.8  \\
% &     Xeon\TM Gold 6142  &           -    &            -    &            -    &          -    &              -    &          -    &           -    \\
  &     Xeon\TM Gold 6240  &         314.6  &        10518.3  &         9915.8  &        277.4  &          23118.3  &       7953.5  &         127.3  \\
% &     EPYC\TM 7452       &         217.5  &        14443.7  &         9096.3  &        357.9  &          28365.2  &      13571.1  &         115.8  \\
  &     EPYC\TM 7702       &         215.4  &    \BF{14919.5} &         9234.5  &        359.5  &          28404.0  &  \BF{13562.0} &         115.4  \\
  \hline \hline
  \multirow{6}{*}{\rotatebox[origin=c]{90}{$\bm{\mathcal{L}}$ ($\mu$s)}}
  & \CR ThunderX2\R CN9975 & \CR     38.15  & \CR       3.04  & \CR       2.74  & \CR    15.65  & \CR         0.27  & \CR     0.72  & \CR     60.58  \\
  &     Xeon Phi\TM 7230   &         20.45  &           1.10  &           -     &        35.23  &             0.83  &         1.87  &         59.48  \\
  &     Xeon\TM E5-2680 v3 &         12.82  &           0.28  &           0.45  &         7.09  &             0.08  &         0.21  &         20.93  \\
  & \CB Xeon\TM Gold 6140  & \CB  \BF{4.86} & \CB       0.14  & \CB   \BF{0.16} & \CB \BF{4.66} & \CB     \BF{0.05} & \CB     0.16  & \CB     10.03  \\
% &     Xeon\TM Gold 6142  &          -     &           -     &           -     &         -     &             -     &         -     &          -     \\
  &     Xeon\TM Gold 6240  &          6.51  &           0.19  &           0.21  &         6.33  &             0.07  &         0.22  &         13.53  \\
% &     EPYC\TM 7452       &          9.42  &           0.14  &           0.23  &         4.90  &             0.06  &         0.13  &         14.88  \\
  &     EPYC\TM 7702       &          9.51  &       \BF{0.14} &           0.22  &         4.88  &             0.06  &     \BF{0.13} &         14.94  \\
  \end{tabular}
  }}
\end{table}

Table~\ref{tab:eval_simu_taks_thr_lat} presents the mono-threaded
throughput ($\mathcal{T}$) and the latency ($\mathcal{L}$) of the simulated
tasks. The throughput is calculated depending on the number of output samples in
the task. For instance, the throughput of the channel is estimated with $N$ bits
while the throughput of the decoder is computed with $K_1$ bits. The latency is
the average latency. The \emph{Total} column corresponds to the global
throughput and latency. The total latency is the cumulative latencies of each
task while the total throughput is deduced from the total latency and $K_2$
value.

\newpage
In general, the most time consuming tasks are the AWGN channel and the decoder.
The other tasks are mainly negligible thanks to the fast SIMD implementations.
The Intel\R Gold 6140 CPU has the best throughputs and latencies in general.
This is due to the Turbo Boost that enables the CPU to reach very high
frequencies on a single thread but not only. The main difference with the AMD\R
CPU comes from the best performance of the Gold 6140 CPU for the AWGN channel
task. Indeed, the Gold 6140 CPU takes advantage of its doubled SIMD length
(AVX-512) compared to the AMD\R EPYC CPU (AVX2). The ARM\R ThunderX2\R CPU comes
with the worst single threaded general performance. The Intel\R Xeon Phi\TM is
also very close to the ARM\R CPU performance. This is not surprising as these
processors have not been designed for the single core performance but for
multi-core performance.

\subsection{Multi-threaded and Multi-node Performances}
\label{sec:eval_simu_mt}

\begin{figure}[htp]
  \centering
  \subfloat[][Simulator speedups.]{\includegraphics[width=1.00\textwidth]{\curChapter/fig/simu/speedup/speedup}\label{plot:eval_simu_speedup}}
  \\
  \subfloat[][Simulator throughputs.]{\includegraphics[width=0.70\textwidth]{\curChapter/fig/simu/throughput/throughput}\label{plot:eval_simu_throughput}}
  \caption
    [\AFFECT simulation results of a (2048,1723) Polar code, FA-SSCL decoder
     $L=32$.]
    {\AFFECT simulation results of a (2048,1723) Polar code, FA-SSCL decoder
     $L=32$, BPSK modulation, AWGN channel, $E_b/N_0$ = 4.5~dB (BER = 4.34e-10,
     FER = 5.17e-08).}
  \label{plot:eval_simu_speedup_throughput}
\end{figure}

Figure~\ref{plot:eval_simu_speedup} depicts the speedups achieved on the various
modern CPU architectures, while Figure~\ref{plot:eval_simu_throughput} exposes
the corresponding simulation information throughputs. In
Figure~\ref{plot:eval_simu_speedup}, the speedups on each architecture are
computed with respect to the single thread simulation time on the same
architecture. Each run assigns at most one \AFFECT thread to each hardware
thread. Since the architectures have different number of hardware threads, the
presented speedups do not all have the same number of measurement points. To
reduce the simulation time it is possible to multiply the number of concurrent
communication chains, thanks to the independence property of Monte Carlo
simulations. The simulation scales rather well on the tested architectures. The
data remains in the CPU caches because of the moderate frame size ($N = 2048$)
and SIMD intra-frame strategy. Scaling on the Xeon\TM Gold 6140 is not as good
as the other targets, because the \textit{Intel\R Turbo Boost} technology is
enabled. The CPU runs at higher frequencies when the number of active cores is
low. \AFFECT effectively leverages the simultaneous multi-threading (SMT)
technology. This is especially true for the ThunderX2\R CN9975 and Xeon\TM Gold
6140 targets. The SMT technology helps to improve the usage of the available
instruction-level parallelism.

The best multi-threaded throughput performance is achieved on the AMD\R EPYC
platform and its 128 cores. 11 Gb/s are reached on the two AMD\R EPYC 7702 CPUs.
The best Intel\R target (Xeon\TM Gold 6140) can only get half of the AMD\R CPU
performance. The ARM\R target and the Xeon Phi\TM are not competitive in terms
of throughput even when all the hardware threads are assigned. It is possible
that these targets are more adapted for SDR usage (like for the C-RAN) when
power consumption matter more. However, for simulation purpose, it is clear that
the AMD\R EPYC CPUs are more interesting. Those results also demonstrate the
interest to enable the frequency boost as well as the SMT technology. Indeed,
the Xeon\TM Gold 6240 CPU should be faster than the Xeon\TM Gold 6140 CPU. But,
the frequency boost and the SMT technology have been disabled on this server. It
results in worst multi-threaded performance. We could not try to enable the
frequency boost and the SMT techniques on the AMD\R CPU but there is a good
chance that it would have increased the throughput even more.

\begin{table}[htp]
  \centering
  \caption{\AFFECT multi-node speedups (single node: $2\times$Xeon\TM E5-2680 v3).}
  \label{tab:eval_simu_speedup_mpi}
  \begin{tabular}{r  r  r  r}
  \textbf{Nodes} & \textbf{Cores} & $\bm{\mathcal{T}_i}$ & \textbf{Speedup} \\
                 &                & (Mb/s)               &                  \\
  \hline
  \hline
   1             &  24            &  1,950               &  1.00            \\
   2             &  48            &  3,901               &  1.95            \\
%  3             &  72            &  5,826               &  2.99            \\
   4             &  96            &  7,793               &  4.00            \\
%  5             & 120            &  9,731               &  4.99            \\
%  6             & 144            & 11,691               &  5.99            \\
%  7             & 168            & 13,644               &  7.00            \\
   8             & 192            & 15,829               &  8.12            \\
%  9             & 216            & 17,755               &  9.10            \\
% 10             & 240            & 19,582               & 10.04            \\
  16             & 384            & 31,640               & 16.22            \\
  32             & 768            & 63,075               & 32.34            \\
  \end{tabular}
\end{table}

Table~\ref{tab:eval_simu_speedup_mpi} shows the multi-node scaling with the
OpenMPI library (version 3.1.2). The information throughput ($\mathcal{T}_i$)
and the speedup values are almost linear with the number of nodes: This is
expected because there are very few communications between the various MPI
processes. Note that the super-linear scaling is due to the measurement
imprecision.

Those aforementioned results demonstrate the high throughput
capabilities of the \AFFECT simulator. For instance, when using 32 MPI nodes on
the given (2048,1723) polar code, it takes about one minute to estimate the
$E_b/N_0=4.5$ dB SNR point (BER = 4.34e-10, FER = 5.17e-08).

\section{Conclusion}

In this chapter we evaluated the implementations of the LDPC decoders, polar
decoders and turbo decoders studied during this thesis. The throughput, the
latency and the energy efficiency have been studied and compared with other
works. For the LDPC decoders and the turbo decoders, the inter-frame strategy
has been applied and leads to throughputs comparable with the state-of-the-art
performance. However, the latencies are not competitive with the intra-frame
implementations found in the literature. These implementations are then more
oriented for simulation purpose or for real-time applications that do not
require low latency like the video streaming, for instance. For the polar
decoders, both the inter-frame and intra-frame strategies has been implemented.
It results in a complete framework that can adapt to many applicative contexts.
The proposed decoders are ones of the fastest in the literature. There are also
able to be very flexible with the dynamic implementations or specialized for
highest possible performance with the source code generation technique. For all
the proposed decoders (LDPC, polar and turbo), the level of genericity is one of
our main contribution. The implementations are able to adapt to various CPUs
architectures as well as to support many algorithmic variants. Moreover, each of
the presented implementations are able to work close to the reference decoding
performance. Most of the obtained results have been published in scientific
conferences and journals~\cite{Ghaffari2019,Leonardon2019,Cassagne2015c,
Cassagne2016b,Cassagne2016a}.

The software decoder Hall of Fames (HoFs) are then introduced. These HoFs are
exhaustive surveys of the software decoders found in the literature. The
proposed decoders are reported as well as the other state-of-the-art works.
These HoFs enables to compare CPU and GPU implementations. Some metrics like the
normalized throughput, the TNDC and the energy consumption are defined. The
results show that these last years, the CPU implementations are more efficient
than the GPU works in terms of throughput, latency and energy efficiency. One of
the main issue of the GPU-based implementations is the required transfer time
between the CPU and the GPU. An other main issue comes from the intrinsic
architecture of the GPU that requires a lot of parallelism to be efficient. This
is not always possible to take advantage of this high level of parallelism in
the channel decoding algorithms. As a consequence, in general, the CPUs are more
adapted to low latency implementations than the GPUs.

The last section of this chapter focuses on the \AFFECT simulator performance.
A fully vectorized digital communication chain is proposed for the evaluation.
First the mono-threaded performances are reported. As a result, \AFFECT runs
fast on the last Intel\R Gold CPUs that support the AVX-512 SIMD engine.
Then the multi-threaded performances are benched and the AMD\R EPYC CPUs comes
with the best throughout performance, up to 11 Gb/s. Even if the AMD\R EPYC CPUs
only supports the AVX instructions, it looks like the Zen 2 architecture is well
balanced between computational power and memory speed. Finally, the multi-node
capacity of the \AFFECT simulator is tested and a linear speedup is observed
over 32 nodes. The peak throughput performance in multi-node is 32 Gb/s. These
high throughputs enable the exploration of many combinations at very low
error-rate level. Preliminary results have been published in a scientific
journal~\cite{Cassagne2019a}. To the best of our knowledge, \AFFECT is one of
the current fastest FEC simulator.

The next chapter presents a new extension of the \AFFECT library to improve the
SDR support. An embedded domain specific language is proposed to ease the usage
of multi-core CPUs in real-time contexts.
