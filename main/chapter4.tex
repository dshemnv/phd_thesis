\graphicspath{{main/chapter4/fig/}}

\chapter{\AFFECT: A Fast Forward Error Correcting Toolbox}

% \vspace*{\fill}
\minitoccustom
% \vspace*{\fill}

\section{Philosophy}

\subsection{High Performance}

\begin{itemize}
  \item performance -> langage C++
\end{itemize}

\subsection{Portability}

\subsection{Algorithmic Heterogeneity}

\subsection{Reproducible Science}

\section{Related Works}

\begin{itemize}
  \item \cmark~Biblioth√®ques FEC: \url{http://aff3ct.github.io/fec_libraries.html}
\end{itemize}

\subsection{FEC Libraries}

\begin{table}[htp]
  \centering
  \caption{\C/\Cxx open source channel coding simulators/libraries.}
  \label{tab:fec_libraries_comparison}
  % \begin{adjustbox}{angle=90}
  {\resizebox{\linewidth}{!}{
  \begin{tabular}{r   r  r  r  r  r | C{\simcolwidth}  C{\simcolwidth}  C{\simcolwidth}  C{\simcolwidth}  C{\simcolwidth}  C{\simcolwidth}  C{\simcolwidth}  C{\simcolwidth}  C{\simcolwidth}  C{\simcolwidth} }
  \multirow{4}{*}{\textbf{Name}} & \multirow{4}{*}{\textbf{Ref.}} &                  &                &                & \multirow{4}{*}{\textbf{License}} & \multirow{4}{*}{\rotatebox[origin=c]{90}{Polar}} & \multirow{4}{*}{\rotatebox[origin=c]{90}{LDPC}} & \multirow{4}{*}{\rotatebox[origin=c]{90}{Turbo}} & \multirow{4}{*}{\rotatebox[origin=c]{90}{Turbo P.}} & \multirow{4}{*}{\rotatebox[origin=c]{90}{BCH}} & \multirow{4}{*}{\rotatebox[origin=c]{90}{RS}} & \multirow{4}{*}{\rotatebox[origin=c]{90}{Conv.}} & \multirow{4}{*}{\rotatebox[origin=c]{90}{RA}} & \multirow{4}{*}{\rotatebox[origin=c]{90}{Rep.}} & \multirow{4}{*}{\rotatebox[origin=c]{90}{Erasure}} \\
                                 &                                & \textbf{Contri-} & \textbf{Code}  & \textbf{Start} &                                   &        &        &        &        &        &        &        &        &        &         \\ %\cline{5-6}
                                 &                                & \textbf{butors}  & \textbf{Lines} & \textbf{Year}  &                                   &        &        &        &        &        &        &        &        &        &         \\
                                 &                                &                  &                &                &                                   &        &        &        &        &        &        &        &        &        &         \\ \hline\hline
                                                                                                                                                           % Polar    LDPC     Turbo    TPC      BCH      RS       Conv.    RA       Rep.     Erasure
  {\AFFECT}                      & \cite{Cassagne2019a}           &               11 &            76k & 2016           & MIT                               & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \xmark  \\
  {aicodix GmbH}                 & \cite{Aicodix}                 &                1 &             7k & 2018           & Copyright                         & \xmark & \cmark & \xmark & \xmark & \cmark & \cmark & \xmark & \xmark & \xmark & \xmark  \\
  {eccpage}                      & \cite{ECCpage}                 &               20 &              - & 1989           & -                                 & \xmark & \cmark & \cmark & \xmark & \cmark & \cmark & \cmark & \xmark & \xmark & \cmark  \\
  {EZPWD}                        & \cite{EZPWDRS}                 &                2 &             6k & 2014           & GPLv3                             & \xmark & \xmark & \xmark & \xmark & \xmark & \cmark & \xmark & \xmark & \xmark & \xmark  \\
  {FastECC}                      & \cite{FastECC}                 &                2 &             1k & 2015           & Apache 2.0                        & \xmark & \xmark & \xmark & \xmark & \xmark & \cmark & \xmark & \xmark & \xmark & \xmark  \\
  {FEC-AL}                       & \cite{FEC-AL}                  &                1 &             3k & 2018           & BSD                               & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \cmark & \xmark & \xmark & \cmark  \\
  {FECpp}                        & \cite{FECpp}                   &                1 &             2k & 2009           & -                                 & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \cmark  \\
  {GNURadio}                     & \cite{GNURadio}                &              192 &           270k & 2006           & GPLv3                             & \cmark & \cmark & \xmark & \xmark & \xmark & \xmark & \cmark & \xmark & \cmark & \xmark  \\
  {Inan}                         & \cite{Inan-LDPC}               &                2 &            13k & 2018           & Copyright                         & \xmark & \cmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark  \\
  {IT++}                         & \cite{ITpp}                    &               20 &           109k & 2005           & GPLv3                             & \xmark & \cmark & \cmark & \xmark & \cmark & \cmark & \cmark & \xmark & \xmark & \xmark  \\
  {Le Gal}                       & \cite{LeGal-LDPC}              &                1 &            83k & 2015           & -                                 & \xmark & \cmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark  \\
  {Leopard}                      & \cite{Leopard}                 &                4 &             5k & 2017           & BSD                               & \xmark & \xmark & \xmark & \xmark & \xmark & \cmark & \xmark & \xmark & \xmark & \xmark  \\
  {libcorrect}                   & \cite{Libcorrect}              &                6 &             5k & 2016           & BSD                               & \xmark & \xmark & \xmark & \xmark & \xmark & \cmark & \cmark & \xmark & \xmark & \xmark  \\
  {Neal}                         & \cite{Neal-LDPC}               &                1 &             5k & 2006           & Copyright                         & \xmark & \cmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark  \\
  {OpenAir}                      & \cite{OpenAir}                 &              148 &           740k & 2013           & OAI Public                        & \xmark & \xmark & \cmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark  \\
  {OpenFEC}                      & \cite{OpenFEC}                 &                8 &            55k & 2009           & CeCCIL-C                          & \xmark & \cmark & \xmark & \xmark & \xmark & \cmark & \xmark & \xmark & \xmark & \xmark  \\
  {Schifra}                      & \cite{Schifra}                 &                1 &             7k & 2010           & GPLv3                             & \xmark & \xmark & \xmark & \xmark & \xmark & \cmark & \xmark & \xmark & \xmark & \xmark  \\
  {Siamese}                      & \cite{Siamese}                 &                1 &            11k & 2018           & BSD                               & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \cmark & \xmark & \xmark & \cmark  \\
  {Tavildar (Polar)}             & \cite{Tavildar-Polar}          &                1 &             2k & 2016           & -                                 & \cmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark  \\
  {Tavildar (LDPC)}              & \cite{Tavildar-LDPC}           &                1 &             1k & 2016           & -                                 & \xmark & \cmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark  \\
  {the-art-of-ecc}               & \cite{The-art-of-ecc}          &                1 &              - & 2006           & Copyright                         & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \xmark & \xmark & \xmark  \\
  {TurboFEC}                     & \cite{TurboFEC}                &                2 &             4k & 2015           & GPLv3                             & \xmark & \xmark & \cmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark  \\
  \end{tabular}
  }}
  % \end{adjustbox}
\end{table}

In the digital communications community, many scientists implement their own
simulation chain to validate their works.
Table~\ref{tab:fec_libraries_comparison} presents, to the best of our knowledge,
a list of currently available \verb|C|/\Cxx open source channel coding
simulators/libraries. We choose to compare with projects compiled as binaries,
since they aim at high throughput and low latency, as \AFFECT. Many open source
projects in Python or in MATLAB exist as well, but these tools are usually
slower than compiled binaries, and rather aim at prototyping.

Table~\ref{tab:fec_libraries_comparison} shows that, generally, the
\verb|C|/\Cxx FEC libraries target a single family or a small subset of channel
codes. As a consequence, a large effort is spent to re-develop similar features,
since all those libraries and tools share many characteristics (except the
channel code itself). \AFFECT attempts to lower this redundancy by releasing a
full simulator/library that consistently supports a wide range of channel codes
to the community. \AFFECT also tries to homogenize usage (command line, \Cxx
interfaces, etc.) for all code families.

Note that Table~\ref{tab:fec_libraries_comparison} does not aim at comparing
channel code implementation performances.

\subsection{FEC Software Decoders Hall of Fame}

On the \AFFECT website, an overview of software channel decoders
state-of-the-art is provided for the mains channel codes. In this section, a
snapshot of the LDPC Hall of Fame (HoF) is provided in
Table~\ref{tab:eval_ldpc_hof} as well as the turbo HoF in
Table~\ref{tab:eval_turbo_hof} and the polar HoF in
Table~\ref{tab:eval_polar_hof}. All the entries are sorted by platform type (GPU
and CPU) and chronologically. For each HoF table a column is dedicated to the
\emph{Hardware specifications}, it can have a huge impact on the decoding
performance depending on if you are using a low power ARM\R CPU or a high end
HPC GPU for instance. Then the next column aims to give some insights on the
\emph{Code} used in the decoding process, again decoding a short code will
generally result in low latencies performance when decoding a big code will
generally lead to higher latencies. The \emph{Decoder parameters} are given in a
dedicated column, those parameters characterize the decoding process used in the
experiments. The \emph{Decoding performances} (or \emph{Decoding perf.}) column
shows the reported performances in term of latency and throughput (and
exceptionally the BER and FER in the turbo HoF). In many cases, those raw
performances are hard to compare directly because the number of iterations ($i$)
or the number of lists ($L$) can vary from a work to an other. This is why we
proposed some \emph{Metrics} in the last column. Those metrics aim to facilitate
the comparison between the results. The \emph{normalized throughput} (NThr.) is
different for each HoF but the idea is to normalize the throughput with a
representative number of iterations/lists ($I$). Here is the normalized
throughput:
\begin{equation}
  NThr. = (Thr. \times i) / I,
\end{equation}
for the LDPC HoF $I = 50$, for the turbo HoF $I = 6$ and for the polar HoF
$I = 1$.
The \emph{throughput under normalized decoding cost} (TNDC) is a metric proposed
in~\cite{Ying2012}, the general idea is to see how much the hardware components
are stressed (higher TNDC is better). In the initial paper the $TNDC$ was only
taking care of the frequency and the number of cores. In this thesis we refined
the model by adding the SIMD length as this is a key for performance in channel
decoding algorithms:
\begin{equation}
  TNDC = NThr. / (Freq. \times Cores \times SIMD).
\end{equation}
The last metric is the \emph{decoding energy} ($E_d$), this is the energy cost
of the proposed implementation (lower is better):
\begin{equation}
  E_d = (TDP / NThr.) \times 10^3.
\end{equation}
For the TNDC and the decoding energy we used the normalized throughput instead
of the raw throughput in the formulas, is so you can compare metrics with each
other. You will notice that there is additional information given by upper
script notes in the different tables, here is the meaning of these notes:
\begin{itemize}
  \item $^*$: only one core of the CPU is used, in the TNDC computation one core
    is considered, in $E_d$ the entire TDP is used,
  \item $^\alpha$: not including the memory data transfers time between the CPU
    and the GPU, in real life those transfers occur and the impact on the real
    latency is significant,
  \item $^\beta$: we have strong doubts on the veracity of the result,
  \item $^\gamma$: following the formula, the throughput should be lower but the
    authors performed a specific data transfers overlapping with CUDA streams
    allowing to reach higher throughput.
  \item $^\dagger$: we did not compute the metrics because the proposed
    algorithm is too different to be compared with the others.
  \item $^\ddagger$: the inter-frame level has been deduced from the throughput
    and the latency.
\end{itemize}

\begin{table}
  \renewcommand{\arraystretch}{1.2}
  % \tabcolsep=6pt
  \centering
  \caption{LDPC Software Decoders Hall of Fame.}
  \label{tab:eval_ldpc_hof}
  \begin{adjustbox}{angle=90}
  {\resizebox{0.95\textheight}{!}{
  \begin{tabular}{|r|r r|r r r r r r|r r r|r r r r r r|r r|r r r|}
  \hline
  \multicolumn{3}{|c|}{\multirow{2}{*}{}} & \multicolumn{6}{c|}{\multirow{2}{*}{\textbf{Hardware specifications}}} & \multicolumn{3}{c|}{\multirow{2}{*}{\textbf{Code}}} & \multicolumn{6}{c|}{\multirow{2}{*}{\textbf{Decoder parameters}}} & \multicolumn{2}{c|}{\multirow{2}{*}{\textbf{Decoding perf.}}} & \multicolumn{3}{c|}{\multirow{2}{*}{\textbf{Metrics}}} \\
  \multicolumn{3}{|c|}{}                  & \multicolumn{6}{c|}{}                                                  & \multicolumn{3}{c|}{}                               & \multicolumn{6}{c|}{}                                             & \multicolumn{2}{c|}{}                                         & \multicolumn{3}{c|}{}                                  \\
  \hline
  \multicolumn{2}{|r}{\textbf{Work}}                                                   & \textbf{Year} & \textbf{Platform} & \textbf{Arch.}     & \textbf{TDP} & \textbf{Cores} & \textbf{SIMD} & \textbf{Freq.} & $\bm{(N,K)}$       & \textbf{Std.}     & \textbf{\# of} & \textbf{Sche-}  & \textbf{Early} & \textbf{Up.}   & \textbf{Pre.} & \textbf{Inter} & $\bm{i}$ & \textbf{Lat.}    & \textbf{Thr.}       & \textbf{NThr.} & \textbf{TNDC} & $\boldsymbol{E_d}$ \\
  \multicolumn{2}{|r}{}                                                                &               &                   &                    & Watts        & or SM          & length        & GHz            &                    &                   & \textbf{Edges} & \textbf{duling} & \textbf{T.}    & \textbf{Nodes} & bit           & level          &          & $\mu$s           & Mbps                & Mbps           &               & nJ                 \\
  \hline
  \hline
  \multirow{21}{*}{\rotatebox[origin=c]{90}{\textbf{GPU-based}}} & \cite{Wang2008}     & 2008          & 8800 GT           & \textit{Tesla}     &          105 &  7             &  16           & 1.50           & $(  4096,   2048)$ &                 - &   6144         & BP-F            & yes            &  SPA           & 32            &     1          &   6      &  467000          &     0.01            &    0.001       & 0.000006      &  105000000         \\
                                                                 & \cite{Falcao2009}   & 2009          & 8800 GTX          & \textit{Tesla}     &          176 &  8             &  16           & 1.35           & $(  1908,   1696)$ &                 - &   7632         & BP-F            &  no            &  SPA           & 32            &     -          &  50      &       -          &     0.08            &    0.080       & 0.000500      &    2200000         \\
                                                                 & \cite{Falcao2011a}  & 2011          & 8800 GTX          & \textit{Tesla}     &          176 &  8             &  16           & 1.35           & $(  8000,   4000)$ &                 - &  24000         & BP-F            &  no            &  SPA           &  8            &     -          &  50      &       -          &    10.10            &   10.100       & 0.058000      &      17426         \\
                                                                 & \cite{Falcao2011}   & 2011          & Tesla C2050       & \textit{Fermi}     &          247 & 14             &  32           & 1.15           & $( 64800,  21600)$ &            DVB-S2 & 216000         & BP-F            &  no            &   MS           &  8            &    16          &  30      &   13275          &    78.10            &   46.860       & 0.091000      &       5271         \\
                                                                 & \cite{Wang2011}     & 2011          & GTX 470           & \textit{Fermi}     &          215 & 14             &  32           & 1.22           & $(  1944,    972)$ &           802.11n &   6804         & BP-F            & yes            & LSPA           & 32            &   300          &  50      &   57743          &    10.10            &   10.100       & 0.018000      &      21287         \\
                                                                 & \cite{Ji2011}       & 2011          & GTX 285           & \textit{Tesla}     &          204 & 15             &  16           & 1.48           & $(  2304,   1152)$ &           802.16e &   7296         & BP-F            & yes            &  SPA           & 32            &     1          &  15      &    1097          &     2.10            &    0.630       & 0.001800      &     323810         \\
                                                                 & \cite{Chang2011}    & 2011          & Tesla C1060       & \textit{Tesla}     &          200 & 15             &  16           & 1.30           & $(  8000,   4000)$ &                 - &  32000         & BP-F            &  no            & LSPA           & 32            &     1          &  50      &    8638          &     0.92            &    0.920       & 0.002900      &     217391         \\
                                                                 & \cite{Wang2011a}    & 2011          & GTX 470           & \textit{Fermi}     &          215 & 14             &  32           & 1.22           & $(  2304,   1152)$ &           802.16e &   7296         & BP-F            &  no            & LSPA           & 32            &   224          &  10      &   10533          &    49.00            &    9.800       & 0.018000      &      21939         \\
                                                                 & \cite{Kang2012}     & 2012          & GTX 480           & \textit{Fermi}     &          250 & 15             &  32           & 1.40           & $(  2048,   1723)$ &           802.3an &  12288         & BP-F            & yes            &  SPA           & 32            &     1          &  50      &     426          &     4.80            &    4.800       & 0.007100      &      52083         \\
                                                                 & \cite{Falcao2012}   & 2012          & HD 5870           & \textit{Cypress}   &          188 & 20             &  20           & 1.20           & $(  8000,   4000)$ &                 - &      -         & BP-F            &  no            &   MS           &  8            &   500          &  10      &   22222          &   180.00            &   36.000       & 0.075000      &       5222         \\
                                                                 & \cite{Falcao2012}   & 2012          & Tesla C2050       & \textit{Fermi}     &          247 & 14             &  32           & 1.15           & $(  8000,   4000)$ &                 - &      -         & BP-F            &  no            &   MS           &  8            &   500          &  10      &   20000          &   200.00            &   40.000       & 0.078000      &       6175         \\
                                                                 & \cite{Gronroos2012} & 2012          & Tesla C2050       & \textit{Fermi}     &          247 & 14             &  32           & 1.15           & $( 16200,   8100)$ &            DVB-T2 &  48599         & BP-F            &  no            &   MS           &  8            &   128          &  50      &   26083          &    79.50            &   79.500       & 0.154000      &       3107         \\
                                                                 & \cite{Li2013}       & 2013          & GTX 580           & \textit{Fermi}     &          244 & 16             &  32           & 1.54           & $(  2304,   1152)$ &           802.16e &   7296         & BP-CL           &  no            &   MS           &  8            &  1024          &   5      &    3322          &   710.20            &  142.000       & 0.180000      &       1718         \\
                                                                 & \cite{Wang2013}     & 2013          & GTX TITAN         & \textit{Kepler}    &          250 & 14             & 192           & 0.84           & $(  2304,   1152)$ &           802.16e &   7296         & BP-F            & yes            &  NMS           & 32            &    50          &  10      &    1266          &   304.20$^\gamma$   &   60.800       & 0.027000      &       4112         \\
                                                                 & \cite{Wang2013}     & 2013          & GTX TITAN         & \textit{Kepler}    &          250 & 14             & 192           & 0.84           & $(  2304,   1152)$ &           802.16e &   7296         & BP-F            & yes            &  NMS           & 32            &     6          &  10      &     207          &    66.80            &   13.400       & 0.006000      &      18657         \\
                                                                 & \cite{Lin2014a}     & 2014          & GTX 660 Ti        & \textit{Kepler}    &          150 &  7             & 192           & 0.92           & $(  8000,   4000)$ &                 - &  24000         & BP-F            &  no            &  SPA           &  8            & 12544          &  50      &  954100$^\alpha$ &   105.20            &  105.200       & 0.085000      &       1426         \\
                                                                 & \cite{LeGal2014a}   & 2014          & GTX 660           & \textit{Kepler}    &          140 &  5             & 192           & 0.98           & $(  1944,    972)$ &           802.11n &   6804         & BP-HL           &  no            &  OMS           &  8            & 16384          &  10      &   34362$^\alpha$ &   926.90            &  185.400       & 0.049000      &        755         \\
                                                                 & \cite{Lai2016}      & 2016          & GTX 470           & \textit{Fermi}     &          215 & 14             &  32           & 1.22           & $(  1944,    972)$ &           802.11n &   6804         & BP-PL           &  no            &   MS           & 32            &   256          &  10      &    9739$^\alpha$ &    51.10            &   10.200       & 0.019000      &      21078         \\
                                                                 & \cite{Keskin2017b}  & 2017          & GTX TITAN X       & \textit{Pascal}    &          250 & 28             & 128           & 1.42           & $(  1944,    972)$ &           802.11n &   6804         & BP-F            &  no            &   MS           & 32            &     -          &  10      &       2$^\beta$  &   913.00            &  182.600       & 0.036000      &       1369         \\
                                                                 & \cite{Keskin2017a}  & 2017          & GTX TITAN X       & \textit{Pascal}    &          250 & 28             & 128           & 1.42           & $(  1944,    972)$ &           802.11n &   6804         & BP-F            &  no            &   MS           & 32            &    28          &  10      &      33$^\alpha$ &  1660.00            &  332.000       & 0.065000      &        753         \\
                                                                 & \cite{Kun2018}      & 2018          & GTX TITAN Xp      & \textit{Pascal}    &          250 & 30             & 128           & 1.58           & $( 64800,  21600)$ &            DVB-S2 & 216000         & BP-F            & yes            &  OMS           & 32            &     1          &  50      &      -           &   160.00            &  160.000       & 0.026000      &       1563         \\
  \hline
  \hline
  \multirow{14}{*}{\rotatebox[origin=c]{90}{\textbf{CPU-based}}} & \cite{Falcao2008}   & 2008          & CELL/BE           & \textit{CELL}      &          200 &  6             &  16           & 3.30           & $(  1248,    624)$ &           802.16e &      -         & BP-F            &  no            &   MS           &  8            &    96          &  25      &    3653          &    32.80            &   16.400       & 0.052000      &       6098         \\
                                                                 & \cite{Falcao2011a}  & 2011          & CELL/BE           & \textit{CELL}      &          200 &  6             &   4           & 3.30           & $(  1024,    512)$ &                 - &   3072         & BP-F            &  no            &  SPA           & 32            &    24          &  50      &    1719          &    14.30            &   14.300       & 0.181000      &      13986         \\
                                                                 & \cite{Falcao2011a}  & 2011          & 2xE5530           & \textit{Nehalem}   &          160 &  8             &   4           & 2.40           & $(  8000,   4000)$ &                 - &  24000         & BP-F            &  no            &  SPA           & 32            &     1          &  50      &   13115          &     0.61            &    0.610       & 0.007900      &     262295         \\
                                                                 & \cite{Zhao2011}     & 2011          & CELL/BE           & \textit{CELL}      &          200 &  8             &  16           & 3.20           & $(   960,    480)$ &           802.16e &      -         & BP-F            &  no            &  OMS           &  8            &     1          &  15      &      74          &    13.00            &    3.900       & 0.009500      &      51282         \\
                                                                 & \cite{Gronroos2012} & 2012          & i7-950            & \textit{Nehalem}   &          130 &  4             &  16           & 3.06           & $( 16200,   8100)$ &            DVB-T2 &  48599         & BP-F            &  no            &   MS           &  8            &   128          &  50      &  113934          &    18.20            &   18.200       & 0.093000      &       7143         \\
                                                                 & \cite{Pan2013}      & 2013          & i7-3960X          & \textit{S. Bridge} &          130 &  6             &  16           & 3.30           & $(  9216,   4608)$ &              CMMB &  27648         & BP-F            & yes            &  NMS           &  8            &    12          &  10      &    1202          &    92.00            &   18.400       & 0.058000      &       7065         \\
                                                                 & \cite{Han2013}      & 2013          & i7-2600K          & \textit{S. Bridge} &          130 &  4$^*$         &  16           & 3.40           & $(524280, 262140)$ &           802.11n &      -         & BP-L            &  no            &  OMS           &  8            &     1          &   5      &   17420          &    30.10            &    3.000       & 0.055000      &      31667         \\
                                                                 & \cite{Gronroos2013} & 2013          & Cortex-A9         & \textit{ARMv7}     &  $\approx~$4 &  4             &  16           & 1.60           & $( 16200,   8100)$ &            DVB-T2 &  48599         & BP-F            &  no            &   MS           &  8            &   128          &  20      &  592457          &     3.50            &    1.400       & 0.014000      &       2857         \\
                                                                 & \cite{Debbabi2016}  & 2016          & i7-4960HQ         & \textit{Haswell}   &           47 &  4             &   8           & 3.40           & $(  2304,   1152)$ &           802.16e &   7296         & LP-F            &  no            & ADMM           & 32            &     4          &   8      &    1511          &     6.10            &    0.980       & 0.009000      &      47959         \\
                                                                 & \cite{Debbabi2016a} & 2016          & i7-4960HQ         & \textit{Haswell}   &           47 &  4             &   8           & 3.40           & $(  2304,   1152)$ &           802.16e &   7296         & LP-HL           &  no            & ADMM           & 32            &    32          & 100      &   13755          &     5.40            &   10.800       & 0.099000      &       4352         \\
                                                                 & \cite{LeGal2016}    & 2016          & i7-4960HQ         & \textit{Haswell}   &           47 &  4             &  32           & 3.40           & $(  2304,   1152)$ &           802.16e &   7296         & BP-HL           & yes            &  NMS           &  8            &   128          &  50      &    1359          &   217.00            &  217.000       & 0.500000      &        217         \\
                                                                 & \cite{LeGal2017}    & 2017          & i7-5650U          & \textit{Broadwell} & $\approx~$10 &  2             &  32           & 3.00           & $(  2304,   1152)$ &           802.16e &   7296         & BP-HL           & yes            &  OMS           &  8            &     2          &  10      &      12          &   385.00            &   77.000       & 0.401000      &        123         \\
                                                                 & \cite{Grayver2019}  & 2019          & 2xEPYC 7351       & \textit{Zen}       &          340 & 32             &  16           & 2.40           & $( 64800,  32400)$ &            DVB-S2 & 226799         & BP-HL           & yes            &  OMS           &  8            &   512          &  20      &   18432          &  1800.00            &  720.000       & 0.586000      &        472         \\
                                                                 & \cite{Xu2019}       & 2019          & Gold 6154         & \textit{Skylake}   &          200 & 18             &  64           & 3.00           & $(  9126,   8448)$ &                5G &      -         & BP-HL           & yes            &  OMS           &  8            &    18          &  10      &      31          &  4892.40            &  978.500       & 0.283000      &        204         \\
  \hline
  \end{tabular}
  }}
  \end{adjustbox}
\end{table}

\begin{table}
  \renewcommand{\arraystretch}{1.2}
  % \tabcolsep=6pt
  \centering
  \caption{Turbo Software Decoders Hall of Fame.}
  \label{tab:eval_turbo_hof}
  \begin{adjustbox}{angle=90}
  {\resizebox{0.95\textheight}{!}{
  \begin{tabular}{|r|r r|r r r r r r|r r r|r r r r|r r r r|r r r|}
  \hline
  \multicolumn{3}{|c|}{\multirow{2}{*}{}} & \multicolumn{6}{c|}{\multirow{2}{*}{\textbf{Hardware specifications}}} & \multicolumn{3}{c|}{\multirow{2}{*}{\textbf{Code}}} & \multicolumn{4}{c|}{\multirow{2}{*}{\textbf{Decoder parameters}}} & \multicolumn{4}{c|}{\multirow{2}{*}{\textbf{Decoding performances}}} & \multicolumn{3}{c|}{\multirow{2}{*}{\textbf{Metrics}}} \\
  \multicolumn{3}{|c|}{}                  & \multicolumn{6}{c|}{}                                                  & \multicolumn{3}{c|}{}                               & \multicolumn{4}{c|}{}                                             & \multicolumn{4}{c|}{}                                                & \multicolumn{3}{c|}{}                                  \\
  \hline
  \multicolumn{2}{|r}{\textbf{Work}}                                                    & \textbf{Year} & \textbf{Platform}  & \textbf{Arch.}     & \textbf{TDP} & \textbf{Cores} & \textbf{SIMD} & \textbf{Freq.} & $\bm{K}$ & $\bm{R}$ & $\textbf{Std.}$ & \textbf{Algorithm} & \textbf{Pre.} & \textbf{Inter} & $\bm{i}$ & \textbf{BER} & \textbf{FER}   & \textbf{Lat.}   & \textbf{Thr.}    & \textbf{NThr.} & \textbf{TNDC} & $\boldsymbol{E_d}$ \\
  \multicolumn{2}{|r}{}                                                                 &               &                    &                    & Watts        & or SM          & length        & GHz            &          &          &                 &                    & bit           & level          &          & \multicolumn{2}{c}{at 0.7 dB} & $\mu$s          & Mbps             & Mbps           &               & nJ                 \\
  \hline
  \hline
  \multirow{12}{*}{\rotatebox[origin=c]{90}{\textbf{GPU-based}}} & \cite{Wu2010}        & 2010          & Tesla C1060        & \textit{Tesla}     & 200          & 15             & 16            & 1.30           & 6144     & 1/3      & LTE             &  ML-MAP            & 32            & 100            & 5        & 1e-04        &     -          &  76800          &    8.0           &   6.7          & 0.021         &  29851             \\
                                                                 & \cite{Wu2011}        & 2011          & GTX 470            & \textit{Fermi}     & 215          & 14             & 32            & 1.22           & 6144     & 1/3      & LTE             &  ML-MAP            & 32            & 100            & 5        & 4e-05        &     -          &  20827          &   29.5           &  24.6          & 0.045         &   8740             \\
                                                                 & \cite{Chinnici2012}  & 2012          & Tesla C2050        & \textit{Fermi}     & 247          & 14             & 32            & 1.15           & 11918    & 1/3      &   -             &   L-MAP            & 32            & 32             & 5        &     -        &     -          & 108965          &    3.5           &   2.9          & 0.0057        &  85172             \\
                                                                 & \cite{Yoge2012}      & 2012          & 9800 GX2           & \textit{Tesla}     & 197          & 16             & 16            & 1.50           & 6144     & 1/3      & LTE             &  ML-MAP            & 32            & 1              & 5        & 1e-02        &     -          &   3072          &    2.0           &   1.7          & 0.0043        & 115882             \\
                                                                 & \cite{Liu2013}       & 2013          & GTX 550 Ti         & \textit{Fermi}     & 116          & 6              & 32            & 1.80           & 6144     & 1/3      & LTE             & EML-MAP            & 32            & 1              & 6        & 1e-02        &     -          &     72$^\alpha$ &   85.3           &  85.3          & 0.247         &   1360             \\
                                                                 & \cite{Chen2013}      & 2013          & GTX 580            & \textit{Fermi}     & 244          & 16             & 32            & 1.54           & 6144     & 1/3      & LTE             &  ML-MAP            & 32            & 1              & 6        & 3e-04        &     -          &   1660          &    3.7           &   3.7          & 0.0047        &  63946             \\
                                                                 & \cite{Xianjun2013}   & 2013          & GTX 480            & \textit{Fermi}     & 250          & 15             & 32            & 1.40           & 6144     & 1/3      & LTE             & EML-MAP            & 32            & 1              & 6        &     -        &     -          &     50$^\alpha$ &  122.8           & 122.8          & 0.183         &   2036             \\
                                                                 & \cite{Wu2013}        & 2013          & GTX 680            & \textit{Kepler}    & 195          & 8              & 192           & 1.01           & 6144     & 1/3      & LTE             & EML-MAP            & 32            & 16             & 6        &     -        & 1e-02          &   2657          &   37.0           &  37.0          & 0.024         &   5270             \\
                                                                 & \cite{Zhang2014}     & 2014          & Tesla K20c         & \textit{Kepler}    & 225          & 13             & 192           & 0.71           & 6144     & 1/3      & LTE             &  ML-MAP            & 32            & 1              & 5        & 1e-04        &     -          &   1097          &    5.6           &   4.7          & 0.0026        &  47872             \\
                                                                 & \cite{Li2014}        & 2014          & GTX 580            & \textit{Fermi}     & 244          & 16             & 32            & 1.54           & 6144     & 1/3      & LTE             & BR-SOVA            & 8             & 4              & 5        & 2e-02        &     -          &    192$^\alpha$ &  127.8           & 106.5          & 0.135         &   2291             \\
                                                                 & \cite{Li2016a}       & 2016          & GTX 680            & \textit{Kepler}    & 195          & 8              & 192           & 1.01           & 6144     & 1/3      & LTE             & EML-MAP            & 32            & 1              & 7        & 9e-03        &     -          &    817          &    8.2$^\gamma$  &   9.6          & 0.0062        &  20313             \\
                                                                 & \cite{Li2016a}       & 2016          & GTX 680            & \textit{Kepler}    & 195          & 8              & 192           & 1.01           & 6144     & 1/3      & LTE             &    FPTD            & 32            & 1              & 36       & 9e-03        &     -          &    403          &   18.7$^\gamma$  & $\dagger$      & $\dagger$     &  $\dagger$         \\
  \hline
  \hline
  \multirow{10}{*}{\rotatebox[origin=c]{90}{\textbf{CPU-based}}} & \cite{Huang2011}     & 2011          & i7-960             & \textit{Nehalem}   & 130          & 1              &  8            & 3.20           & 1008     & 1/3      &   -             &  ML-MAP            & 16           & 1               & 8        & 3e-03        & 7e-02          &    138          &    7.3           &    9.7         & 0.380         &  13402             \\
                                                                 & \cite{Zhang2012}     & 2012          & X5670              & \textit{Westmere}  & 95           & 6              & 16            & 2.93           & 5824     & 1/3      &   -             & EML-MAP            &  8           & 6               & 3        & 6e-02        &     -          &    157          &  222.6           &  111.3         & 0.396         &    854             \\
                                                                 & \cite{Wu2013}        & 2013          & i7-3770K           & \textit{I. Bridge} & 77           & 4              &  8            & 3.50           & 6144     & 1/3      & LTE             & EML-MAP            & 16           & 4               & 6        &     -        & 1e-01          &    323          &   76.2           &   76.2         & 0.680         &   1011             \\
                                                                 & \cite{Cassagne2016a} & 2016          & E5-2650            & \textit{I. Bridge} & 95           & 8              &  8            & 2.50           & 6144     & 1/3      & LTE             & EML-MAP            & 16           & 64              & 6        & 6e-06        & 6e-03          &   3665          &  107.3           &  107.3         & 0.669         &    885             \\
                                                                 & \cite{Cassagne2016a} & 2016          & i7-4960HQ          & \textit{Haswell}   & 47           & 4              &  8            & 3.20           & 6144     & 1/3      & LTE             & EML-MAP            & 16           & 32              & 6        & 6e-06        & 6e-03          &   2212          &   88.9           &   88.9         & 0.868         &    527             \\
                                                                 & \cite{Cassagne2016a} & 2016          & $2\times$E5-2680v3 & \textit{Haswell}   & 240          & 24             &  8            & 2.50           & 6144     & 1/3      & LTE             & EML-MAP            & 16           & 192             & 6        & 6e-06        & 6e-03          &   2657          &  443.7           &  443.7         & 0.924         &    541             \\
                                                                 & \cite{Cassagne2016a} & 2016          & E5-2650            & \textit{I. Bridge} & 95           & 8              & 16            & 2.50           & 6144     & 1/3      & LTE             & EML-MAP            &  8           & 128             & 6        & 8e-05        & 5e-02          &   3492          &  225.2           &  225.2         & 0.704         &    422             \\
                                                                 & \cite{Cassagne2016a} & 2016          & i7-4960HQ          & \textit{Haswell}   & 47           & 4              & 16            & 3.20           & 6144     & 1/3      & LTE             & EML-MAP            &  8           & 64              & 6        & 8e-05        & 5e-02          &   2837          &  138.6           &  138.6         & 0.677         &    339             \\
                                                                 & \cite{Cassagne2016a} & 2016          & $2\times$E5-2680v3 & \textit{Haswell}   & 240          & 24             & 16            & 2.50           & 6144     & 1/3      & LTE             & EML-MAP            &  8           & 384             & 6        & 8e-05        & 5e-02          &   3293          &  716.4           &  716.4         & 0.746         &    335             \\
                                                                 & \cite{LeGal2019a}    & 2019          & $2\times$E5-2680v3 & \textit{Haswell}   & 240          & 24             & 32            & 2.50           & 6144     & 1/3      & LTE             & EML-MAP            &  8           & 24              & 6        & 1e-03        & 3e-01          &     84          & 1735.0           & 1735.0         & 0.904         &    138             \\
  \hline
  \end{tabular}
  }}
  \end{adjustbox}
\end{table}

\begin{table}
  \renewcommand{\arraystretch}{1.2}
  % \tabcolsep=6pt
  \centering
  \caption{Polar Software Decoders Hall of Fame.}
  \label{tab:eval_polar_hof}
  \begin{adjustbox}{angle=90}
  {\resizebox{0.95\textheight}{!}{
  \begin{tabular}{|r|r r|r r r r r r|r r|r r r r|r r|r r r|}
  \hline
  \multicolumn{3}{|c|}{\multirow{2}{*}{}} & \multicolumn{6}{c|}{\multirow{2}{*}{\textbf{Hardware specifications}}} & \multicolumn{2}{c|}{\multirow{2}{*}{\textbf{Code}}} & \multicolumn{4}{c|}{\multirow{2}{*}{\textbf{Decoder parameters}}} & \multicolumn{2}{c|}{\multirow{2}{*}{\textbf{Decoding perf.}}} & \multicolumn{3}{c|}{\multirow{2}{*}{\textbf{Metrics}}} \\
  \multicolumn{3}{|c|}{}                  & \multicolumn{6}{c|}{}                                                  & \multicolumn{2}{c|}{}                               & \multicolumn{4}{c|}{}                                             & \multicolumn{2}{c|}{}                                         & \multicolumn{3}{c|}{}                                  \\
  \hline
  \multicolumn{2}{|r}{\textbf{Work}}                                                    & \textbf{Year} & \textbf{Platform}  & \textbf{Arch.}     & \textbf{TDP} & \textbf{Cores} & \textbf{SIMD} & \textbf{Freq.} & $\bm{N}$ & $\bm{R}$ & \textbf{Algorithm} & \textbf{Pre.} & \textbf{Inter}   & $\bm{i}$/$\bm{L}$ & \textbf{Lat.}     & \textbf{Thr.}    & \textbf{NThr.} & \textbf{TNDC} & $\boldsymbol{E_d}$ \\
  \multicolumn{2}{|r}{}                                                                 &               &                    &                    & Watts        & or SM          & length        & GHz            &          &          &                    & bit           & level            &                   & $\mu$s            & Mbps             & Mbps           &               & nJ                 \\
  \hline
  \hline
  \multirow{ 5}{*}{\rotatebox[origin=c]{90}{\textbf{GPU-based}}} & \cite{Giard2016b}    & 2016          & Tesla K20c         & \textit{Kepler}    &         225  & 13             & 192           & 0.71           &  4096    & 0.90     &      SSC           & 32            &  832             &  1                &    9400           &  1043.0$^\gamma$ & 1043.00       &  0.5890        &    216             \\
                                                                 & \cite{Li2016b}       & 2016          & Tesla K20c         & \textit{Kepler}    &         225  & 13             & 192           & 0.71           &   256    & 0.50     &      SSC           & 32            &    -             &  1                &       -           &  395.00          &  395.00       &  0.2230        &    570             \\
                                                                 & \cite{Cammerer2017}  & 2017          & GTX 980 Ti         & \textit{Maxwell}   &         250  & 22             & 128           & 1.00           &  4096    & 0.50     & BP+CA-SCL          & 32            &    5$^\ddagger$  & 32                & 1000000           &    0.01          &    0.32       &  0.0001        & 781250             \\
                                                                 & \cite{Han2017}       & 2017          & GTX 980            & \textit{Maxwell}   &         165  & 16             & 128           & 1.17           &  4096    & 0.50     &       SCL          & 32/16         & 1310$^\ddagger$  & 32                &  111900$^\alpha$  &   24.00          &  768.00       &  0.3205        &    215             \\
                                                                 & \cite{Han2017}       & 2017          & GTX TITAN X        & \textit{Maxwell}   &         250  & 24             & 128           & 1.00           &  4096    & 0.50     &       SCL          & 32/16         & 1918$^\ddagger$  & 32                &  126700$^\alpha$  &   31.00          &  992.00       &  0.3229        &    252             \\
  \hline
  \hline
  \multirow{17}{*}{\rotatebox[origin=c]{90}{\textbf{CPU-based}}} & \cite{Giard2014}     & 2014          & i7-2600            & \textit{S. Bridge} &          95  &  4$^*$         &   8           & 3.40           & 32768    & 0.84     &      SSC           & 32            &    1             &  1                &     223           &  123.70          &  123.70       &  4.5480        &    768             \\
                                                                 & \cite{Giard2014}     & 2014          & i7-2600            & \textit{S. Bridge} &          95  &  4$^*$         &  16           & 3.40           & 32768    & 0.84     &      SSC           &  8            &    1             &  1                &     135           &  203.60          &  203.60       &  3.7430        &    467             \\
                                                                 & \cite{LeGal2014}     & 2014          & Cortex-A9          & \textit{ARMv7}     & $\approx~$3  &  4$^*$         &  16           & 1.30           & 32768    & 0.90     &      SSC           &  8            &   16             &  1                &   16852           &   28.00          &   28.00       &  1.3460        &    107             \\
                                                                 & \cite{Sarkis2014b}   & 2014          & i7-2600            & \textit{S. Bridge} &          95  &  4$^*$         &   8           & 3.40           &  2048    & 0.84     &   CA-SSCL          & 32            &    1             & 32                &    3300           &    0.52          &   16.64       &  0.5882        &   5709             \\
                                                                 & \cite{Sarkis2014}    & 2014          & i7-2600            & \textit{S. Bridge} &          95  &  4$^*$         &   8           & 3.40           & 32768    & 0.84     &      SSC           & 32            &    1             &  1                &     125           &  219.80          &  219.80       &  8.0810        &    432             \\
                                                                 & \cite{LeGal2015a}    & 2015          & i7-4960HQ          & \textit{Haswell}   &          47  &  4$^*$         &  16           & 3.60           & 32768    & 0.90     &      SSC           &  8            &   16             &  1                &     337           & 1400.00          & 1400.00       & 24.3060        &     34             \\
                                                                 & \cite{Cassagne2015c} & 2015          & E3-1225            & \textit{S. Bridge} &          95  &  4$^*$         &   8           & 3.10           & 32768    & 0.84     &      SSC           & 32            &    1             &  1                &     114           &  241.00          &  241.00       &  9.7180        &    394             \\
                                                                 & \cite{Cassagne2015c} & 2015          & E3-1225            & \textit{S. Bridge} &          95  &  4$^*$         &  16           & 3.10           & 32768    & 0.83     &      SSC           &  8            &   16             &  1                &     370           & 1180.00          & 1180.00       & 23.7900        &     81             \\
                                                                 & \cite{Sarkis2016}    & 2016          & i7-2600            & \textit{S. Bridge} &          95  &  4$^*$         &   8           & 3.40           &  2048    & 0.84     &   CA-SSCL          & 32            &    1             & 32                &     433           &    4.00          &  128.00       &  4.7059        &    742             \\
                                                                 & \cite{Giard2016b}    & 2016          & i7-4770S           & \textit{Haswell}   &          64  &  4$^*$         &  32           & 3.10           & 32768    & 0.84     &      SSC           &  8            &    1             &  1                &      31           &  886.00          &  886.00       &  8.9310        &     73             \\
                                                                 & \cite{Giard2016b}    & 2016          & Cortex-A9          & \textit{ARMv7}     & $\approx~$3  &  4$^*$         &  16           & 1.70           & 32768    & 0.90     &      SSC           &  8            &    1             &  1                &     361           &   81.70          &   81.70       &  3.0030        &     37             \\
                                                                 & \cite{Cassagne2016b} & 2016          & i7-4850HQ          & \textit{Haswell}   &          47  &  4$^*$         &  16           & 3.30           & 32768    & 0.83     &      SSC           &  8            &    1             &  1                &      47           &  580.00          &  580.00       & 10.9840        &     81             \\
                                                                 & \cite{Cassagne2016b} & 2016          & Cortex-A57         & \textit{ARMv8}     & $\approx~$2  &  2$^*$         &  16           & 1.10           & 32768    & 0.83     &      SSC           &  8            &    1             &  1                &     374           &   73.00          &   73.00       &  4.1480        &     27             \\
                                                                 & \cite{Shen2016}      & 2016          & i7-4790K           & \textit{Haswell}   &          88  &  4$^*$         &   8           & 4.00           &  2048    & 0.84     &       SCL          & 32            &    1             &  1                &    1573           &    1.10          &   35.10       &  1.0938        &   2514             \\
                                                                 & \cite{LeGal2017a}    & 2018          & i7-4960HQ          & \textit{Haswell}   &          47  &  4$^*$         &  32           & 3.60           & 32768    & 0.84     &      SSCAN         & 32            &    1             &  1                &      56           &  490.00          &  490.00       &  4.2535        &     96             \\
                                                                 & \cite{LeGal2017a}    & 2018          & i7-4960HQ          & \textit{Haswell}   &          47  &  4$^*$         &  32           & 3.60           & 32768    & 0.84     &      SSCAN         & 32            &   32             &  1                &    1601           &  550.00          &  550.00       &  4.7743        &     85             \\
                                                                 & \cite{Leonardon2019} & 2019          & i5-6600K           & \textit{Skylake}   &          91  &  4$^*$         &  32           & 3.90           &  2048    & 0.84     &   CA-SSCL          &  8            &    1             & 32                &     577           &    3.00          &   96.00       &  0.7692        &    948             \\

  \hline
  \end{tabular}
  }}
  \end{adjustbox}
\end{table}

\section{Use Cases}

\subsection{Simulator}

\begin{itemize}
  \item documentation
  \item r√©sultats de simulation, comparateur BER/FER (travaux de Mehdi)
  \item multi-noeuds
  \item \cite{Cassagne2017,Cassagne2017a}
\end{itemize}

\begin{table}[htp]
  \centering
  \caption{Specifications of the target processors.}
  \label{tab:simu_cpus_specs}
  {\resizebox{\linewidth}{!}{
  \begin{tabular}{l  l | l | l | c | c | c | c | c}
  \multicolumn{2}{c |}{\multirow{2}{*}{\textbf{CPU}}} & \multicolumn{2}{c |}{\textbf{SIMD instr.}} & \multirow{2}{*}{\textbf{\# Proc.}} & \textbf{\# Cores}  & \textbf{Freq.} & \multirow{2}{*}{\textbf{SMT}} & \textbf{Turbo} \\ \cline{3-4}
          &                                           & \textbf{Name} & \textbf{Size}              &                                    & \textbf{per Proc.} & (GHz)          &                               & \textbf{Boost} \\
  \hline
  \hline
  ARM\R   & ThunderX2\R CN9975                        & NEON          & 128-bit                    & 2                                  &  28                & 2.00           & 4                             & \xmark         \\
  Intel\R & Xeon Phi\TM 7230                          & AVX-512F      & 512-bit                    & 1                                  &  64                & 1.30           & 4                             & \cmark         \\
% AMD\R   & Ryzen\TM 7 2700X                          & AVX2          & 256-bit                    & 1                                  &  8                 & 3.70           & 2                             & \cmark         \\
  Intel\R & Xeon\TM E5-2680 v3                        & AVX2          & 256-bit                    & 2                                  &  12                & 2.50           & 1                             & \xmark         \\
  Intel\R & Xeon\TM Gold 6140                         & AVX-512BW     & 512-bit                    & 2                                  &  18                & 2.30           & 2                             & \cmark         \\
  Intel\R & Xeon\TM Gold 6142                         & AVX-512BW     & 512-bit                    & 2                                  &  16                & 2.60           & 1                             & \xmark         \\
  \end{tabular}
  }}
\end{table}

\begin{figure}[htp]
  \centering
  \subfloat[][Simulator speedups.]{\includegraphics[width=0.70\textwidth]{simu/speedup/speedup}\label{plot:simu_speedup}}
  % \quad
  \\
  \subfloat[][Simulator throughputs.]{\includegraphics[width=0.70\textwidth]{simu/throughput/throughput}\label{plot:simu_throughput}}
  \caption{\AFFECT simulation of a (2048,1723) Polar code, FA-SCL decoder
    $L=32$, BPSK modulation, AWGN channel, $E_b/N_0$ = 4.5~dB (BER = 4.34e-10,
    FER = 5.17e-08).}
  \label{plot:simu_speedup_throughput}
\end{figure}

Figure~\ref{plot:simu_speedup} depicts the speedups achieved on various modern
CPU architectures detailed in Table~\ref{tab:simu_cpus_specs}, while
Figure~\ref{plot:simu_throughput} exposes the corresponding simulation
information throughputs. In Figure~\ref{plot:simu_speedup}, the speedups on each
architecture are computed with respect to the single thread simulation time on
the same architecture. Each run assigns at most one \AFFECT thread to each
hardware thread, thus, since the architectures have different number of hardware
threads, the presented speedups do not all have the same number of measurement
points. In Figure~\ref{plot:simu_speedup_throughput}, an $N=2048$ and $K=1723$
Polar code (FA-SCL decoder, $L=32$, 32-bit GZip \verb|0x04C11DB7| CRC) is
simulated with a BPSK modulation and over an AWGN channel ($E_b/N_0 = 4.5$~dB,
last SNR point of the blue curve in Figure~\ref{fig:intro_bfer_polar}). The
frozen bits of the polar code have been generated with the Gaussian
Approximation method (GA)~\cite{Trifonov2012}. The communication chain is fully
vectorized with the \MIPP wrapper~\cite{Cassagne2018} and multi-threaded with
\Cxy{11} threads. The vectorization is applied at the tasks level (c.f.
Section~\ref{sec:soft_archi}) to take advantage of the algorithms intrinsic
level of parallelism, when the multi-threaded parallelism is used, to reduce the
simulation time by multiplicating the number of concurrent communication chains,
thanks to the independence property of Monte Carlo simulations. In order to
achieve highest possible throughputs, the receiver part of the simulator is
configured to work with 8-bit fixed-point representation for real numbers. It
has been shown that this representation does not degrade the decoding
performances of the FA-SCL decoder~\cite{Leonardon2019}. However \AFFECT
algorithms implementations can also be run on other representations like
64/32-bit floating-point and 16-bit fixed-point. For all the CPU targets, the
code has been compiled with the \Cxx GNU compiler version 8.2.0 on Linux, with
the following optimization flags: \verb|-O3 -funroll-loops -march=native|. Note
that \AFFECT also works on Windows and macOS at the same level of performance.
The simulation scales rather well on the tested architectures. The data remains
in the CPU caches because of the moderate frame size ($N = 2048$). Scaling on
the Xeon\TM Gold 6142 is not as good as the other targets, because the
\textit{Intel\R Turbo Boost} technology is enabled on this platform: the CPU
runs at higher frequencies when the number of active cores is low. \AFFECT
effectively leverages the simultaneous multi-threading (SMT) technology. This is
especially true for the ThunderX2\R CN9975 and Xeon\TM Gold 6140 targets. The
SMT technology helps to improve the usage of the available instruction-level
parallelism.

\begin{table}[htp]
  \centering
  \caption{\AFFECT multi-node speedups (single node: $2\times$Xeon\TM E5-2680 v3).}
  \label{tab:simu_speedup_mpi}
% {\footnotesize%\resizebox{\linewidth}{!}{
  \begin{tabular}{r  r  r  r}
  \textbf{Nodes} & \textbf{Cores} & \textbf{Info. T/P} & \textbf{Speedup} \\
                 &                & (Mb/s)             &           \\
  \hline
  \hline
   1             &  24            &  1950              &  1.00     \\
   2             &  48            &  3901              &  1.95     \\
%  3             &  72            &  5826              &  2.99     \\
   4             &  96            &  7793              &  4.00     \\
%  5             & 120            &  9731              &  4.99     \\
%  6             & 144            & 11691              &  5.99     \\
%  7             & 168            & 13644              &  7.00     \\
   8             & 192            & 15829              &  8.12     \\
%  9             & 216            & 17755              &  9.10     \\
% 10             & 240            & 19582              & 10.04     \\
  16             & 384            & 31640              & 16.22     \\
  32             & 768            & 63075              & 32.34     \\
  \end{tabular}
% }%}
\end{table}

Table~\ref{tab:simu_speedup_mpi} shows the multi-node scaling with the OpenMPI
library (version 3.1.2). The information throughput (T/P) and the speedup are
almost linear with the number of nodes: This is expected because there are very
few communications between the various MPI processes. Note that the super-linear
scaling is due to the measurements imprecision.

\textbf{Those aforementioned results demonstrate the high throughput
capabilities of \AFFECT.} For instance, when using 32 MPI nodes on the given
(2048,1723) polar code, it takes about one minute to estimate the $E_b/N_0=4.5$
dB SNR point (BER = 4.34e-10, FER = 5.17e-08).

\subsection{Library}

\begin{itemize}
  \item pleins d'implem autre que les d√©codeurs
  \item outil graphique avec des bo√Ætes, projet Romain
  \item wrapper MATLAB (travaux de Kun)
\end{itemize}

As a FEC library, \AFFECT can be used programmatically, for instance in
\emph{Software Defined Radio} (SDR) contexts or in simulations. \AFFECT blocks
can be used in external projects without restriction. Compute intensive blocks
are optimized and vectorized to run fast on a single core. The library is
thread-safe; however, it is not multi-threaded by itself, in contrast to the
simulator. Instead, it is the responsibility of the user to manage
multi-threading.

\subsubsection{Software Functionalities}

The \AFFECT software functionalities can be decomposed in three main parts: the
\textit{codecs}, the \textit{modems} and the \textit{channels}. The codecs are
the main part of the toolbox. There is a broad range of supported codes listed
in Table~\ref{tab:lib_codecs}.

\begin{table}[htp]
  \centering
  \caption{List of supported channel codes (codecs).}
  \label{tab:lib_codecs}
% {\footnotesize%\resizebox{\linewidth}{!}{
  \begin{tabular}{ c | c | c }
  \multirow{2}{*}{\textbf{Channel Code}}  & \multirow{2}{*}{\textbf{Standards}} & \multirow{2}{*}{\textbf{Decoders}}     \\
                                          &                                     &                                        \\
  \hline
  \hline
  \multirow{5}{*}{{LDPC}}                 & 5G (data), WiFi,                    & Scheduling: Flooding and H./V. Layered \\
                                          & WiMAX, WRAN,                        & Sum-Product Algorithm (SPA)            \\
                                          & 10 Gigabit Eth.,                    & Min-Sum (NMS, OMS)                     \\
                                          & DVB-S2, CCSDS                       & Approximate Min-Star (AMS)             \\
                                          & etc.                                & Bit Flipping: GallagerA/B/E, PPBF, WBF \\
  \hline
  \multirow{4}{*}{{Polar}}                &                                     & Successive Cancellation (SC)           \\
                                          & 5G                                  & Successive Cancellation List (SCL)     \\
                                          & (control channel)                   & CRC Aided SCL (CA-SCL, Adaptive SCL)   \\
                                          &                                     & Soft Cancellation (SCAN)               \\
  \hline
  \multirow{1}{*}{{Turbo Parallel}}       & LTE (3G, 4G),                       & Turbo BCJR                             \\
  (single and double                      & DVB-RCS,                            & Turbo BCJR + Early Termination (CRC)   \\
  binary)                                 & CCSDS, etc.                         & Post proc.: Flip aNd Check (FNC)       \\
  \hline
  \multirow{2}{*}{{Turbo Product}}        & \multirow{2}{*}{WiMAX (opt.)}       & \multirow{2}{*}{Turbo Chase-Pyndiah}   \\
                                          &                                     &                                        \\
  \hline
  \multirow{3}{*}{{BCH}}                  & CD, DVD,                            &                                        \\
                                          & SSD, DVB-S2,                        & Berlekamp-Massey + Chien search        \\
                                          & Bitcoin, etc.                       &                                        \\
  \hline
  \multirow{3}{*}{{Reed-Solomon}}         & CD, DVD,                            &                                        \\
                                          & SSD, DVB-T,                         & Berlekamp-Massey + Chien search        \\
                                          & ADSL, etc.                          &                                        \\
  \hline
  \multirow{1}{*}{{Convolutional}}        &                                     & BCJR - Maximum A Posteriori (MAP)      \\
  (single and double                      & NASA                                & BCJR - Linear Approximation            \\
  binary)                                 &                                     & BCJR - Max Approximation               \\
  \end{tabular}
% }%}
\end{table}

The codecs naturally encompass the encoders and decoders, but they can also
include puncturing patterns to shorten frames length according to some
communication standards. Most of the codec algorithms come from the literature,
while the others have been designed under
\AFFECT~\cite{Tonnellier2016a,Tonnellier2016b,Tonnellier2017,Leonardon2019}.
In channel coding, the decoder is the most time-consuming process, compared to
the puncturing and the encoding processes. This is why a specific effort is put
on ensuring the high computing performance of the decoders. Most of the decoding
algorithms have thus been optimized to satisfy high throughput and low latency
constraints~\cite{LeGal2015a,Cassagne2015c,Cassagne2016a,Cassagne2016b}. Those
optimizations generally involve a vectorized implementation, a tailored data
quantization and the use of fixed-point arithmetic.

In typical communication chains, it is necessary to adapt the digital signal
to the physical support. This operation is performed by the modulator and
conversely by the demodulator. \AFFECT comes with a rich set of modems to this
purpose. Table~\ref{tab:lib_modems} lists all the supported modems.

\begin{table}[htp]
  \centering
  \caption{List of supported modulations/demodulations (modems).}
  \label{tab:lib_modems}
  %{\footnotesize%\resizebox{\linewidth}{!}{
  \begin{tabular}{ c | c | c }
  \multirow{2}{*}{\textbf{Modem}} & \multirow{2}{*}{\textbf{Standard}} & \multirow{2}{*}{\textbf{Characteristics}} \\
                                  &                                    &                                           \\
  \hline
  \hline
  \multirow{3}{*}{{N-PSK}}        & IEEE 802.16 (WiMAX)                &                                           \\
                                  & UMTS (2G, 2G+)                     & Phase-Shift Keying                        \\
                                  & EDGE (8-PSK), ...                  &                                           \\
  \hline
  \multirow{3}{*}{{N-QAM}}        & IEEE 802.16 (WiMAX)                &                                           \\
                                  & UMTS (2G, 2G+)                     & Quadrature Amplitude Modulation           \\
                                  & 3G, 4G, 5G, ...                    &                                           \\
  \hline
  \multirow{3}{*}{{N-PAM}}        & IEEE 802.16 (WiMAX)                &                                           \\
                                  & UMTS (2G, 2G+)                     & Pulse Amplitude Modulation                \\
                                  & 3G, 4G, 5G, ...                    &                                           \\
  \hline
  \multirow{2}{*}{{CPM}}          & GMSK, Bluetooth                    & Continuous Phase Modulation               \\
                                  & IEEE 802.11 FHSS                   & Coded (convolutional-based) modulation    \\
  \hline
  \multirow{2}{*}{{OOK}}          & IrDA (Infrared)                    & On-Off Keying                             \\
                                  & ISM bands                          & Used in optical communication systems     \\
  \hline
  \multirow{2}{*}{{SCMA}}         & \multirow{2}{*}{Considered for 5G} & Sparse Code Multiple Access               \\
                                  &                                    & Multi-user modulation                     \\
  \hline
  \multirow{2}{*}{{User defined}} & \multirow{2}{*}{-}                 & Constellation and order can be            \\
                                  &                                    & defined from an external file             \\
  \end{tabular}
  %}%}
\end{table}

\AFFECT supports several coded modulation/demodulation schemes like the
Continuous Phase Modulation (CPM)~\cite{Aulin1981a,Aulin1981b} and the Sparse
Code Multiple Access (SCMA) modulation~\cite{Nikopour2013,Ghaffari2017,
Ghaffari2019} (many codebooks are supported~\cite{AlteraSCMA,Wu2015,Cheng2015,
Zhang2016,Klimentyev2016,Song2017,Klimentyev2017}). It allows to easily combine
and evaluate the channel codes with several types of modulations. In the case of
the CPM, analogical wave shapes are also simulated. The other modulation schemes
are at the digital level.

For simulation purposes, it is crucial to emulate the behavior of the physical
layer. This is the role of the channel. There are many possible configurations
depending on the physics phenomena to simulate.
Table~\ref{tab:lib_channels} reports all the supported channels.

\begin{table}[htp]
  \centering
  \caption{List of supported channels.}
  \label{tab:lib_channels}
  % {\footnotesize%\resizebox{\linewidth}{!}{
  \begin{tabular}{ c | c | c }
  \multirow{2}{*}{\textbf{Channel}}      & \multirow{2}{*}{\textbf{Multi-user}} & \multirow{2}{*}{\textbf{Characteristics}}      \\
                                         &                                      &                                                \\
  \hline
  \hline
  \multirow{2}{*}{{AWGN}}                & \multirow{2}{*}{Yes}                 & \multirow{2}{*}{Additive White Gaussian Noise} \\
                                         &                                      &                                                \\
  \hline
  \multirow{2}{*}{{BEC}}                 & \multirow{2}{*}{No}                  & \multirow{2}{*}{Binary Erasure Channel}        \\
                                         &                                      &                                                \\
  \hline
  \multirow{2}{*}{{BSC}}                 & \multirow{2}{*}{No}                  & \multirow{2}{*}{Binary Symmetric Channel}      \\
                                         &                                      &                                                \\
  \hline
  \multirow{2}{*}{{Rayleigh}}            & \multirow{2}{*}{Yes}                 & \multirow{2}{*}{Flat Rayleigh fading channel}  \\
                                         &                                      &                                                \\
  \hline
  \multirow{2}{*}{{User defined}}        & \multirow{2}{*}{Not yet}             & User can import noise samples                  \\
                                         &                                      & from an external file                          \\
  \end{tabular}
  %}%}
\end{table}

The channels involve complex floating-point computations. It is frequent to use
exponential and trigonometric operations. Those types of operations cost a large
amount of CPU cycles to be computed. As for the decoders, the channels have been
carefully optimized based on branch instructions reduction and massive
vectorization.

All these features are available from the simulator and in the library. Many
additional functional functionalities available are skipped here for concision.

\subsubsection{Illustrative Example}

\begin{listing}[htp]
  \inputminted[frame=lines,linenos]{C++}{main/chapter4/src/library/modules_allocation.cpp}
  \caption{Modules allocation.}
  \label{lst:library_modules_allocation}
\end{listing}

In this section the communication chain proposed in
Figure~\ref{fig:soft_archi_com_chain_task_module} is implemented with the
\AFFECT library. The first step is to allocate the modules. In
Listing~\ref{lst:library_modules_allocation} we chose to allocate modules on
the stack, but it is also possible to do the same on the heap. $K$ is the number
of information bits, $N$ is the frame size and $E$ is the number of erroneous
frames to simulate. One can notice that there is a module for the encoder and
for the decoder, this differs from
Figure~\ref{fig:soft_archi_com_chain_task_module} where \textit{encode} and
\textit{decode} are tasks of the codec module. In fact the codec module exists
in \AFFECT and it is an aggregation of the encoder and decoder modules. For
simplicity, we chose not to use the codec module here. In this basic example, a
repetition code is selected, it simply repeats the information bits $N/K$ times.

\begin{listing}[htp]
  \inputminted[frame=lines,linenos]{C++}{main/chapter4/src/library/sockets_binding.cpp}
  \caption{Sockets binding.}
  \label{lst:library_sockets_binding}
\end{listing}

The next step is to bind the sockets of successive tasks together (see
Listing~\ref{lst:library_sockets_binding}): The \textit{source} module
output socket \verb|src::sck::generate::U_K| is connected to the
input socket \verb|enc::sck::encode::U_K| of the \textit{encoder}, and so
on, for all the sockets of the tasks.

\begin{listing}[htp]
  \inputminted[frame=lines,linenos]{C++}{main/chapter4/src/library/tasks_execution.cpp}
  \caption{Tasks execution.}
  \label{lst:library_tasks_execution}
\end{listing}

The simulation is then started and each task is executed. In
Listing~\ref{lst:library_tasks_execution}, the whole communication chain is
executed multiple times, until the $E$ frame error limit is achieved (typically
$E = 100$ erroneous frames).

To propose an easy to use interface, sockets and tasks can be selected through
the \verb|[]| operator, which takes a \Cxx strongly typed enumerate. This way it
is possible to specialize the code depending on whether it is a socket or a
task. Strongly typed enumerates are checked at compile time (contrary to
standard enumerates), making it impossible to use wrong values.

\subsection{Prototyping}

\begin{itemize}
  \item hardware in the loop (travaux d'Olivier)
  \item \cite{Cassagne2017,Cassagne2017a}
\end{itemize}

\section{Software Architecture}
\label{sec:soft_archi}

\AFFECT is developed in \Cxx in an object-oriented programming style. It
provides the fundamental blocks involved in building communication chains
(sources, modems, codecs, channels, ...). Those blocks are organized as
\textit{modules} and \textit{tasks}.

\textbf{Module:} A set of related tasks sharing some characteristics. For
instance, the \textit{modem} module contains the \textit{modulate} and
\textit{demodulate} tasks.

\textbf{Task:} An elementary processing performed on some data. For instance,
\textit{decode} or \textit{modulate} are tasks. The tasks are characterized by
their \textit{sockets}. A socket of a task defines an entry point through which
the task will consume and/or produce data. There are three kinds of sockets:
\textit{input}, \textit{output} and \textit{input/output}, following a
philosophy close to \emph{ports} in component-based development approaches.

\begin{figure}[htp]
  \centering
  \includegraphics[width=0.70\linewidth]{soft_archi/com_chain_task_module}
  \caption{Modules and tasks.}
  \label{fig:soft_archi_com_chain_task_module}
\end{figure}

As a rule, a task is always a \emph{verb} and a module is always a \emph{noun}.
Modules are implemented as C++ classes, and tasks as class methods. \AFFECT
defines several abstract modules, for sources, codecs, modems, channels, etc. It
readily provides many implementations of those abstract classes; it is also
straightforward to add new ones.
Figure~\ref{fig:soft_archi_com_chain_task_module} presents common modules and
tasks typically found in a basic communication chain. It shows that the number
of tasks per module can vary depending on the module type.

\subsection{Source Code Organization}

\subsubsection{Factory}

\subsubsection{Module}

\subsubsection{Tools}

\subsubsection{Simulation}

\subsection{Sub-projects}

\subsubsection{\MIPP}

\MIPP: \url{https://github.com/aff3ct/MIPP}.

\subsubsection{My Project with \AFFECT}

\verb|my_project_with_aff3ct|: \url{https://github.com/aff3ct/my_project_with_aff3ct}.

\subsubsection{Polar Decoder Generation}

\verb|polar_decoder_gen|: \url{https://github.com/aff3ct/polar_decoder_gen}.

\subsubsection{PyBER}

\verb|PyBER|: \url{https://github.com/aff3ct/PyBER}.

\subsubsection{aff3ct.github.io}

\verb|aff3ct.github.io|: \url{https://github.com/aff3ct/aff3ct.github.io}.

\subsubsection{Command Line Interface}

\verb|cli|: \url{https://github.com/aff3ct/cli}.

\section{CI/CD}

\AFFECT's development leverages streamlined Continuous Integration (CI) process.
Each new commit to the version control repository triggers a comprehensive
sequence of tests to catch potential regressions. Regression tests are based on
past simulation results, validated from the state-of-the-art.

The CI process enables us to safely and confidently integrate contributed
features and improvements from the community to \AFFECT. It also helps to keep
the code review time by the core development team low-enough to swiftly
integrate such contributions into the master branch.

\subsection{Continuous Integration}
\begin{itemize}
  \item tests de compilation
  \item tests de r√©gressions
\end{itemize}

\subsection{Continuous Delivery}

\section{Community and Impact}

\AFFECT is currently used in several industrial contexts for simulation purposes
(Turbo concept, Airbus, Thales, Huawei) and for specific developments (CNES,
Schlumberger, Airbus, Thales, Orange), as well as in academic projects (NAND
French National Agency project, IdEx CPU). The MIT license used in the project
is very permissive and gives confidence to industrial and academic partners, who
can then invest themselves and reuse parts of \AFFECT in their own projects
without any restrictions.

An important aspect of channel coding is the ability to reproduce
state-of-the-art results, because there are many possible configurations and it
is time-consuming to rediscover those configurations. This is why \AFFECT comes
with a large database of pre-simulated performance curves with all the required
parameters. Some research projects have been using \AFFECT as a
reference~\cite{Leonardon2018a,Leonardon2018b,Florian2018,Pignoly2018,
Ghanaatian2018,Poulenard2018,Cavatassi2019a,Cavatassi2019b,Cenova2019,
Guermouche2019,Krainyk2019,Wang2019,Wang2019a,Hsieh2020,Rush2020,Tasdighi2020}.
All pre-computed simulation results are available at a glance on the online
comparator\footnote{BER/FER comparator:
\url{http://aff3ct.github.io/comparator.html}}, with corresponding command lines
to reproduce them. Combined with the possibility to download \AFFECT last
builds\footnote{\AFFECT last builds:
\url{http://aff3ct.github.io/download.html}}, testing the reference
configurations, replicating the experiments and playing with parameters is
straightforward. \textbf{\AFFECT aims to achieve results easily reproducible by
the scientific community.}

It comes with a comprehensive documentation, to help using, modifying, extending
existing coding schemes, to potentially improve them or to adapt to other
domains. Moreover, \AFFECT can be used to prototype and evaluate hardware
implementations~\cite{Cassagne2017a}.

\subsection{Academics}
\subsection{Industrials}
\subsection{Contributors}

\section{Discussion}
