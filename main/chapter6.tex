%!TEX root = ../my_thesis.tex

\graphicspath{{main/chapter6/fig/}}

\chapter{Embedded Domain Specific Language for the Software Defined Radio}

% \vspace*{\fill}
\minitoccustom
% \vspace*{\fill}

\section{Introduction}

\begin{itemize}
  \item \xmark~Algorithmes de synchronisation avant la démodulation
  \item \xmark~Tâches séquentielles (avec état)
\end{itemize}

It is now commonplace to state that Humanity has entered the era of
communication. The fifth generation of mobile networks (5G) is a perfect
illustration of this: all kinds of objects will increasingly use communication
technology to exchange information on the Internet of Things (IoT).

Despite their variety, all communication systems are based on a common
abstract model proposed by Claude Shannon. In his seminal
paper~\cite{Shannon1948}, he proposed to model a communication system with five
components: an information source, a transmitter, a channel, a receiver and a
destination.

Traditionally those communication systems are implemented on dedicated hardware
(ASIC) targeting high throughputs, low latencies and energy efficiency.
However, the implementations of such solutions have a long time to market, are
expensive and are specific by nature~\cite{Palkovic2010,Palkovic2012}.

The new standards like the 5G are coming with very large specifications and
multiple possible configurations~\cite{ETSI2018}. Small objects that need to
communicate very few data at low rates will live together with 4K video
streaming for mobile phone games which will required high throughputs as well as
low latencies~\cite{Rost2014}.

To meet those various specifications the transceivers will have to be able to
adapt quickly to new configurations. There is a growing need for flexible,
re-configurable and programmable solutions. To match those constraints, there is
a growing interest for the SDR which consists in processing both the Physical
(PHY) and Medium Access Control (MAC) layers in software~\cite{Mitola1993}, as
opposed to the traditionally hardware-based solutions. Short time to market,
lower development costs, interoperability, readiness to adapt to future updates
and new protocols are the mains advantages of the SDR~\cite{Akeela2018}.

SDR can be implemented on various targets like Field Programmable Gate Arrays
(FPGAs)~\cite{Coulton2004,Skey2006,Dutta2010,Shaik2013,Maheshwarappa2015,
Nivin2016}, Digital Signal Processors (DSPs)~\cite{Kaur2008,Karlsson2013,
Shaik2013} or General Purpose Processors (GPPs)~\cite{Yoge2012,Bang2014,
Meshram2019,Grayver2020}. This thesis focuses on GPPs targets as they are widely
spread, affordable and easy to program. More precisely, only the CPUs are
considered. Many elementary blocks of digital communication systems has been
optimized to run fast on x86 and ARM CPUs~\cite{Cassagne2015c,Cassagne2016a,
Cassagne2016b,Cassagne2018,Leonardon2019,Ghaffari2019} and have been packaged in
AFF3CT~\cite{Cassagne2017a,Cassagne2019a}, our dedicated open source toolbox.
Even if there is some interesting results in term of throughput on
GPUs~\cite{Xianjun2013,Li2014,LeGal2014a,Giard2016b,Keskin2017a}, the achieved
latency on this architecture is still too high to meet real time constraints and
cannot compete with existing CPU implementations~\cite{LeGal2015a,Cassagne2015c,
Giard2016b,Cassagne2016a,LeGal2017,Leonardon2019,LeGal2019a}. This is mainly due
to data transfers between the host (CPUs) and the device (GPUs), and to the
intrinsic nature of the GPU architecture which is not optimized for latency
efficiency.

\section{Dataflow Model}

\begin{itemize}
  \item \xmark~géneral dataflow
  \item \xmark~synchronous dataflow
  \item \xmark~cyclo static dataflow
\end{itemize}

The Shanon's communication model presented before can be refined in a way
that the transmitter and the receiver are decomposed into many processing
blocks. Those blocks are mainly connected to each other in an ordered graph.
This perfectly matches the dataflow model~\cite{Dennis1980,Ackerman1982}: the
blocks are the filters and the binding links between the blocks represent the
data movements. The dataflow model allows to describe the system from a high
level point of view and to perform optimizations independently of the system
designer. In the case of the SDR, simpler models than the generalized dataflow
can be used like the synchronous dataflow~\cite{Lee1987} or the cyclo-static
dataflow~\cite{Engels1994,Bilsen1995}. This allows to perform aggressive
simplifications like a static scheduling of the filters
execution~\cite{Parks1995}.

\section{Related Works}

\subsection{Dedicated Languages}

Many languages dedicated to streaming applications have been
developed~\cite{Buck2004,Amarasinghe2005,Liao2006,Black-Schaffer2010,Glitia2010,
Thies2010,DeOliveiraCastro2017}. Streaming applications are most of the time
represented with the dataflow model and the dedicated languages often support
the general or the cyclo-static dataflow model. They also very often come with
automatic parallelism mechanisms like pipelining and forks/joins.

\subsection{Ad Hoc Solutions}

Some preliminary works has been made to support a part of a communication
standard (DVB-S2 receiver) on CPUs and shows that it is possible to reach high
throughputs (10~Gb/s) using a small cluster~\cite{Grayver2020}. Those works
demonstrate the feasibility but lack an overall methodology. Indeed, the
approach is ad hoc for fixed parameters of the standard and a single CPU.

\subsection{GNU Radio}

However, there are few solutions targeting specifically the SDR sub-domain yet.
The most famous is GNU Radio~\cite{GNURadio} which is open source and largely
adopted by the community. The software is bundled with a large variety of
algorithms existing in real life systems. GNU Radio models the digital
communication systems at the symbol level: this philosophy is very close to the
algorithms descriptions that can be found in the signal community literature.
Thus, it allows quick implementation of new algorithms. Still, we show this is a
limitation to meet high throughputs and low latencies constraints on current
GPPs architectures, this is why, in this thesis, we propose, through AFF3CT, a
runtime Embedded Domain Specific Language (EDSL) working on sets of symbols
(aka frames). AFF3CT is a form of the synchronous dataflow model specialized to
the relevant characteristics of FEC communication chains enabling to perform
more aggressive optimizations than GNU Radio, at the cost of lower generality.

\section{Runtime Embedded DSL}

\begin{itemize}
  \item \xmark~dire pourquoi c'est un runtime embedded DSL.
\end{itemize}

\subsection{Serial Blocks}

\begin{itemize}
  \item \cmark~tâches = les traitements (effectués sur des trames)
  \item \cmark~modules = les données internes à une ou plusieurs tâches
  \item \cmark~sockets = les données échangées entre les tâches
  \item \cmark~boucles = permet de répéter une sous-séquence
  \item \xmark~routeurs = permet d'aiguiller vers différentes sous-séquences
\end{itemize}

The proposed domain specific language (DSL) comes with a set of elementary
components. The most important one is the \emph{task}, this component is also
known as the \emph{filter} in the standard dataflow model. A task is an
elementary block, it can be an encoder, a decoder or a modulator processing for
instance. Sometime a task, unlike a dataflow filter, can have an internal memory
to store temporary data for instance. If the life time of the private data
exceeds the task execution then the data will be contained by the \emph{module}.
Additionally a set of tasks can share the same internal/private memory, in that
particularly case, multiple tasks are regrouped in a single module. Be aware
that this behavior is not recommended by the standard dataflow model, and should
be avoided in a fully dataflow-compliant model. However, in many situations the
writing of a task or a set of tasks can be simplified by relieving this
constraint. Furthermore, storing private data in the module can be, in some
cases, a way to avoid to allocate memory for each task execution which is a very
expensive operation.

A task can consume and produce public data. To this purpose, each task exposes
input and/or output \emph{sockets}. The action of connecting the sockets of
different tasks is called the \emph{binding}. The binding directly determines
the tasks execution order (cf. Fig.~\ref{fig:soft_archi_com_chain_task_module}).

We found that some digital communication scenarios include repeated schemes.
To naturally map a repeated scheme, we introduced a specific task: the
\emph{loop}. This task has the particularity to be executed one or more times
depending on a \emph{condition}. A loop is binded to two sub-sequences of tasks,
the first one is executed and repeated while the condition is invalid and the
second one is taken when the condition is valid.

\begin{figure}[htp]
  \centering
  \includegraphics[width=1.00\textwidth]{dsl/loop/loop}
  \caption
    [Example of a sequence of tasks with a loop.]
    {Example of a sequence of tasks with a loop.}
  \label{fig:dsl_loop}
\end{figure}

Fig.~\ref{fig:dsl_loop} illustrates a sequence of tasks with a loop. In this
particular case, the loop condition is based on an input socket so the condition
evaluation is dynamic and depends on the runtime values of this input socket.
In a first place, the sub-sequence 1 will be executed, then the loop condition
is evaluated, if the condition return \emph{false} the sub-sequence 2 is
executed and the loop condition is re-evaluated until it returns \emph{true}. At
this point the sub-sequence 3 will be executed. To be able to achieve a static
binding, the number of input and output sockets of the loop are duplicated.
After the execution on the sub-sequence 1, the convention in the loop in to use
the input sockets 1 and 3. The input socket 1 is only used for the condition
evaluation whereas the input socket 3 is simply forwarded to the output socket 1
and 2. If the sub-sequence 2 is executed, the input sockets 2 and 4 will be used
until the end of the loop.

In the example the loop uses an input socket to evaluate the condition, this is
common in iterative demodulation/decoding schemes when the overall system can
have an early termination criterion like a CRC detection. Of course it is also
possible to override the loop behavior by inheriting from it, and the condition
evaluation process can be modified by the user. An other very common loop is the
predicate: in this case, the condition evaluation does not require any input
socket. The predicate can simply be a counter, each time the condition is
evaluated the counter is incremented and when the counter reaches a given values
the condition evaluation returns \emph{true} (\emph{for-loop} behavior).

\begin{figure}[htp]
  \centering
  \includegraphics{dsl/nested_loops/nested_loops}
  \caption
    [Nested loops.]
    {Nested loops.}
  \label{fig:dsl_nested_loops}
\end{figure}

The overall system also supports nested loops. The idea is to regroup the tasks
in sub-sequences: one before the loop and two after. This is managed with binary
tree, each time a loop in encountered, two new paths are created.
Fig.~\ref{fig:dsl_nested_loops} shows an example with two loops ($L_1$ and
$L_2$). Five sub-sequences of tasks are created ($SS_x$), one before $L_1$
($SS_1$), two after $L_1$ ($SS_2$ and $SS_5$) and two after $L_2$ ($SS_3$ and
$SS_4$). In this example $L_2$ is a nested loop because it is an inner loop
within the body of an outer one ($L_1$).

\subsection{Parallel Blocks}

\begin{itemize}
  \item \cmark~séquence = un enchaînement de tâches dont l'ordre est défini par les
    connections entre les sockets
  \item \cmark~pipeline
\end{itemize}

Many tasks that have been binded together can be regrouped in what we call a
\emph{sequence} of tasks. The sequence notion remind us that the tasks are
executed sequentially one by one in a pre-defined static order (like in the SDF
model). To create a sequence the user have to give the first tasks and the
last tasks to execute. Then the sequence will be analyzed and built. Once it is
done, the user can execute the whole sequence directly.

\begin{figure}[htp]
  \centering
  \subfloat[][Simple chain sequence.]{\includegraphics[width=0.485\textwidth]{dsl/sequence/sequence_chain}\label{fig:dsl_sequence_chain}}
  \quad
  \subfloat[][Sequence with multiple first and last tasks.]{\includegraphics[width=0.485\textwidth]{dsl/sequence/sequence_generic}\label{fig:dsl_sequence_generic}}
  \caption{Example of sequences.}
  \label{fig:dsl_sequence}
\end{figure}

Fig.~\ref{fig:dsl_sequence} show two examples of sequence.
Fig.~\ref{fig:dsl_sequence_chain} is a simple chain of tasks, this type of
sequence is very easy to build, the user only need to specify the first task of
the chain ($t_1$) and the sequence will automatically follow the binding to
reach and stop at the last task ($t_4$). Fig.~\ref{fig:dsl_sequence_generic} is
a little bit more complicated, there are binded tasks before and after the
wanted sequence. There is also two \emph{first} tasks ($t_1$ and $t_3$) and
two \emph{last} tasks ($t_5$ and $t_6$). In this case the user need to
explicitly specify that $t_1$ and $t_3$ are first tasks, if $t_1$ is given
before $t_3$ then $t_1$ will be executed first and $t_3$ after. In fact the
analysis will start from $t_1$ and continue to add new tasks if possible. In the
example, $t_2$ can be executed directly after $t_1$ but $t_4$ cannot because it
depends on $t_3$, so the analysis will stop after $t_2$ and will restart from
$t_3$. The index $i$ of the $t_i$ task represent the execution order. The $t_5$
and $t_6$ last tasks have to be given by the user because there are other tasks
binded to their output sockets: the analysis can't guess the end of the sequence
alone.

The proposed DSL is targeting streaming application and more precisely signal
processing and digital communication chains. In this type of applications, the
processing are repeated indefinitely a batch of frames when the system in on. So
a sequence is executed in loop, when the last task is executed, the next task is
the first one. The user can control if the sequence should restart by giving a
\emph{condition function} at the sequence execution. The prototype of the
function is \verb|bool cond_func(void)|: if the function returns \emph{false},
the sequence is repeated, else, if the function returns \emph{true}, the
sequence is stopped.

\begin{figure}[htp]
  \centering
  \includegraphics{dsl/sequence_dup/sequence_dup}
  \caption
    [Sequence duplication for multi-threaded execution.]
    {Sequence duplication for multi-threaded execution.}
  \label{fig:dsl_sequence_dup}
\end{figure}

A sequence can also be duplicated when created. The $t$ number of duplications
is a parameter of its constructor. As shown in Fig.~\ref{fig:dsl_sequence_dup},
one thread will be affected to one duplicated chain. This way a sequence is able
to take advantage of the multi-core architectures. For instance, the \AFFECT
simulator, based on the Monte Carlo Method, extensively use the sequence
duplication feature to speedup the results restitution time. The duplication
strategy is very efficient since there is no need for synchronization between
the threads. Each threaded sequence can be executed on one dedicated core and
the public data transfers remain on this core which is good for the data reuse
in the caches. However this parallelism is only possible if the tasks themselves
can be duplicated.

In some particular cases like in the signal synchronization stages, the tasks
can have a dependency on themselves. It is then impossible to duplicate the
sequence because of the sequential nature of these tasks. To overcome this issue
the well-known pipelining strategy can be used to be able to increase the
sequence throughput up to the slowest task throughput. The proposed DSL comes
with a specific \emph{pipeline} block to this purpose. The pipeline takes
multiple sequences as input. Each sequence of the pipeline is called a
\emph{stage}. A pipeline stage is run on one thread. For instance, a 4-stage
pipeline will create 4 threads, one thread per stage. A pipeline stage can be
combined with the sequence duplication strategy: there will be nested threads in
the current stage thread. Be aware that the pipelining strategy comes with an
extra synchronization cost between the stage threads. The implementation details
will be discussed later.

\subsection{Rules}

\begin{itemize}
  \item \cmark~une socket d'entrée ne peut être connectée qu'à une seule socket de
    sortie
  \item \cmark~toutes les sockets d'entrée d'une tâche doivent être connectées pour
    qu'elle puisse s'exécuter
  \item \cmark~une socket de sortie peut être connectée à aucune, une ou plus d'une
    socket d'entrée
  \item \cmark~l'ordonnancement d'une séquence est implicitement défini par le binding,
    quand la dernière socket d'input d'une tâche est connectée, alors on va
    passer aux tâches suivantes
\end{itemize}

In the proposed DSL, an input socket can only be binded to one output socket.
On the other side, an output socket can be binded to multiple input sockets.
A task can only be executed if all its input sockets are filled. The scheduling
of the tasks in a sequence is defined by the binding order. The general rule
in the sequence parser is to add a task to the sequence when its last input
socket is hit. After that, the output sockets of the current task are followed
to reach new tasks. The new tasks are discovered in the order in which they were
binded by the user.

\section{Implementation Details}

\subsection{Sequence Duplication and Clone}

In order to be able to duplicate sequences, we implemented a \emph{clone} method
in the modules. The \emph{clone} is an polymorphic method defined in the
\emph{Module} abstract mother class and relies on the implicit copy constructors
and a \emph{deep copy} protected method (overridable). The clone method
prototype is \verb|module::Module* clone() const|. In an implementation
(\emph{ModuleImpl}) of the abstract \emph{Module} class, a covariant return type
is used: \verb|module::ModuleImpl* clone() const|. The \emph{clone} method
implementation first call the implicit copy constructor of the \emph{ModuleImpl}
class and secondly call the \emph{deep copy} protected method. It is to the
responsibility to the \emph{ModuleImpl} developer to correctly override the
\emph{deep copy} method.

The \emph{deep copy} method helps to deal with pointer and reference members.
If the pointer/reference members are read-only (\verb|const|), then the implicit
copy constructor will copy the memory addresses automatically. The problem comes
when there is writable pointer/reference members. It is not possible to properly
manage writable references, this could mean that the current module can't be
duplicated (it also can be an implementation default). In the particular case of
a writable pointer member, the developer can explicitly allocate a new pointer
in the \emph{deep copy} method.

\subsection{Sequence Processes}

A sequence encapsulates a set of tasks and gives the opportunity to execute
these tasks in a predefined order. The tasks can also be executed manually
outside from the sequence but the user need to explicitly execute each task.
When using a sequence, the analysis process is able to match specific patterns
(known configurations of binded tasks) and in some case those patterns can be
replaced by a more efficient source code. To this purpose the notion of
\emph{process} has been introduced: in a sequence each task is necessarily
encapsulated in what we call a \emph{process}. For the majority of the tasks,
the \emph{process} just executes the task. But for some specific patterns, the
task execution source code is replaced by a more efficient one. The pattern
detection is based on a \Cxx basic introspection feature: during the analysis,
for each parsed task, we try to cast (\verb|dynamic_cast|) the corresponding
module in a specific class.

\subsection{Pipeline and 0-copy}

\section{Application on the DVB-S2 Standard}

\subsection{Transmitter}

\subsection{Receiver}

\subsection{Evaluations}

\subsection{Discussion}
