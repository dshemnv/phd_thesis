%!TEX root = ../my_thesis.tex

\graphicspath{{main/conclusion/fig/}}

\chapter*{Conclusions and Perspectives}
\markboth{Conclusions and Perspectives}{Conclusions and Perspectives}
\addcontentsline{toc}{chapter}{Conclusions and Perspectives}

\section*{Conclusion}

In the context of digital communications, channel coding schemes are widely
spread. This thesis focused on three channel codes that are present in most of
the current digital communication standards: the LDPC codes, the polar codes and
the turbo codes. In digital communication systems, most of the computational
time is spent in the receiver and more precisely in the decoding stage. This is
why, we propose efficient implementations of these decoding algorithms on CPUs.
The proposed implementations enable fast evaluations and validations of various
configurations. Moreover, there is a growing need to build full digital
communication chains in software. This is what we call the Software-Defined
Radio (SDR). Thus, the challenge is to take advantage of multi-core CPU
architectures to schedule the processing in parallel.

Several optimization strategies have been presented and discussed. One of the
main characteristic of the digital communication algorithms is that they have a
very short execution time (low latency). Thus, the most adapted parallelism
level presents in the actual CPUs is the Single Instruction Multiple Data (SIMD)
model. In Section~\ref{sec:opt_mipp}, \MIPP, a generic SIMD library, is
proposed. This library enables simplified and portable use of the CPUs
vectorized instructions. Then, in Section~\ref{sec:opt_vec}, two main
vectorization strategies are detailed: the intra-frame SIMD strategy that
enables very low latency implementations and the inter-frame SIMD strategy that
enables very high throughput implementations. The intra-frame SIMD strategy
consists in using the algorithm inherent parallelism to speedup the computation
in a single frame while the inter-frame SIMD strategy processes several frames
in parallel. In a second part of this chapter, specific optimizations for each
channel codes are given. First, a new SIMD implementation of the LDPC Belief
Propagation (BP) decoder is proposed. This decoder rests upon the inter-frame
strategy and focuses on maximizing the flexibility. Indeed, it is able to adapt
to many algorithmic sub-variants which is without precedent in the domain. Then,
the optimizations of two polar decoders are proposed, namely the Successive
Cancellation (SC) and the Successive Cancellation List (SCL) algorithms. Both
the inter-frame and intra-frame strategies are implemented. This two decoders
are based on a recursive description and the decoding process can be seen as a
tree traversal. Some specific optimizations like the tree pruning are performed
to drastically reduce the number of tree nodes. The recursive calls have also
been unrolled and generated decoders are proposed to reach the best possible
throughputs and latencies. This comes at the cost of reduced flexibility.
Finally, an SIMD implementation of the turbo decoder (max-log-MAP algorithms) is
given. The implementation uses the inter-frame SIMD strategy and targets high
throughputs. Specific optimizations have been made to increase the decoder
efficiency: some loops at the core of the decoding process have been merged and
unrolled to increase the registers reuse.

%In Chapter~\ref{chap:aff3ct}, \AFFECT, our open-source toolbox, is presented.
\AFFECT is a library of digital communication algorithms, developed as part of
this thesis, focusing on high performance implementations. Its software
architecture supports the algorithmic heterogeneity. Many channel codes are
supported like the LDPC codes, the polar codes and the turbo codes detailed
before. To the best of our knowledge, \AFFECT is the library with the most
comprehensive support for channel coding algorithms. The toolbox also includes a
BER/FER simulator. Many digital communication systems can be evaluated over
various parameters. The simulator takes advantage of the multi-core CPU
architectures to reduce the restitution time. All these features have been
designed to enable reproducible science. A BER/FER comparator tool has been
developed to easily search in a database of 500 pre-simulated BER/FER
references. All there references are results simulated with \AFFECT and that can
be reproduced. To this purpose, a pipeline of tests has been implemented. Each
time there is a modification in the source code, the database of references is
replayed to avoid regressions.

The new implementations have been evaluated and compared with the
state-of-the-art. The results show levels of performance close to the best
software implementations in the literature. Exhaustive surveys are given through
software decoder Hall of Fames (HoFs). The proposed decoders are reported as
well as state-of-the-art works. These HoFs enable to compare CPU and GPU
implementations. Some metrics like the normalized throughput, the Throughput
Under Normalized Decoding Cost (TNDC) and the energy consumption are defined.
Finally the \AFFECT simulator performance is evaluated over several server-class
CPUs. It shows that the simulator is able to take advantage of various SIMD
instructions and multi-core architectures. During the simulation of a polar
code, a peak performance of 11 Gb/s is reached on a AMD\R EPYC CPU. To the best
of our knowledge, this is the first work to reach this level of performance.

The \AFFECT library has been enriched with a new embedded Domain Specific
Language (eDSL). Main components have been designed to satisfy the SDR needs in
terms of 1) expressiveness; 2) performance. Most of the digital communication
systems can be represented by a directed graph of processing tasks (dataflow
model). The proposed eDSL uses this representation to improve the
expressiveness. Indeed, the tasks data transfers and their execution are
automatically managed by the eDSL. Moreover, in real-time contexts, the
performance is an important aspect. To reduce the execution time, some data
independent parts of the graph of tasks can be duplicated. Each duplication can
be executed on separated CPU cores. This strategy leads to an increased
throughput. However, when it cannot be applied the well-known pipeline strategy
have been implemented. Thus, the performance of the overall communication system
can be increased up to the throughput of the slowest task. Then, the proposed
eDSL is evaluated in an applicative context: the software implementation of the
DVB-S2 standard physical layer. The results demonstrate the efficiency of the
\AFFECT eDSL. Indeed, the proposed solution matches satellite real-time
constraints (30 $\thicksim$ 50~Mb/s). This is the consequence of two main
factors: 1) the task level optimizations, 2) the low overhead eDSL, with among
others, an efficient implementation of the pipeline technique.

\AFFECT is currently used in several industrial contexts for simulation purposes
(Turbo concept, Airbus, Thales, Huawei) and for specific developments (CNES,
Schlumberger, Airbus, Thales, Orange, Safran), as well as in academic projects
(NAND French National Agency project, IdEx CPU, RST CNES). The MIT license
chosen for the project enables industrial and academic partners to reuse parts
of \AFFECT in their own projects without any restriction. Moreover, \AFFECT has
been cited in scientific publications. Many works are exploiting the \AFFECT
simulator as a reference for the decoding performance. In other works, \AFFECT
has been enriched to support new features. And, in some cases, \AFFECT is used
as a library where some sub-parts of the toolbox are reused or some
methodologies are extracted.

To conclude on this thesis work, the main contributions are 1) the definition of
task level optimization techniques that enable high performance portable
implementations of signal processing algorithms on CPUs, 2) an open-source
software that enables homogeneous uses of various algorithms and implementations
and 3) a new language dedicated to the SDR needs that enables to define digital
communication systems taking advantage of the CPUs parallel architecture.
\AFFECT has been designed for high performance keeping in mind that the
algorithms come from the signal community experts that are not familiar with CPU
optimization techniques. Consequently, there is a clear separation of concerns
between the tasks design and their parallel execution. Co-design is then
possible: signal experts can focus on the tasks description while HPC experts
can work independently on the parallel execution thanks to the eDSL abstraction.
To the best of our knowledge, \AFFECT is the first environment to propose this
level of performance combined with the integration of many digital communication
algorithms.

% \newpage
\section*{Perspectives}

Several study and research perspectives remain to be explored following this
thesis work. A non-exhaustive list of these perspectives is given below. This
list is given in ascending order of presupposed complexity.

First, thanks to the flexibility of the proposed software architecture, new
coding schemes can be explored. The channel coding theory is constantly evolving
and it is mandatory to be able to evaluate the performance of new schemes. For
instance, the polar codes are one of the main interest in the domain. They have
been recently generalized from their discovery by \Arikan. It is possible to
build new codes from various kernels that are not just powers of two. This is
called multi-kernel polar codes. Some preliminary works have been conducted to
find kernels that have good factorization properties. However, this is a brute
force exploration and the complexity grows exponentially with the size of the
kernels. It could be interesting to reduce the kernel exploration domain and to
apply HPC techniques to reduce the finding time. The multi-kernel polar codes
construction is a promising area of research that could lead to decoding
performance even closer to the Shannon limit.

One of the main contribution of this thesis is to propose efficient digital
signal processing methods and implementations on CPU. Nowadays there is a
growing interest for GPUs in the HPC community. The GPUs are very parallel
architectures. In some conditions, the GPU implementations can lead to
non-negligible reduction of the computational time compared to the
implementations on CPU. It could be interesting to study the integration of
GPU tasks in \AFFECT. One of the main challenges is to manage the CPU to GPU and
GPU to CPU transfers. Even if the GPUs are a good alternative to the CPUs, we
believe that they will not be integrated in cloud-RAN architectures. The FPGAs
look like to provide a better compromize between power efficiency and
computational performance for scaling up. Their integration in \AFFECT could be
a great challenge.

Finally, the proposed eDSL could be enriched. For instance, the pipeline stages
are given by the user while they could be found automatically. The execution
time of the tasks is mostly constant for a given CPU. Thus, an auto-tuning phase
could be applied to determine a good configuration of the pipeline stages
automatically. Moreover, the scheduling of the tasks inside a sequence is very
basic. The tasks are not executed in parallel even if the data dependencies
allow it. We think that a dynamic scheduling strategy like it can be found in
the HPC runtime libraries (see OpenMP or StarPU) would be overkill. The overhead
of a dynamic scheduler is not negligible because the execution time of the
signal processing tasks in very short (ranging from some nanoseconds to some
microseconds). However, an improved static scheduling strategy that enables
parallel executions inside sequences would certainly help to reduce the
restitution time. These improvements could lead to an extension of the \AFFECT
eDSL. Indeed, the targeted domain could be expended to the generalized streaming
applications (image/video processing, cryptographic processing, networking, DSP,
etc.). The challenge will be to identify the required additional modules and to
integrate them into the eDSL with no impact on the execution efficiency.
