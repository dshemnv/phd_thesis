%!TEX root = ../my_thesis.tex

\graphicspath{{main/introduction/fig/}}

\chapter*{Introduction}
\markboth{Introduction}{Introduction}
\addcontentsline{toc}{chapter}{Introduction}

From time immemorial, man has sought to communicate. It started with the
development of the spoken language. However, one of the main limitation with
speech is that it only works at close range. To overcome this issue, the writing
has been invented. Man has always been seeking for more efficient ways to extend
his communication possibilities. Nowadays, with the advent of the Internet, the
digital communications represent the last technology advances to communicate
world-wide. Digital communications allow both live video transmission and the
use of a messaging system for instance. With the growing number of users and
needs, the digital communication systems are the subject of an important area of
research. New digital communication systems have to be able to match high
throughput and low latency constraints as well as acceptable energy consumption
levels.

Traditionally, the digital communication systems are implemented in hardware, on
dedicated chips. The required signal processing algorithms are often very
specific and repetitive. Thus, they are good candidates for specialized
architectures. However, with the growing number of use cases and standards,
these algorithms are evolving and are becoming more and more complex. In this
context, it becomes interesting to consider more generic processing units.
For instance, this type of programmable processing units is available in the
computers and is commonly referred as the Central Process Unit (CPU). The CPUs
are General Purpose Processors (GPP) that can adapt to various types of
algorithms. Improving the computational and the energy efficiency of these
processors is one of the main concern in computer science. As they are largely
adopted for many use cases, the CPUs take advantage of the best manufacturing
processes (up to 7 nm). Thanks to their pipelined architecture they are able to
reach very high frequencies ranging from 1 to 4 GHz. They also come with
dedicated memory caches that enable efficient spatial and temporal reuse of
data. Nowadays, the computational efficiency of the CPUs relies on the
multi-core architecture as well as on the vectorized instructions. These type of
instructions are able to perform the same operation on a chunk of data. This is
also known as the Single Instruction Multiple Data (SIMD) model.

From an energy point of view, it is clear that the CPUs are not directly
competitive with the dedicated architectures. Their large number of instructions
are the key of their capacity to adapt to many algorithms but this is also a
limitation when targeting specific implementations. Many transistors are
unused and consume a non-negligible amount of energy. On the other hand, the
main strength of the GPP architectures comes from their ability to be used
programmatically with high level languages. Consequently, the time required to
implement new algorithms is much faster on GPPs than on dedicated hardwares.
However, even with reduced implementation time, it is still challenging to
develop algorithms that take advantage of the CPUs parallelism levels. To this
purpose, dedicated compilers, languages and libraries are a important research
area in computer science. In the conception of digital communication systems, it
is largely adopted to rely on software implementations for the evaluation and
the validation of signal processing algorithms. Moreover, the software
implementations are also considered for real time uses. Their flexibility and
reduced time to market are becoming more and more attractive.

To help to the comprehension of the motivations, a parallel can be made between
the deep learning and the signal processing domains. Like for the deep learning,
the signal processing algorithms are based on a sub-set of predefined operators
and the communication between those algorithms rest upon regular work flows.
Thus, they are good candidates for dedicated languages. Firstly, like for the
neural networks, there is a preliminary phase where the digital communication
system is calibrated. This phase is generally made in software and requires
a non-negligible computational power (it is close to the learning phase in
machine learning). Then, once the characteristics of the system has been chosen,
the calibrated algorithms can be implemented in hardware or in software.
Depending on the targeted throughput and latency, the real-time implementations
can be challenging as some of the processing are compute intensive. This
thesis proposes optimizations techniques for the signal processing algorithms
that are close to the one used in the deep learning domain. One of the most
significant is the use of short representations of the real numbers during the
computations.